{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUPRfpyjuTJ2"
      },
      "source": [
        "THIS MODEL BUILD AS THE FIRST PROTOTYP MODEL OF AAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "IXtx-7OH6fLy",
        "outputId": "f5be2e97-19bf-45c7-e707-ca4e487ba879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DATA] TFRecords missing, starting preprocessing...\n",
            "[DATA] Processing DoS_dataset.csv\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b48e6a446451>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[WARN] {src} not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mnormals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mattacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-b48e6a446451>\u001b[0m in \u001b[0;36mpreprocess_windows\u001b[0;34m(csv_file)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Timestamp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DLC'\u001b[0m\u001b[0;34m]\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DLC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Timestamp'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'canID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_flag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'Data{i}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'Data{i}'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhex_to_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Flag'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Flag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'T'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10376\u001b[0m     def map(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.chained_assignment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mseries_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mseries_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_wrapped_if_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mproperties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m  12662\u001b[0m                ['monkey', nan, None]], dtype=object)\n\u001b[1;32m  12663\u001b[0m         \"\"\"\n\u001b[0;32m> 12664\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  12665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mas_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1692\u001b[0m                 \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1694\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1695\u001b[0m             \u001b[0;31m# The underlying data was copied within _interleave, so no need\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m             \u001b[0;31m# to further copy if copy=True or setting na_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1735\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1737\u001b[0;31m                 \u001b[0mitemmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1738\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0) GPU setup (optional)\n",
        "# ------------------------------------------------------------\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) CSV → windows → TFRecord (with file checks)\n",
        "# ------------------------------------------------------------\n",
        "datasets = ['DoS','Fuzzy','RPM','gear','parsed_dataset']\n",
        "csv_map = {\n",
        "    'DoS': 'DoS_dataset.csv',\n",
        "    'Fuzzy': 'Fuzzy_dataset.csv',\n",
        "    'RPM': 'RPM_dataset.csv',\n",
        "    'gear': 'gear_dataset.csv',\n",
        "    'parsed_dataset': 'parsed_dataset.csv'\n",
        "}\n",
        "\n",
        "FEATURE_DIM = 29*29*2\n",
        "LATENT_DIM  = 64\n",
        "N_LABELS    = 2\n",
        "N_L1        = 1000\n",
        "N_L2        = 1000\n",
        "BATCH       = 128\n",
        "EPOCHS      = 30\n",
        "\n",
        "\n",
        "def fill_flag(row):\n",
        "    if not isinstance(row['Flag'], str):\n",
        "        col = 'Data'+str(int(row['DLC']))\n",
        "        row['Flag'] = row.get(col, row['Flag'])\n",
        "    return row\n",
        "\n",
        "def convert_canid_bits(cid):\n",
        "    try:\n",
        "        b = bin(int(str(cid),16))[2:].zfill(29)\n",
        "        return np.array(list(map(int,b)),dtype=np.uint8)\n",
        "    except:\n",
        "        return np.zeros(29,dtype=np.uint8)\n",
        "\n",
        "def hex_to_int(x):\n",
        "    try: return int(str(x).strip(),16)\n",
        "    except: return 0\n",
        "\n",
        "def preprocess_windows(csv_file):\n",
        "    print(f\"[DATA] Processing {csv_file}\")\n",
        "    attrs = ['Timestamp','canID','DLC'] + [f'Data{i}' for i in range(8)] + ['Flag']\n",
        "    df = pd.read_csv(csv_file, header=None, names=attrs, low_memory=False)\n",
        "    df['Timestamp'] = pd.to_numeric(df['Timestamp'], errors='coerce')\n",
        "    df['DLC']= pd.to_numeric(df['DLC'], errors='coerce').fillna(0).astype(int)\n",
        "    df = df.dropna(subset=['Timestamp','canID']).apply(fill_flag, axis=1)\n",
        "    for i in range(8): df[f'Data{i}'] = df[f'Data{i}'].apply(hex_to_int).astype(np.uint8)\n",
        "    df['Flag'] = df['Flag'].astype(str).str.upper().eq('T').astype(np.uint8)\n",
        "    df['canBits'] = df['canID'].apply(convert_canid_bits)\n",
        "    df = df.sort_values('Timestamp')\n",
        "    bits_all   = np.stack(df['canBits'].values)\n",
        "    data_bytes = df[[f'Data{i}' for i in range(8)]].values\n",
        "    flags_all  = df['Flag'].values\n",
        "    win = 29; N = len(bits_all)//win\n",
        "    bits = bits_all[:N*win].reshape(N,win,29)\n",
        "    data = data_bytes[:N*win].reshape(N,win,8)\n",
        "    flags= flags_all[:N*win].reshape(N,win)\n",
        "    rows=[]\n",
        "    for i in range(N):\n",
        "        id_img = bits[i].astype(np.uint8)\n",
        "        last_b = data[i,-1,:]\n",
        "        b8 = np.unpackbits(last_b,axis=0).reshape(8,8)\n",
        "        data_img = cv2.resize(b8.astype(np.float32),(29,29), interpolation=cv2.INTER_NEAREST)>0.5\n",
        "        two_ch = np.stack([id_img, data_img.astype(np.uint8)],axis=-1)\n",
        "        pad = ((1,2), (1,2), (0,0))        # סה״כ גובה: 29+1+2=32  |  רוחב: 29+1+2=32\n",
        "        two_ch = np.pad(two_ch, pad, mode='constant')\n",
        "        feat_int = two_ch.flatten().tolist()\n",
        "        lbl = int(flags[i].any())\n",
        "        rows.append((feat_int,lbl))\n",
        "    return rows\n",
        "\n",
        "# Check or create TFRecords\n",
        "expected = []\n",
        "for a in datasets:\n",
        "    for ph in ('train','val','test'):\n",
        "        expected.append(f\"{a}_{ph}.tfrecord\")\n",
        "        if a!='parsed_dataset': expected.append(f\"Normal_{a}_{ph}.tfrecord\")\n",
        "if not all(os.path.exists(f) for f in expected):\n",
        "    print(\"[DATA] TFRecords missing, starting preprocessing...\")\n",
        "    for a in datasets:\n",
        "        src = csv_map[a]\n",
        "        if not os.path.exists(src): print(f\"[WARN] {src} not found\"); continue\n",
        "        rows = preprocess_windows(src)\n",
        "        normals = [r for r in rows if r[1]==0]\n",
        "        attacks = [r for r in rows if r[1]==1]\n",
        "        def write_tfrecord(rows, base):\n",
        "            np.random.shuffle(rows)\n",
        "            ntr = int(0.7*len(rows)); nvl = int(0.15*len(rows))\n",
        "            splits = {'train': rows[:ntr], 'val': rows[ntr:ntr+nvl], 'test': rows[ntr+nvl:]}\n",
        "            for ph,ch in splits.items():\n",
        "                fn = f\"{base}_{ph}.tfrecord\"\n",
        "                with tf.io.TFRecordWriter(fn) as w:\n",
        "                    for feat,lbl in ch:\n",
        "                        ex = tf.train.Example(features=tf.train.Features(feature={\n",
        "                            'features': tf.train.Feature(int64_list=tf.train.Int64List(value=feat)),\n",
        "                            'label':    tf.train.Feature(int64_list=tf.train.Int64List(value=[lbl]))\n",
        "                        }))\n",
        "                        w.write(ex.SerializeToString())\n",
        "        write_tfrecord(normals, f\"Normal_{a}\")\n",
        "        if attacks: write_tfrecord(attacks, a)\n",
        "else:\n",
        "    print(\"[DATA] All TFRecords found.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) tf.data pipeline\n",
        "# ------------------------------------------------------------\n",
        "def parse_feat(proto):\n",
        "    feat = tf.io.parse_single_example(proto, {\n",
        "        'features': tf.io.FixedLenFeature([FEATURE_DIM], tf.int64),\n",
        "        'label':    tf.io.FixedLenFeature([1], tf.int64)\n",
        "    })\n",
        "    x = tf.cast(feat['features'], tf.float32)\n",
        "    y = tf.one_hot(tf.cast(feat['label'][0], tf.int32), N_LABELS)\n",
        "    return x, y\n",
        "\n",
        "norm_train = glob.glob(\"Normal_*_train.tfrecord\")\n",
        "print(f\"[PIPE] Training TFRecords: {norm_train}\")\n",
        "def add_noise(x,y): return x+tf.random.normal(tf.shape(x),0,0.01), x, y\n",
        "\n",
        "ae_ds = (\n",
        "    tf.data.TFRecordDataset(norm_train, num_parallel_reads=tf.data.AUTOTUNE)\n",
        "    .map(parse_feat,  num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .map(add_noise,   num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .shuffle(10000).repeat()\n",
        "    .batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "total_records = sum(1 for _ in tf.data.TFRecordDataset(norm_train))\n",
        "steps_ae = total_records // BATCH\n",
        "print(f\"[PIPE] Total records: {total_records}, Steps/epoch: {steps_ae}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) Model definition\n",
        "# ------------------------------------------------------------\n",
        "class AAE(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.e1 = tf.keras.layers.Dense(N_L1, activation='relu')\n",
        "        self.e2 = tf.keras.layers.Dense(N_L2, activation='relu')\n",
        "        self.ez = tf.keras.layers.Dense(LATENT_DIM)\n",
        "        self.ey = tf.keras.layers.Dense(N_LABELS)\n",
        "        self.d1 = tf.keras.layers.Dense(N_L2, activation='relu')\n",
        "        self.d2 = tf.keras.layers.Dense(N_L1, activation='relu')\n",
        "        self.dout = tf.keras.layers.Dense(FEATURE_DIM, activation='sigmoid')\n",
        "        self.dz1 = tf.keras.layers.Dense(N_L1, activation='relu')\n",
        "        self.dz2 = tf.keras.layers.Dense(N_L2, activation='relu')\n",
        "        self.dzout = tf.keras.layers.Dense(1)\n",
        "        self.dy1 = tf.keras.layers.Dense(N_L1, activation='relu')\n",
        "        self.dy2 = tf.keras.layers.Dense(N_L2, activation='relu')\n",
        "        self.dyout = tf.keras.layers.Dense(1)\n",
        "    def encode(self,x):\n",
        "        h = self.e1(x); h = self.e2(h)\n",
        "        return self.ez(h), tf.nn.softmax(self.ey(h)), self.ey(h)\n",
        "    def decode(self,z,y):\n",
        "        h = tf.concat([z,y], axis=1); h = self.d1(h); h = self.d2(h)\n",
        "        return self.dout(h)\n",
        "    def discriminate_z(self,z):\n",
        "        h = self.dz1(z); h = self.dz2(h); return self.dzout(h)\n",
        "    def discriminate_y(self,y):\n",
        "        h = self.dy1(y); h = self.dy2(h); return self.dyout(h)\n",
        "\n",
        "aae = AAE()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4) Losses & Optimizers\n",
        "# ------------------------------------------------------------\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "ce  = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "opt_ae = tf.keras.optimizers.Adam(1e-3)\n",
        "opt_dz = tf.keras.optimizers.Adam(1e-4)\n",
        "opt_dy = tf.keras.optimizers.Adam(1e-4)\n",
        "opt_g  = tf.keras.optimizers.Adam(1e-4)\n",
        "λ_gp   = 10.0\n",
        "\n",
        "def gradient_penalty(f, real, fake):\n",
        "    α = tf.random.uniform([real.shape[0],1],0,1)\n",
        "    interm = real + α*(fake-real)\n",
        "    with tf.GradientTape() as t:\n",
        "        t.watch(interm)\n",
        "        pred = f(interm)\n",
        "    grads = t.gradient(pred, interm)\n",
        "    slopes= tf.sqrt(tf.reduce_sum(grads**2,axis=1)+1e-8)\n",
        "    return tf.reduce_mean((slopes-1)**2)\n",
        "\n",
        "@tf.function\n",
        "def train_step(xn, xc, y):\n",
        "    # AE Reconstruction\n",
        "    with tf.GradientTape() as tr:\n",
        "        z, yp, logits = aae.encode(xn)\n",
        "        xr = aae.decode(z, yp)\n",
        "        loss_re = mse(xc, xr)\n",
        "    ae_vars = (aae.e1.trainable_variables + aae.e2.trainable_variables + aae.ez.trainable_variables +\n",
        "               aae.ey.trainable_variables + aae.d1.trainable_variables + aae.d2.trainable_variables + aae.dout.trainable_variables)\n",
        "    grads_re = tr.gradient(loss_re, ae_vars)\n",
        "    opt_ae.apply_gradients(zip(grads_re, ae_vars))\n",
        "    # Discriminator z\n",
        "    with tf.GradientTape() as td:\n",
        "        z_real = tf.random.normal([xn.shape[0], LATENT_DIM])\n",
        "        dz_r, dz_f = aae.discriminate_z(z_real), aae.discriminate_z(z)\n",
        "        gp_z = gradient_penalty(aae.discriminate_z, z_real, z)\n",
        "        loss_dz = tf.reduce_mean(dz_f)-tf.reduce_mean(dz_r) + λ_gp*gp_z\n",
        "    dz_vars = aae.dz1.trainable_variables + aae.dz2.trainable_variables + aae.dzout.trainable_variables\n",
        "    grads_dz = td.gradient(loss_dz, dz_vars)\n",
        "    opt_dz.apply_gradients(zip(grads_dz, dz_vars))\n",
        "    # Discriminator y\n",
        "    with tf.GradientTape() as ty:\n",
        "        dy_r, dy_f = aae.discriminate_y(y), aae.discriminate_y(yp)\n",
        "        gp_y = gradient_penalty(aae.discriminate_y, y, yp)\n",
        "        loss_dy = tf.reduce_mean(dy_f)-tf.reduce_mean(dy_r) + λ_gp*gp_y\n",
        "    dy_vars = aae.dy1.trainable_variables + aae.dy2.trainable_variables + aae.dyout.trainable_variables\n",
        "    grads_dy = ty.gradient(loss_dy, dy_vars)\n",
        "    opt_dy.apply_gradients(zip(grads_dy, dy_vars))\n",
        "    # Generator (encoder) adversarial + classification\n",
        "    with tf.GradientTape() as tg:\n",
        "        zf = aae.discriminate_z(aae.encode(xc)[0])\n",
        "        yf = aae.discriminate_y(aae.encode(xc)[1])\n",
        "        loss_g = -tf.reduce_mean(zf) - tf.reduce_mean(yf) + ce(y, logits)\n",
        "    gen_vars = aae.e1.trainable_variables + aae.e2.trainable_variables + aae.ez.trainable_variables + aae.ey.trainable_variables\n",
        "    grads_g = tg.gradient(loss_g, gen_vars)\n",
        "    opt_g.apply_gradients(zip(grads_g, gen_vars))\n",
        "    return loss_re, loss_dz, loss_dy, loss_g\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5) Training loop\n",
        "# ------------------------------------------------------------\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    print(f\"[TRAIN] Epoch {ep}/{EPOCHS}\")\n",
        "    it = iter(ae_ds)\n",
        "    for step in range(steps_ae):\n",
        "        xn, xc, y = next(it)\n",
        "        lr, ldz, ldy, lg = train_step(xn, xc, y)\n",
        "        if step % 100 == 0:\n",
        "            print(f\" step {step}/{steps_ae} | recon={lr:.4f} dz={ldz:.4f} dy={ldy:.4f} gen={lg:.4f}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6) Save Models (functional build)\n",
        "# ------------------------------------------------------------\n",
        "print(\"[SAVE] Defining and saving encoder & decoder models...\")\n",
        "from tensorflow.keras.layers import Input, Activation, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# build functional encoder model using the layers from 'aae'\n",
        "enc_in = Input(shape=(FEATURE_DIM,), name='encoder_input')\n",
        "h = aae.e1(enc_in)\n",
        "h = aae.e2(h)\n",
        "z_enc = aae.ez(h)\n",
        "y_logits = aae.ey(h)\n",
        "y_enc = Activation('softmax', name='y_softmax')(y_logits)\n",
        "encoder_model = Model(inputs=enc_in, outputs=[z_enc, y_enc], name='aae_encoder')\n",
        "\n",
        "# build functional decoder model\n",
        "z_in = Input(shape=(LATENT_DIM,), name='z_input')\n",
        "y_in = Input(shape=(N_LABELS,), name='y_input')\n",
        "merged = Concatenate(axis=1)([z_in, y_in])\n",
        "h = aae.d1(merged)\n",
        "h = aae.d2(h)\n",
        "dec_out = aae.dout(h)\n",
        "decoder_model = Model(inputs=[z_in, y_in], outputs=dec_out, name='aae_decoder')\n",
        "\n",
        "# save full models\n",
        "encoder_model.save('aae_encoder.keras')\n",
        "decoder_model.save('aae_decoder.keras')\n",
        "print(\"[SAVE] Encoder and decoder saved to 'aae_encoder.keras' & 'aae_decoder.keras'\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7) Evaluation using loaded models\n",
        "# ------------------------------------------------------------\n",
        "print(\"[EVAL] Loading models and starting evaluation...\")\n",
        "encoder = tf.keras.models.load_model('aae_encoder.keras', compile=False)\n",
        "decoder = tf.keras.models.load_model('aae_decoder.keras', compile=False)\n",
        "\n",
        "print(\"[EVAL] Loading models and starting evaluation...\")\n",
        "encoder = tf.keras.models.load_model('aae_encoder.keras', compile=False)\n",
        "decoder = tf.keras.models.load_model('aae_decoder.keras', compile=False)\n",
        "err_list = []\n",
        "y_list   = []\n",
        "for fn in glob.glob('*_test.tfrecord'):\n",
        "    label = 0 if fn.startswith('Normal_') else 1\n",
        "    ds = tf.data.TFRecordDataset(fn).map(parse_feat).batch(256)\n",
        "    for x, _ in ds:\n",
        "        z_p, y_p = encoder(x)\n",
        "        x_r = decoder([z_p, y_p])\n",
        "        errs = tf.reduce_mean((x - x_r)**2, axis=1).numpy()\n",
        "        err_list.append(errs)\n",
        "        y_list.append(np.full(errs.shape, label))\n",
        "errs = np.concatenate(err_list)\n",
        "ys   = np.concatenate(y_list)\n",
        "# Metrics\n",
        "fpr, tpr, ths = roc_curve(ys, errs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "opt_i   = np.argmax(tpr - fpr)\n",
        "opt_t   = ths[opt_i]\n",
        "y_pred_labels = (errs > opt_t).astype(int)\n",
        "print(f\"[RESULT] ROC AUC        : {roc_auc:.4f}\")\n",
        "print(f\"[RESULT] Optimal Threshold: {opt_t:.6f}\")\n",
        "print(f\"[RESULT] TPR            : {tpr[opt_i]:.3f}\")\n",
        "print(f\"[RESULT] FPR            : {fpr[opt_i]:.3f}\")\n",
        "print(\"[RESULT] Confusion Matrix:\")\n",
        "print(confusion_matrix(ys, y_pred_labels))\n",
        "print(\"[RESULT] Classification Report:\")\n",
        "print(classification_report(ys, y_pred_labels, target_names=['Normal','Attack']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y884cxJ6uHG7"
      },
      "source": [
        "THIS MODEL BUILD FOR FIND THE BEST HYPERPARMTER SEARCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TGWrRLr0tnv",
        "outputId": "a7cb0430-fe0f-4aa2-abd6-b9065432cccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 51m 29s]\n",
            "val_loss: 0.017599908635020256\n",
            "\n",
            "Best val_loss So Far: 0.01379714347422123\n",
            "Total elapsed time: 08h 21m 40s\n",
            "[TUNER] Best HP: {'n_layers': 2, 'dropout': 0.2, 'activation': 'elu', 'norm_type': 'layer', 'n_l1': 1024, 'n_l2': 768, 'latent_dim': 64, 'lambda_gp': 10.0, 'lr_ae': 0.0005, 'lr_dz': 0.0001, 'lr_dy': 0.0001, 'lr_g': 5e-05}\n",
            "[TRAIN] Final training...\n",
            "[PIPE] Building datasets...\n",
            "[PIPE] Train files: 5, Val files: 5\n",
            "[TUNER] fit start\n",
            "[TUNER] Epoch 1/30\n",
            "[TUNER] Epoch 2/30\n",
            "[TUNER] Epoch 3/30\n",
            "[TUNER] Epoch 4/30\n",
            "[TUNER] Epoch 5/30\n",
            "[TUNER] Epoch 6/30\n",
            "[TUNER] Epoch 7/30\n"
          ]
        }
      ],
      "source": [
        "# ✅ גרסה מלאה של הפייפליין כולל AAE + Keras Tuner לאדברסיאל אוטואינקודר\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import sys\n",
        "import subprocess\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
        "from tensorflow.keras.layers import BatchNormalization, LayerNormalization, Dropout, LeakyReLU, Activation\n",
        "# התקנת keras-tuner אם צריך\n",
        "try:\n",
        "    import keras_tuner as kt\n",
        "except ModuleNotFoundError:\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'keras-tuner'])\n",
        "    import keras_tuner as kt\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0) GPU setup (optional)\n",
        "# ------------------------------------------------------------\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) CSV → windows → TFRecord (with file checks)\n",
        "# ------------------------------------------------------------\n",
        "datasets = ['DoS','Fuzzy','RPM','gear','parsed_dataset']\n",
        "csv_map = {\n",
        "    'DoS': 'DoS_dataset.csv',\n",
        "    'Fuzzy': 'Fuzzy_dataset.csv',\n",
        "    'RPM': 'RPM_dataset.csv',\n",
        "    'gear': 'gear_dataset.csv',\n",
        "    'parsed_dataset': 'parsed_dataset.csv'\n",
        "}\n",
        "FEATURE_DIM = 29*29*2\n",
        "N_LABELS    = 2\n",
        "BATCH       = 128\n",
        "EPOCHS      = 30\n",
        "\n",
        "# helper functions for preprocessing\n",
        "def fill_flag(row):\n",
        "    if not isinstance(row['Flag'], str):\n",
        "        col = 'Data'+str(int(row['DLC']))\n",
        "        row['Flag'] = row.get(col, row['Flag'])\n",
        "    return row\n",
        "\n",
        "def convert_canid_bits(cid):\n",
        "    try:\n",
        "        b = bin(int(str(cid),16))[2:].zfill(29)\n",
        "        return np.array(list(map(int,b)),dtype=np.uint8)\n",
        "    except:\n",
        "        return np.zeros(29,dtype=np.uint8)\n",
        "\n",
        "def hex_to_int(x):\n",
        "    try: return int(str(x).strip(),16)\n",
        "    except: return 0\n",
        "\n",
        "def preprocess_windows(csv_file):\n",
        "    print(f\"[DATA] Processing {csv_file}\")\n",
        "    attrs = ['Timestamp','canID','DLC'] + [f'Data{i}' for i in range(8)] + ['Flag']\n",
        "    df = pd.read_csv(csv_file, header=None, names=attrs, low_memory=False)\n",
        "    df['Timestamp'] = pd.to_numeric(df['Timestamp'], errors='coerce')\n",
        "    df['DLC']       = pd.to_numeric(df['DLC'], errors='coerce').fillna(0).astype(int)\n",
        "    df = df.dropna(subset=['Timestamp','canID']).apply(fill_flag, axis=1)\n",
        "    for i in range(8):\n",
        "        df[f'Data{i}'] = df[f'Data{i}'].apply(hex_to_int).astype(np.uint8)\n",
        "    df['Flag'] = df['Flag'].astype(str).str.upper().eq('T').astype(np.uint8)\n",
        "    df['canBits'] = df['canID'].apply(convert_canid_bits)\n",
        "    df = df.sort_values('Timestamp')\n",
        "    bits_all   = np.stack(df['canBits'].values)\n",
        "    data_bytes = df[[f'Data{i}' for i in range(8)]].values\n",
        "    flags_all  = df['Flag'].values\n",
        "    win = 29; N = len(bits_all)//win\n",
        "    bits = bits_all[:N*win].reshape(N,win,29)\n",
        "    data = data_bytes[:N*win].reshape(N,win,8)\n",
        "    flags= flags_all[:N*win].reshape(N,win)\n",
        "    rows=[]\n",
        "    for i in range(N):\n",
        "        id_img = bits[i].astype(np.uint8)\n",
        "        last_b = data[i,-1,:]\n",
        "        b8 = np.unpackbits(last_b,axis=0).reshape(8,8)\n",
        "        data_img = cv2.resize(b8.astype(np.float32),(29,29), interpolation=cv2.INTER_NEAREST)>0.5\n",
        "        two_ch = np.stack([id_img, data_img.astype(np.uint8)],axis=-1)\n",
        "        feat_int = two_ch.flatten().tolist()\n",
        "        lbl = int(flags[i].any())\n",
        "        rows.append((feat_int,lbl))\n",
        "    return rows\n",
        "\n",
        "def write_tfrecord(rows, base):\n",
        "    np.random.shuffle(rows)\n",
        "    ntr = int(0.7*len(rows)); nvl = int(0.15*len(rows))\n",
        "    splits = {'train': rows[:ntr], 'val': rows[ntr:ntr+nvl], 'test': rows[ntr+nvl:]}\n",
        "    for ph,ch in splits.items():\n",
        "        fn = f\"{base}_{ph}.tfrecord\"\n",
        "        with tf.io.TFRecordWriter(fn) as w:\n",
        "            for feat,lbl in ch:\n",
        "                ex = tf.train.Example(features=tf.train.Features(feature={\n",
        "                    'features': tf.train.Feature(int64_list=tf.train.Int64List(value=feat)),\n",
        "                    'label':    tf.train.Feature(int64_list=tf.train.Int64List(value=[lbl]))\n",
        "                }))\n",
        "                w.write(ex.SerializeToString())\n",
        "\n",
        "# create/check TFRecords\n",
        "expected=[]\n",
        "for a in datasets:\n",
        "    for ph in ('train','val','test'):\n",
        "        expected.append(f\"{a}_{ph}.tfrecord\")\n",
        "        if a!='parsed_dataset': expected.append(f\"Normal_{a}_{ph}.tfrecord\")\n",
        "if not all(os.path.exists(f) for f in expected):\n",
        "    print(\"[DATA] TFRecords missing, preprocessing...\")\n",
        "    for a in datasets:\n",
        "        src=csv_map[a]\n",
        "        if not os.path.exists(src): print(f\"[WARN] {src} not found\")\n",
        "        else:\n",
        "            rows=preprocess_windows(src)\n",
        "            normals=[r for r in rows if r[1]==0]\n",
        "            attacks=[r for r in rows if r[1]==1]\n",
        "            write_tfrecord(normals,f\"Normal_{a}\")\n",
        "            if attacks: write_tfrecord(attacks,a)\n",
        "else:\n",
        "    print(\"[DATA] All TFRecords found.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) tf.data pipeline\n",
        "# ------------------------------------------------------------\n",
        "def parse_feat(proto):\n",
        "    feat=tf.io.parse_single_example(proto,{\n",
        "        'features':tf.io.FixedLenFeature([FEATURE_DIM],tf.int64),\n",
        "        'label':   tf.io.FixedLenFeature([1],tf.int64)\n",
        "    })\n",
        "    x=tf.cast(feat['features'],tf.float32)\n",
        "    y=tf.one_hot(tf.cast(feat['label'][0],tf.int32),N_LABELS)\n",
        "    return x,y\n",
        "\n",
        "def make_datasets():\n",
        "    print('[PIPE] Building datasets...')\n",
        "    train_files=glob.glob('Normal_*_train.tfrecord')\n",
        "    val_files  =glob.glob('Normal_*_val.tfrecord')\n",
        "    ds_train=(tf.data.TFRecordDataset(train_files, num_parallel_reads=tf.data.AUTOTUNE)\n",
        "              .map(parse_feat, tf.data.AUTOTUNE)\n",
        "              .map(lambda x,y:(x+tf.random.normal(tf.shape(x),0,0.01),x,y), tf.data.AUTOTUNE)\n",
        "              .shuffle(10000).batch(BATCH).prefetch(tf.data.AUTOTUNE))\n",
        "    ds_val  =(tf.data.TFRecordDataset(val_files, num_parallel_reads=tf.data.AUTOTUNE)\n",
        "              .map(parse_feat, tf.data.AUTOTUNE)\n",
        "              .map(lambda x,y:(x,x,y), tf.data.AUTOTUNE)\n",
        "              .batch(BATCH).prefetch(tf.data.AUTOTUNE))\n",
        "    print(f'[PIPE] Train files: {len(train_files)}, Val files: {len(val_files)}')\n",
        "    return ds_train, ds_val\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) AAE Model definition\n",
        "# ------------------------------------------------------------\n",
        "class AAE(tf.keras.Model):\n",
        "    def __init__(self, n_l1, n_l2, latent_dim, lam_gp, n_layers=2, dropout_rate=0.2, activation='relu', norm_type='batch'):\n",
        "        super().__init__()\n",
        "        self.norm_type = norm_type\n",
        "        self.activation = activation\n",
        "        self.dropout_rate = dropout_rate\n",
        "        # Encoder\n",
        "        self.enc_layers = []\n",
        "        self.enc_norms = []\n",
        "        self.enc_drops = []\n",
        "        for i in range(n_layers):\n",
        "            units = n_l1 if i == 0 else n_l2\n",
        "            self.enc_layers.append(tf.keras.layers.Dense(units))\n",
        "            if norm_type == 'batch':\n",
        "                self.enc_norms.append(BatchNormalization())\n",
        "            else:\n",
        "                self.enc_norms.append(LayerNormalization())\n",
        "            self.enc_drops.append(Dropout(dropout_rate))\n",
        "        self.ez = tf.keras.layers.Dense(latent_dim)\n",
        "        self.ey = tf.keras.layers.Dense(N_LABELS)\n",
        "        # Decoder\n",
        "        self.dec_layers = []\n",
        "        self.dec_norms = []\n",
        "        self.dec_drops = []\n",
        "        for i in range(n_layers):\n",
        "            units = n_l2 if i == 0 else n_l1\n",
        "            self.dec_layers.append(tf.keras.layers.Dense(units))\n",
        "            if norm_type == 'batch':\n",
        "                self.dec_norms.append(BatchNormalization())\n",
        "            else:\n",
        "                self.dec_norms.append(LayerNormalization())\n",
        "            self.dec_drops.append(Dropout(dropout_rate))\n",
        "        self.dout = tf.keras.layers.Dense(FEATURE_DIM, activation='sigmoid')\n",
        "        # Discriminators\n",
        "        self.dz1 = tf.keras.layers.Dense(n_l1)\n",
        "        self.dz2 = tf.keras.layers.Dense(n_l2)\n",
        "        self.dzout = tf.keras.layers.Dense(1)\n",
        "        self.dy1 = tf.keras.layers.Dense(n_l1)\n",
        "        self.dy2 = tf.keras.layers.Dense(n_l2)\n",
        "        self.dyout = tf.keras.layers.Dense(1)\n",
        "        self.lam_gp = lam_gp\n",
        "        self.input_norm = LayerNormalization()\n",
        "    def _apply_activation(self, x):\n",
        "        if self.activation == 'leaky_relu':\n",
        "            return LeakyReLU()(x)\n",
        "        elif self.activation == 'elu':\n",
        "            return tf.keras.activations.elu(x)\n",
        "        else:\n",
        "            return tf.keras.activations.relu(x)\n",
        "    def encode(self, x):\n",
        "        h = self.input_norm(x)\n",
        "        for l, n, d in zip(self.enc_layers, self.enc_norms, self.enc_drops):\n",
        "            h = l(h)\n",
        "            h = n(h)\n",
        "            h = self._apply_activation(h)\n",
        "            h = d(h)\n",
        "        z = self.ez(h)\n",
        "        logits = self.ey(h)\n",
        "        return z, tf.nn.softmax(logits), logits\n",
        "    def decode(self, z, y):\n",
        "        h = tf.concat([z, y], 1)\n",
        "        for l, n, d in zip(self.dec_layers, self.dec_norms, self.dec_drops):\n",
        "            h = l(h)\n",
        "            h = n(h)\n",
        "            h = self._apply_activation(h)\n",
        "            h = d(h)\n",
        "        return self.dout(h)\n",
        "    def discriminate_z(self, z):\n",
        "        h = self._apply_activation(self.dz1(z))\n",
        "        h = self._apply_activation(self.dz2(h))\n",
        "        return self.dzout(h)\n",
        "    def discriminate_y(self, y):\n",
        "        h = self._apply_activation(self.dy1(y))\n",
        "        h = self._apply_activation(self.dy2(h))\n",
        "        return self.dyout(h)\n",
        "    def gradient_penalty(self, f, real, fake):\n",
        "        a = tf.random.uniform([real.shape[0], 1], 0, 1)\n",
        "        i = real + a * (fake - real)\n",
        "        with tf.GradientTape() as t:\n",
        "            t.watch(i)\n",
        "            p = f(i)\n",
        "        g = t.gradient(p, i)\n",
        "        s = tf.sqrt(tf.reduce_sum(tf.square(g), axis=1) + 1e-8)\n",
        "        return tf.reduce_mean((s - 1) ** 2)\n",
        "\n",
        "class AAEHyperModel(kt.HyperModel):\n",
        "    def build(self, hp):\n",
        "        n_layers = hp.Int('n_layers', 2, 4)\n",
        "        dropout_rate = hp.Float('dropout', 0.0, 0.5, step=0.1)\n",
        "        activation = hp.Choice('activation', ['relu', 'elu', 'leaky_relu'])\n",
        "        norm_type = hp.Choice('norm_type', ['batch', 'layer'])\n",
        "        return AAE(\n",
        "            hp.Int('n_l1', 256, 1024, 256),\n",
        "            hp.Int('n_l2', 256, 1024, 256),\n",
        "            hp.Int('latent_dim', 16, 128, 16),\n",
        "            hp.Choice('lambda_gp', [1.0, 5.0, 10.0, 20.0]),\n",
        "            n_layers=n_layers,\n",
        "            dropout_rate=dropout_rate,\n",
        "            activation=activation,\n",
        "            norm_type=norm_type\n",
        "        )\n",
        "    def fit(self, hp, model, ds_train, ds_val, epochs, steps_per_epoch, **kwargs):\n",
        "        print('[TUNER] fit start')\n",
        "        opt_ae = tf.keras.optimizers.Adam(hp.Choice('lr_ae', [1e-3, 5e-4, 1e-4]))\n",
        "        opt_dz = tf.keras.optimizers.Adam(hp.Choice('lr_dz', [1e-4, 5e-5]))\n",
        "        opt_dy = tf.keras.optimizers.Adam(hp.Choice('lr_dy', [1e-4, 5e-5]))\n",
        "        opt_g = tf.keras.optimizers.Adam(hp.Choice('lr_g', [1e-4, 5e-5]))\n",
        "        mse = tf.keras.losses.MeanSquaredError()\n",
        "        ce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "        for e in range(epochs):\n",
        "            print(f'[TUNER] Epoch {e+1}/{epochs}')\n",
        "            for step, (xn, xc, y) in enumerate(ds_train.take(steps_per_epoch)):\n",
        "                # AE\n",
        "                with tf.GradientTape() as t:\n",
        "                    z, yp, logits = model.encode(xn)\n",
        "                    xr = model.decode(z, yp)\n",
        "                    loss_re = mse(xc, xr)\n",
        "                vars_ae = []\n",
        "                for l in model.enc_layers + model.dec_layers:\n",
        "                    vars_ae += l.trainable_variables\n",
        "                vars_ae += model.ez.trainable_variables + model.ey.trainable_variables + model.dout.trainable_variables\n",
        "                opt_ae.apply_gradients(zip(t.gradient(loss_re, vars_ae), vars_ae))\n",
        "                # D_z\n",
        "                with tf.GradientTape() as t:\n",
        "                    zr = tf.random.normal([xn.shape[0], model.ez.units])\n",
        "                    dzr, dzf = model.discriminate_z(zr), model.discriminate_z(z)\n",
        "                    loss_dz = tf.reduce_mean(dzf) - tf.reduce_mean(dzr) + model.lam_gp * model.gradient_penalty(model.discriminate_z, zr, z)\n",
        "                vars_dz = model.dz1.trainable_variables + model.dz2.trainable_variables + model.dzout.trainable_variables\n",
        "                opt_dz.apply_gradients(zip(t.gradient(loss_dz, vars_dz), vars_dz))\n",
        "                # D_y\n",
        "                with tf.GradientTape() as t:\n",
        "                    dyr, dyf = model.discriminate_y(y), model.discriminate_y(yp)\n",
        "                    loss_dy = tf.reduce_mean(dyf) - tf.reduce_mean(dyr) + model.lam_gp * model.gradient_penalty(model.discriminate_y, y, yp)\n",
        "                vars_dy = model.dy1.trainable_variables + model.dy2.trainable_variables + model.dyout.trainable_variables\n",
        "                opt_dy.apply_gradients(zip(t.gradient(loss_dy, vars_dy), vars_dy))\n",
        "                # G\n",
        "                with tf.GradientTape() as t:\n",
        "                    zf = model.discriminate_z(model.encode(xc)[0])\n",
        "                    yf = model.discriminate_y(model.encode(xc)[1])\n",
        "                    loss_g = -tf.reduce_mean(zf) - tf.reduce_mean(yf) + ce(y, logits)\n",
        "                vars_g = []\n",
        "                for l in model.enc_layers:\n",
        "                    vars_g += l.trainable_variables\n",
        "                vars_g += model.ez.trainable_variables + model.ey.trainable_variables\n",
        "                opt_g.apply_gradients(zip(t.gradient(loss_g, vars_g), vars_g))\n",
        "        vals = []\n",
        "        for xv, xc, _ in ds_val:\n",
        "            z, y, _ = model.encode(xv)\n",
        "            xr = model.decode(z, y)\n",
        "            vals.append(mse(xc, xr).numpy())\n",
        "        avg = np.mean(vals)\n",
        "        print(f'[TUNER] Val MSE: {avg:.4f}')\n",
        "        return avg\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5) Hyperparameter search\n",
        "# ------------------------------------------------------------\n",
        "ds_train,ds_val=make_datasets()\n",
        "steps=sum(1 for _ in tf.data.TFRecordDataset(glob.glob('Normal_*_train.tfrecord')))//BATCH\n",
        "hypermodel=AAEHyperModel()\n",
        "tuner=kt.RandomSearch(hypermodel,objective=kt.Objective('val_loss','min'),max_trials=10,directory='aae_adv_tuner',project_name='adv_aae')\n",
        "print('[TUNER] Searching...')\n",
        "tuner.search(ds_train=ds_train,ds_val=ds_val,epochs=5,steps_per_epoch=steps)\n",
        "best_hp=tuner.get_best_hyperparameters()[0]\n",
        "print('[TUNER] Best HP:',best_hp.values)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6) Train final with best HP\n",
        "# ------------------------------------------------------------\n",
        "print('[TRAIN] Final training...')\n",
        "best_model=hypermodel.build(best_hp)\n",
        "ds_train,ds_val=make_datasets()\n",
        "_ = AAEHyperModel().fit(best_hp,best_model,ds_train,ds_val,EPOCHS,steps)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7) Save and evaluate\n",
        "# ------------------------------------------------------------\n",
        "from tensorflow.keras.layers import Input,Activation,Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "print('[SAVE] Saving encoder & decoder')\n",
        "enc_in=Input((FEATURE_DIM,));h=best_model.e2(best_model.e1(enc_in));z=best_model.ez(h);y=Activation('softmax')(best_model.ey(h))\n",
        "enc_model=Model(enc_in,[z,y],name='aae_encoder')\n",
        "z_in=Input((best_model.ez.units,));y_in=Input((N_LABELS,));merged=Concatenate()([z_in,y_in]);h=best_model.d2(best_model.d1(merged));out=best_model.dout(h)\n",
        "dec_model=Model([z_in,y_in],out,name='aae_decoder')\n",
        "enc_model.save('aae_encoder.keras');dec_model.save('aae_decoder.keras')\n",
        "print('[SAVE] Models saved')\n",
        "errs,ys=[],[]\n",
        "for fn in glob.glob('*_test.tfrecord'):\n",
        "    label=0 if fn.startswith('Normal_') else 1\n",
        "    for x,_ in tf.data.TFRecordDataset(fn).map(parse_feat).batch(256):\n",
        "        z_p,y_p=enc_model(x);x_r=dec_model([z_p,y_p]);e=tf.reduce_mean((x-x_r)**2,1).numpy()\n",
        "        errs.append(e);ys.append(np.full(e.shape,label))\n",
        "errs,ys=np.concatenate(errs),np.concatenate(ys)\n",
        "fpr,tpr,ths=roc_curve(ys,errs);roc=auc(fpr,tpr);opt_i=np.argmax(tpr-fpr);opt_t=ths[opt_i]\n",
        "print(f'ROC AUC:{roc:.4f} thr:{opt_t:.6f} TPR:{tpr[opt_i]:.3f} FPR:{fpr[opt_i]:.3f}')\n",
        "print('CM:',confusion_matrix(ys,(errs>opt_t).astype(int)))\n",
        "print(classification_report(ys,(errs>opt_t).astype(int),target_names=['Normal','Attack']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpaR5UxYd4C8"
      },
      "source": [
        "# =======================================================================================\n",
        "# 🛡️ CAN Bus Intrusion Detection using Tuned Adversarial Autoencoder (AAE)\n",
        "# =======================================================================================\n",
        "# This script implements a full pipeline for detecting anomalies in CAN bus traffic\n",
        "# using a carefully tuned Adversarial Autoencoder (AAE) model.\n",
        "#\n",
        "# 💡 Features:\n",
        "# - Converts CAN messages into 2-channel (ID + Data) pseudo-images of shape 29x29x2\n",
        "# - Trains an AAE model to learn compressed representations (z) and categorical labels (y)\n",
        "# - Detects anomalies via reconstruction error on test sets\n",
        "# - Uses both class and latent discriminators with gradient penalty for adversarial training\n",
        "#\n",
        "# 🔧 Tuned Hyperparameters (post-optimization):\n",
        "# - Latent dimension (z):        64\n",
        "# - Encoder/Decoder layers:      [1024, 768]\n",
        "# - Activation function:         ELU\n",
        "# - Dropout:                     0.2\n",
        "# - Normalization:               LayerNorm\n",
        "# - λ (gradient penalty):        10.0\n",
        "#\n",
        "# 🚀 Optimizer Learning Rates:\n",
        "# - Autoencoder (LR_AE):         0.0005\n",
        "# - Discriminator_z (LR_DZ):     0.0001\n",
        "# - Discriminator_y (LR_DY):     0.0001\n",
        "# - Generator (LR_G):            0.00005\n",
        "#\n",
        "# 📊 Final Evaluation:\n",
        "# - ROC AUC:                     ~[filled at runtime]\n",
        "# - Optimal Threshold:           ~[filled at runtime]\n",
        "# - Metrics:                     Confusion matrix and classification report\n",
        "#\n",
        "# After tuning, this configuration showed improved anomaly detection performance\n",
        "# across multiple CAN attack scenarios (DoS, Fuzzy, RPM, Gear).\n",
        "# =======================================================================================\n",
        "\n",
        "[RESULT] ROC AUC: 0.9820, Thr: 0.015617, TPR: 0.948, FPR: 0.058\n",
        "[RESULT] Confusion Matrix:\n",
        "[[39695  2427]\n",
        " [ 1208 21783]]\n",
        "[RESULT] Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "      Normal       0.97      0.94      0.96     42122\n",
        "      Attack       0.90      0.95      0.92     22991\n",
        "    accuracy                           0.94     65113\n",
        "   macro avg       0.94      0.94      0.94     65113\n",
        "weighted avg       0.95      0.94      0.94     65113"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45YSrBCUd6GM",
        "outputId": "1a22611c-cebc-4fc1-f294-193ecc4440a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DATA] TFRecords missing, preprocessing...\n",
            "[DATA] Processing DoS_dataset.csv\n",
            "[DATA] Processing Fuzzy_dataset.csv\n",
            "[DATA] Processing RPM_dataset.csv\n",
            "[DATA] Processing gear_dataset.csv\n",
            "[DATA] Processing parsed_dataset.csv\n",
            "[PIPE] Total records: 196541, steps/epoch: 1535\n",
            "[TRAIN] Epoch 1/30\n",
            " step 0/1535 | recon=0.2733 dz=1.9218 dy=5.3378 gen=-1.4722\n",
            " step 100/1535 | recon=0.0570 dz=-4.2550 dy=-0.0035 gen=1.6584\n",
            " step 200/1535 | recon=0.0394 dz=-2.3828 dy=-0.0020 gen=-1.0089\n",
            " step 300/1535 | recon=0.0295 dz=-1.5527 dy=-0.0009 gen=-2.7389\n",
            " step 400/1535 | recon=0.0288 dz=-1.2230 dy=-0.0007 gen=-3.7749\n",
            " step 500/1535 | recon=0.0255 dz=-0.8081 dy=-0.0005 gen=-4.1547\n",
            " step 600/1535 | recon=0.0260 dz=-0.7109 dy=-0.0006 gen=-3.8181\n",
            " step 700/1535 | recon=0.0245 dz=-0.7931 dy=-0.0004 gen=-3.8004\n",
            " step 800/1535 | recon=0.0232 dz=-0.7230 dy=-0.0006 gen=-3.8912\n",
            " step 900/1535 | recon=0.0218 dz=-0.7263 dy=-0.0004 gen=-3.9559\n",
            " step 1000/1535 | recon=0.0222 dz=-0.7663 dy=-0.0008 gen=-4.0987\n",
            " step 1100/1535 | recon=0.0212 dz=-0.7020 dy=-0.0006 gen=-4.2695\n",
            " step 1200/1535 | recon=0.0203 dz=-0.5447 dy=-0.0007 gen=-4.7470\n",
            " step 1300/1535 | recon=0.0194 dz=-0.5266 dy=-0.0007 gen=-4.7765\n",
            " step 1400/1535 | recon=0.0191 dz=-0.5156 dy=-0.0008 gen=-4.8375\n",
            " step 1500/1535 | recon=0.0183 dz=-0.7122 dy=-0.0008 gen=-5.0901\n",
            "[TRAIN] Epoch 2/30\n",
            " step 0/1535 | recon=0.0239 dz=-0.4144 dy=-0.0006 gen=-5.5528\n",
            " step 100/1535 | recon=0.0216 dz=-0.8742 dy=-0.0005 gen=-6.1909\n",
            " step 200/1535 | recon=0.0192 dz=-0.8333 dy=-0.0005 gen=-6.1655\n",
            " step 300/1535 | recon=0.0202 dz=-0.6455 dy=-0.0002 gen=-6.3624\n",
            " step 400/1535 | recon=0.0193 dz=-0.9246 dy=-0.0001 gen=-6.2189\n",
            " step 500/1535 | recon=0.0189 dz=-1.0416 dy=-0.0006 gen=-6.2248\n",
            " step 600/1535 | recon=0.0189 dz=-0.8985 dy=0.0011 gen=-6.5132\n",
            " step 700/1535 | recon=0.0178 dz=-1.0988 dy=-0.0007 gen=-6.5059\n",
            " step 800/1535 | recon=0.0182 dz=-1.1103 dy=-0.0008 gen=-6.8512\n",
            " step 900/1535 | recon=0.0165 dz=-1.1206 dy=-0.0008 gen=-6.2260\n",
            " step 1000/1535 | recon=0.0161 dz=-1.3885 dy=-0.0011 gen=-5.8192\n",
            " step 1100/1535 | recon=0.0166 dz=-1.4063 dy=-0.0010 gen=-5.9527\n",
            " step 1200/1535 | recon=0.0155 dz=-1.2854 dy=-0.0017 gen=-5.9666\n",
            " step 1300/1535 | recon=0.0158 dz=-1.3587 dy=-0.0043 gen=-5.6404\n",
            " step 1400/1535 | recon=0.0150 dz=-1.5365 dy=-0.0046 gen=-4.1967\n",
            " step 1500/1535 | recon=0.0148 dz=-1.5063 dy=-0.0072 gen=-3.8317\n",
            "[TRAIN] Epoch 3/30\n",
            " step 0/1535 | recon=0.0205 dz=-0.9624 dy=-0.0041 gen=-4.3061\n",
            " step 100/1535 | recon=0.0171 dz=-1.4091 dy=-0.0107 gen=-4.2280\n",
            " step 200/1535 | recon=0.0165 dz=-1.5716 dy=-0.0128 gen=-5.2779\n",
            " step 300/1535 | recon=0.0168 dz=-1.7037 dy=-0.0276 gen=-5.2547\n",
            " step 400/1535 | recon=0.0158 dz=-1.7103 dy=-0.0771 gen=-4.7820\n",
            " step 500/1535 | recon=0.0161 dz=-1.7888 dy=-0.0446 gen=-4.6902\n",
            " step 600/1535 | recon=0.0162 dz=-1.8031 dy=0.0117 gen=-4.2686\n",
            " step 700/1535 | recon=0.0150 dz=-1.8446 dy=-0.0399 gen=-4.0545\n",
            " step 800/1535 | recon=0.0150 dz=-1.9863 dy=-0.0284 gen=-3.9419\n",
            " step 900/1535 | recon=0.0139 dz=-2.1924 dy=-0.0180 gen=-3.0063\n",
            " step 1000/1535 | recon=0.0138 dz=-2.1799 dy=-0.0279 gen=-2.3448\n",
            " step 1100/1535 | recon=0.0143 dz=-2.0763 dy=-0.0207 gen=-2.1455\n",
            " step 1200/1535 | recon=0.0143 dz=-2.0553 dy=-0.0347 gen=-1.6966\n",
            " step 1300/1535 | recon=0.0137 dz=-2.0329 dy=-0.0302 gen=-1.4372\n",
            " step 1400/1535 | recon=0.0130 dz=-1.9251 dy=-0.0294 gen=-1.3816\n",
            " step 1500/1535 | recon=0.0134 dz=-2.0452 dy=-0.0055 gen=-1.4568\n",
            "[TRAIN] Epoch 4/30\n",
            " step 0/1535 | recon=0.0183 dz=-1.4138 dy=-0.0364 gen=-1.6292\n",
            " step 100/1535 | recon=0.0156 dz=-1.9522 dy=-0.0642 gen=-2.4935\n",
            " step 200/1535 | recon=0.0156 dz=-1.9371 dy=-0.0874 gen=-2.8863\n",
            " step 300/1535 | recon=0.0150 dz=-2.1384 dy=-0.0695 gen=-2.6101\n",
            " step 400/1535 | recon=0.0141 dz=-2.2771 dy=-0.0881 gen=-2.4933\n",
            " step 500/1535 | recon=0.0150 dz=-2.1228 dy=-0.0759 gen=-2.7571\n",
            " step 600/1535 | recon=0.0139 dz=-2.1905 dy=-0.0623 gen=-2.8623\n",
            " step 700/1535 | recon=0.0138 dz=-2.3335 dy=-0.0803 gen=-2.7687\n",
            " step 800/1535 | recon=0.0139 dz=-2.0742 dy=-0.1103 gen=-2.6345\n",
            " step 900/1535 | recon=0.0128 dz=-2.2104 dy=-0.0642 gen=-2.3945\n",
            " step 1000/1535 | recon=0.0131 dz=-2.1601 dy=-0.1115 gen=-1.9236\n",
            " step 1100/1535 | recon=0.0128 dz=-2.1631 dy=-0.0944 gen=-1.8765\n",
            " step 1200/1535 | recon=0.0125 dz=-2.3008 dy=-0.1159 gen=-2.0403\n",
            " step 1300/1535 | recon=0.0127 dz=-2.2701 dy=-0.1416 gen=-2.1440\n",
            " step 1400/1535 | recon=0.0136 dz=-2.0468 dy=-0.1519 gen=-2.1340\n",
            " step 1500/1535 | recon=0.0128 dz=-2.1954 dy=-0.1448 gen=-2.2529\n",
            "[TRAIN] Epoch 5/30\n",
            " step 0/1535 | recon=0.0150 dz=-2.0141 dy=-0.1463 gen=-2.3362\n",
            " step 100/1535 | recon=0.0145 dz=-2.3855 dy=-0.1843 gen=-2.9715\n",
            " step 200/1535 | recon=0.0138 dz=-2.3820 dy=-0.1835 gen=-3.0334\n",
            " step 300/1535 | recon=0.0137 dz=-2.2985 dy=-0.1961 gen=-3.2866\n",
            " step 400/1535 | recon=0.0135 dz=-2.4389 dy=-0.2616 gen=-2.9316\n",
            " step 500/1535 | recon=0.0129 dz=-2.1179 dy=-0.2246 gen=-3.0377\n",
            " step 600/1535 | recon=0.0132 dz=-2.2041 dy=-0.2006 gen=-2.8300\n",
            " step 700/1535 | recon=0.0134 dz=-2.3070 dy=-0.2027 gen=-2.7899\n",
            " step 800/1535 | recon=0.0119 dz=-2.2374 dy=-0.1814 gen=-2.6561\n",
            " step 900/1535 | recon=0.0129 dz=-2.4378 dy=-0.1730 gen=-2.4154\n",
            " step 1000/1535 | recon=0.0118 dz=-2.3248 dy=-0.1983 gen=-2.0912\n",
            " step 1100/1535 | recon=0.0126 dz=-2.2769 dy=-0.1659 gen=-2.2531\n",
            " step 1200/1535 | recon=0.0118 dz=-2.2468 dy=-0.1920 gen=-2.1324\n",
            " step 1300/1535 | recon=0.0125 dz=-2.1606 dy=-0.2644 gen=-1.8379\n",
            " step 1400/1535 | recon=0.0110 dz=-2.2720 dy=-0.1728 gen=-1.8794\n",
            " step 1500/1535 | recon=0.0115 dz=-2.1829 dy=-0.2571 gen=-1.5439\n",
            "[TRAIN] Epoch 6/30\n",
            " step 0/1535 | recon=0.0139 dz=-1.9233 dy=-0.3081 gen=-1.4600\n",
            " step 100/1535 | recon=0.0127 dz=-2.4012 dy=-0.2311 gen=-2.3507\n",
            " step 200/1535 | recon=0.0129 dz=-2.5750 dy=-0.4004 gen=-1.8761\n",
            " step 300/1535 | recon=0.0133 dz=-2.5932 dy=-0.3137 gen=-2.0616\n",
            " step 400/1535 | recon=0.0129 dz=-2.2962 dy=-0.3869 gen=-1.9354\n",
            " step 500/1535 | recon=0.0125 dz=-2.3182 dy=-0.3970 gen=-2.0516\n",
            " step 600/1535 | recon=0.0129 dz=-2.2690 dy=-0.3862 gen=-1.9962\n",
            " step 700/1535 | recon=0.0121 dz=-2.5291 dy=-0.3382 gen=-1.8220\n",
            " step 800/1535 | recon=0.0121 dz=-2.5260 dy=-0.4002 gen=-1.4465\n",
            " step 900/1535 | recon=0.0117 dz=-2.4183 dy=-0.3598 gen=-1.5296\n",
            " step 1000/1535 | recon=0.0110 dz=-2.4203 dy=-0.3642 gen=-1.0899\n",
            " step 1100/1535 | recon=0.0116 dz=-2.5534 dy=-0.3313 gen=-1.3083\n",
            " step 1200/1535 | recon=0.0120 dz=-2.4210 dy=-0.3750 gen=-1.4101\n",
            " step 1300/1535 | recon=0.0119 dz=-2.5379 dy=-0.3302 gen=-1.2826\n",
            " step 1400/1535 | recon=0.0106 dz=-2.5453 dy=-0.3913 gen=-1.1092\n",
            " step 1500/1535 | recon=0.0115 dz=-2.3058 dy=-0.3414 gen=-1.3467\n",
            "[TRAIN] Epoch 7/30\n",
            " step 0/1535 | recon=0.0138 dz=-2.0109 dy=-0.4098 gen=-1.4717\n",
            " step 100/1535 | recon=0.0111 dz=-2.5617 dy=-0.4430 gen=-1.8267\n",
            " step 200/1535 | recon=0.0122 dz=-2.5704 dy=-0.3414 gen=-2.0961\n",
            " step 300/1535 | recon=0.0119 dz=-2.4800 dy=-0.3212 gen=-1.8718\n",
            " step 400/1535 | recon=0.0125 dz=-2.3521 dy=-0.3215 gen=-1.9595\n",
            " step 500/1535 | recon=0.0117 dz=-2.4099 dy=-0.3767 gen=-1.8916\n",
            " step 600/1535 | recon=0.0120 dz=-2.5161 dy=-0.3682 gen=-1.8375\n",
            " step 700/1535 | recon=0.0121 dz=-2.3927 dy=-0.3667 gen=-1.6924\n",
            " step 800/1535 | recon=0.0109 dz=-2.7468 dy=-0.3737 gen=-1.2195\n",
            " step 900/1535 | recon=0.0112 dz=-2.4101 dy=-0.3141 gen=-1.3270\n",
            " step 1000/1535 | recon=0.0109 dz=-2.4356 dy=-0.3648 gen=-1.0154\n",
            " step 1100/1535 | recon=0.0112 dz=-2.2579 dy=-0.3375 gen=-1.1119\n",
            " step 1200/1535 | recon=0.0106 dz=-2.5377 dy=-0.3374 gen=-1.1678\n",
            " step 1300/1535 | recon=0.0103 dz=-2.4087 dy=-0.3352 gen=-1.1984\n",
            " step 1400/1535 | recon=0.0103 dz=-2.3883 dy=-0.3747 gen=-1.1396\n",
            " step 1500/1535 | recon=0.0101 dz=-2.4851 dy=-0.3361 gen=-0.9868\n",
            "[TRAIN] Epoch 8/30\n",
            " step 0/1535 | recon=0.0140 dz=-2.2453 dy=-0.3631 gen=-1.4289\n",
            " step 100/1535 | recon=0.0119 dz=-2.5732 dy=-0.4087 gen=-1.7072\n",
            " step 200/1535 | recon=0.0121 dz=-2.4701 dy=-0.3635 gen=-2.0985\n",
            " step 300/1535 | recon=0.0113 dz=-2.6812 dy=-0.3641 gen=-2.0276\n",
            " step 400/1535 | recon=0.0127 dz=-2.4719 dy=-0.4102 gen=-1.9155\n",
            " step 500/1535 | recon=0.0118 dz=-2.6909 dy=-0.4253 gen=-1.5994\n",
            " step 600/1535 | recon=0.0122 dz=-2.4317 dy=-0.4474 gen=-1.8040\n",
            " step 700/1535 | recon=0.0112 dz=-2.5844 dy=-0.4224 gen=-1.4815\n",
            " step 800/1535 | recon=0.0110 dz=-2.6866 dy=-0.3568 gen=-1.2774\n",
            " step 900/1535 | recon=0.0105 dz=-2.6505 dy=-0.3475 gen=-1.4126\n",
            " step 1000/1535 | recon=0.0103 dz=-2.6293 dy=-0.4022 gen=-1.2011\n",
            " step 1100/1535 | recon=0.0105 dz=-2.5285 dy=-0.3718 gen=-1.3538\n",
            " step 1200/1535 | recon=0.0109 dz=-2.4892 dy=-0.3355 gen=-1.2967\n",
            " step 1300/1535 | recon=0.0101 dz=-2.5632 dy=-0.4046 gen=-1.1198\n",
            " step 1400/1535 | recon=0.0100 dz=-2.4453 dy=-0.3876 gen=-1.3185\n",
            " step 1500/1535 | recon=0.0097 dz=-2.2652 dy=-0.4288 gen=-1.3560\n",
            "[TRAIN] Epoch 9/30\n",
            " step 0/1535 | recon=0.0129 dz=-2.1534 dy=-0.3117 gen=-1.6272\n",
            " step 100/1535 | recon=0.0113 dz=-2.4024 dy=-0.4231 gen=-1.9717\n",
            " step 200/1535 | recon=0.0112 dz=-2.6403 dy=-0.4271 gen=-1.9561\n",
            " step 300/1535 | recon=0.0112 dz=-2.6483 dy=-0.4308 gen=-1.8666\n",
            " step 400/1535 | recon=0.0108 dz=-2.6591 dy=-0.3470 gen=-1.8757\n",
            " step 500/1535 | recon=0.0109 dz=-2.7274 dy=-0.4043 gen=-1.6438\n",
            " step 600/1535 | recon=0.0111 dz=-2.6039 dy=-0.3721 gen=-1.5791\n",
            " step 700/1535 | recon=0.0105 dz=-2.5660 dy=-0.4080 gen=-1.4185\n",
            " step 800/1535 | recon=0.0104 dz=-2.4479 dy=-0.3736 gen=-1.3267\n",
            " step 900/1535 | recon=0.0097 dz=-2.6056 dy=-0.3543 gen=-1.3277\n",
            " step 1000/1535 | recon=0.0100 dz=-2.6004 dy=-0.4028 gen=-1.0334\n",
            " step 1100/1535 | recon=0.0097 dz=-2.6828 dy=-0.3390 gen=-1.1128\n",
            " step 1200/1535 | recon=0.0105 dz=-2.5735 dy=-0.3916 gen=-1.1152\n",
            " step 1300/1535 | recon=0.0095 dz=-2.5425 dy=-0.3529 gen=-1.0766\n",
            " step 1400/1535 | recon=0.0092 dz=-2.5658 dy=-0.3546 gen=-1.1496\n",
            " step 1500/1535 | recon=0.0097 dz=-2.7208 dy=-0.3514 gen=-1.0092\n",
            "[TRAIN] Epoch 10/30\n",
            " step 0/1535 | recon=0.0124 dz=-2.1003 dy=-0.3245 gen=-1.5633\n",
            " step 100/1535 | recon=0.0110 dz=-2.6210 dy=-0.3192 gen=-1.7769\n",
            " step 200/1535 | recon=0.0102 dz=-2.6165 dy=-0.3481 gen=-1.8011\n",
            " step 300/1535 | recon=0.0107 dz=-2.5863 dy=-0.3337 gen=-1.9497\n",
            " step 400/1535 | recon=0.0111 dz=-2.3790 dy=-0.3391 gen=-1.8220\n",
            " step 500/1535 | recon=0.0102 dz=-2.5624 dy=-0.3338 gen=-1.7942\n",
            " step 600/1535 | recon=0.0107 dz=-2.6955 dy=-0.3306 gen=-1.6130\n",
            " step 700/1535 | recon=0.0098 dz=-2.9890 dy=-0.2820 gen=-1.5862\n",
            " step 800/1535 | recon=0.0096 dz=-2.7351 dy=-0.3049 gen=-1.4302\n",
            " step 900/1535 | recon=0.0096 dz=-2.7563 dy=-0.3247 gen=-1.2065\n",
            " step 1000/1535 | recon=0.0096 dz=-2.4691 dy=-0.3216 gen=-1.2802\n",
            " step 1100/1535 | recon=0.0103 dz=-2.5471 dy=-0.3070 gen=-1.2713\n",
            " step 1200/1535 | recon=0.0096 dz=-2.6006 dy=-0.2647 gen=-1.3971\n",
            " step 1300/1535 | recon=0.0086 dz=-2.6760 dy=-0.3098 gen=-1.2588\n",
            " step 1400/1535 | recon=0.0095 dz=-2.6285 dy=-0.3170 gen=-1.2020\n",
            " step 1500/1535 | recon=0.0093 dz=-2.6112 dy=-0.3191 gen=-1.2018\n",
            "[TRAIN] Epoch 11/30\n",
            " step 0/1535 | recon=0.0097 dz=-2.1115 dy=-0.3872 gen=-1.3057\n",
            " step 100/1535 | recon=0.0109 dz=-2.2916 dy=-0.3117 gen=-2.0122\n",
            " step 200/1535 | recon=0.0107 dz=-2.6759 dy=-0.3235 gen=-1.9149\n",
            " step 300/1535 | recon=0.0099 dz=-2.7020 dy=-0.3334 gen=-1.9198\n",
            " step 400/1535 | recon=0.0100 dz=-2.4706 dy=-0.3215 gen=-1.9495\n",
            " step 500/1535 | recon=0.0107 dz=-2.5858 dy=-0.3279 gen=-1.9195\n",
            " step 600/1535 | recon=0.0096 dz=-2.5794 dy=-0.3018 gen=-2.0832\n",
            " step 700/1535 | recon=0.0097 dz=-2.7441 dy=-0.3239 gen=-1.9154\n",
            " step 800/1535 | recon=0.0097 dz=-2.8125 dy=-0.2844 gen=-1.6214\n",
            " step 900/1535 | recon=0.0090 dz=-2.7556 dy=-0.3027 gen=-1.4688\n",
            " step 1000/1535 | recon=0.0098 dz=-2.5494 dy=-0.3199 gen=-1.7523\n",
            " step 1100/1535 | recon=0.0091 dz=-2.6565 dy=-0.3006 gen=-1.6759\n",
            " step 1200/1535 | recon=0.0095 dz=-2.5719 dy=-0.2855 gen=-1.7852\n",
            " step 1300/1535 | recon=0.0085 dz=-2.7284 dy=-0.2577 gen=-1.7097\n",
            " step 1400/1535 | recon=0.0091 dz=-2.5230 dy=-0.2613 gen=-1.6884\n",
            " step 1500/1535 | recon=0.0085 dz=-2.4250 dy=-0.3069 gen=-1.6745\n",
            "[TRAIN] Epoch 12/30\n",
            " step 0/1535 | recon=0.0110 dz=-2.0587 dy=-0.2997 gen=-1.9527\n",
            " step 100/1535 | recon=0.0100 dz=-2.7137 dy=-0.2927 gen=-2.1047\n",
            " step 200/1535 | recon=0.0102 dz=-2.7435 dy=-0.2980 gen=-2.0667\n",
            " step 300/1535 | recon=0.0095 dz=-2.8018 dy=-0.2780 gen=-2.0589\n",
            " step 400/1535 | recon=0.0097 dz=-2.6797 dy=-0.2902 gen=-2.1186\n",
            " step 500/1535 | recon=0.0097 dz=-2.6478 dy=-0.2891 gen=-2.1365\n",
            " step 600/1535 | recon=0.0094 dz=-2.6791 dy=-0.2923 gen=-1.9778\n",
            " step 700/1535 | recon=0.0096 dz=-2.7404 dy=-0.2726 gen=-2.1403\n",
            " step 800/1535 | recon=0.0085 dz=-2.5907 dy=-0.2938 gen=-1.9584\n",
            " step 900/1535 | recon=0.0087 dz=-2.5628 dy=-0.3051 gen=-1.8383\n",
            " step 1000/1535 | recon=0.0084 dz=-2.7364 dy=-0.3104 gen=-1.7659\n",
            " step 1100/1535 | recon=0.0093 dz=-2.7160 dy=-0.2920 gen=-1.7772\n",
            " step 1200/1535 | recon=0.0087 dz=-2.5646 dy=-0.3053 gen=-1.8698\n",
            " step 1300/1535 | recon=0.0093 dz=-2.5102 dy=-0.2735 gen=-1.9680\n",
            " step 1400/1535 | recon=0.0087 dz=-2.6869 dy=-0.2922 gen=-1.7659\n",
            " step 1500/1535 | recon=0.0086 dz=-2.5731 dy=-0.3083 gen=-1.8197\n",
            "[TRAIN] Epoch 13/30\n",
            " step 0/1535 | recon=0.0104 dz=-2.3279 dy=-0.2985 gen=-2.0259\n",
            " step 100/1535 | recon=0.0099 dz=-2.7023 dy=-0.3125 gen=-2.4147\n",
            " step 200/1535 | recon=0.0111 dz=-2.7484 dy=-0.3036 gen=-2.1950\n",
            " step 300/1535 | recon=0.0105 dz=-2.6250 dy=-0.2670 gen=-2.4244\n",
            " step 400/1535 | recon=0.0096 dz=-2.5405 dy=-0.3162 gen=-2.2365\n",
            " step 500/1535 | recon=0.0104 dz=-2.6250 dy=-0.3265 gen=-2.3215\n",
            " step 600/1535 | recon=0.0092 dz=-2.5421 dy=-0.3030 gen=-2.3993\n",
            " step 700/1535 | recon=0.0083 dz=-2.7671 dy=-0.2922 gen=-2.1957\n",
            " step 800/1535 | recon=0.0086 dz=-2.7626 dy=-0.2527 gen=-2.1503\n",
            " step 900/1535 | recon=0.0082 dz=-2.9276 dy=-0.2908 gen=-1.9464\n",
            " step 1000/1535 | recon=0.0085 dz=-2.5501 dy=-0.3041 gen=-2.0533\n",
            " step 1100/1535 | recon=0.0087 dz=-2.6871 dy=-0.2867 gen=-2.0514\n",
            " step 1200/1535 | recon=0.0085 dz=-2.7659 dy=-0.2733 gen=-1.8945\n",
            " step 1300/1535 | recon=0.0083 dz=-2.6349 dy=-0.3272 gen=-1.8822\n",
            " step 1400/1535 | recon=0.0083 dz=-2.2653 dy=-0.2851 gen=-2.0847\n",
            " step 1500/1535 | recon=0.0074 dz=-2.8186 dy=-0.2761 gen=-1.8099\n",
            "[TRAIN] Epoch 14/30\n",
            " step 0/1535 | recon=0.0111 dz=-2.0869 dy=-0.3133 gen=-2.3875\n",
            " step 100/1535 | recon=0.0099 dz=-2.5985 dy=-0.3540 gen=-2.1579\n",
            " step 200/1535 | recon=0.0089 dz=-2.5396 dy=-0.3403 gen=-2.3943\n",
            " step 300/1535 | recon=0.0089 dz=-2.7231 dy=-0.2928 gen=-2.4465\n",
            " step 400/1535 | recon=0.0098 dz=-2.7591 dy=-0.3005 gen=-2.3986\n",
            " step 500/1535 | recon=0.0092 dz=-2.5354 dy=-0.3073 gen=-2.2509\n",
            " step 600/1535 | recon=0.0091 dz=-2.8497 dy=-0.3037 gen=-2.2874\n",
            " step 700/1535 | recon=0.0095 dz=-2.6017 dy=-0.2742 gen=-2.4671\n",
            " step 800/1535 | recon=0.0087 dz=-2.5937 dy=-0.2919 gen=-2.4354\n",
            " step 900/1535 | recon=0.0080 dz=-2.6274 dy=-0.2934 gen=-2.2247\n",
            " step 1000/1535 | recon=0.0081 dz=-2.6392 dy=-0.3010 gen=-1.9900\n",
            " step 1100/1535 | recon=0.0084 dz=-2.4648 dy=-0.2802 gen=-2.1181\n",
            " step 1200/1535 | recon=0.0085 dz=-2.7217 dy=-0.2862 gen=-2.1175\n",
            " step 1300/1535 | recon=0.0088 dz=-2.3899 dy=-0.2464 gen=-2.3456\n",
            " step 1400/1535 | recon=0.0082 dz=-2.6215 dy=-0.3262 gen=-2.0154\n",
            " step 1500/1535 | recon=0.0081 dz=-2.5524 dy=-0.2829 gen=-2.1263\n",
            "[TRAIN] Epoch 15/30\n",
            " step 0/1535 | recon=0.0100 dz=-2.4786 dy=-0.2825 gen=-2.2983\n",
            " step 100/1535 | recon=0.0086 dz=-2.8781 dy=-0.3149 gen=-2.3734\n",
            " step 200/1535 | recon=0.0092 dz=-2.4772 dy=-0.2952 gen=-2.5736\n",
            " step 300/1535 | recon=0.0099 dz=-2.2413 dy=-0.2956 gen=-2.7674\n",
            " step 400/1535 | recon=0.0089 dz=-2.5639 dy=-0.3305 gen=-2.3485\n",
            " step 500/1535 | recon=0.0095 dz=-2.7520 dy=-0.2961 gen=-2.5346\n",
            " step 600/1535 | recon=0.0086 dz=-2.6919 dy=-0.3176 gen=-2.4160\n",
            " step 700/1535 | recon=0.0086 dz=-2.6786 dy=-0.2930 gen=-2.5596\n",
            " step 800/1535 | recon=0.0083 dz=-2.4820 dy=-0.3029 gen=-2.4420\n",
            " step 900/1535 | recon=0.0083 dz=-2.7371 dy=-0.2907 gen=-2.2886\n",
            " step 1000/1535 | recon=0.0083 dz=-2.5418 dy=-0.3130 gen=-2.0841\n",
            " step 1100/1535 | recon=0.0081 dz=-2.6074 dy=-0.2519 gen=-2.1925\n",
            " step 1200/1535 | recon=0.0081 dz=-2.6505 dy=-0.2849 gen=-1.9543\n",
            " step 1300/1535 | recon=0.0086 dz=-2.5838 dy=-0.2920 gen=-2.0569\n",
            " step 1400/1535 | recon=0.0079 dz=-2.4016 dy=-0.3027 gen=-2.0507\n",
            " step 1500/1535 | recon=0.0076 dz=-2.5336 dy=-0.2646 gen=-1.8723\n",
            "[TRAIN] Epoch 16/30\n",
            " step 0/1535 | recon=0.0091 dz=-2.2489 dy=-0.2802 gen=-2.1485\n",
            " step 100/1535 | recon=0.0091 dz=-2.6300 dy=-0.2833 gen=-2.3346\n",
            " step 200/1535 | recon=0.0090 dz=-2.6703 dy=-0.3266 gen=-2.1302\n",
            " step 300/1535 | recon=0.0091 dz=-2.3334 dy=-0.3069 gen=-2.5021\n",
            " step 400/1535 | recon=0.0081 dz=-2.6542 dy=-0.2906 gen=-2.4674\n",
            " step 500/1535 | recon=0.0087 dz=-2.7991 dy=-0.3435 gen=-2.3058\n",
            " step 600/1535 | recon=0.0077 dz=-2.7292 dy=-0.3083 gen=-2.3192\n",
            " step 700/1535 | recon=0.0090 dz=-2.5221 dy=-0.3011 gen=-2.4364\n",
            " step 800/1535 | recon=0.0080 dz=-2.4150 dy=-0.3021 gen=-2.0976\n",
            " step 900/1535 | recon=0.0074 dz=-2.6021 dy=-0.2736 gen=-2.1917\n",
            " step 1000/1535 | recon=0.0076 dz=-2.7111 dy=-0.2835 gen=-2.0594\n",
            " step 1100/1535 | recon=0.0081 dz=-2.7616 dy=-0.2927 gen=-1.9082\n",
            " step 1200/1535 | recon=0.0080 dz=-2.5307 dy=-0.2995 gen=-2.0757\n",
            " step 1300/1535 | recon=0.0074 dz=-2.3571 dy=-0.2949 gen=-2.1549\n",
            " step 1400/1535 | recon=0.0078 dz=-2.4764 dy=-0.2759 gen=-2.0766\n",
            " step 1500/1535 | recon=0.0073 dz=-2.4171 dy=-0.2647 gen=-2.0469\n",
            "[TRAIN] Epoch 17/30\n",
            " step 0/1535 | recon=0.0083 dz=-2.3657 dy=-0.2972 gen=-2.1571\n",
            " step 100/1535 | recon=0.0094 dz=-2.5086 dy=-0.3066 gen=-2.2346\n",
            " step 200/1535 | recon=0.0097 dz=-2.7844 dy=-0.3077 gen=-2.1696\n",
            " step 300/1535 | recon=0.0085 dz=-2.5059 dy=-0.3119 gen=-2.2829\n",
            " step 400/1535 | recon=0.0082 dz=-2.5870 dy=-0.3217 gen=-2.3654\n",
            " step 500/1535 | recon=0.0085 dz=-2.6609 dy=-0.2633 gen=-2.5181\n",
            " step 600/1535 | recon=0.0089 dz=-2.6260 dy=-0.3094 gen=-2.2329\n",
            " step 700/1535 | recon=0.0081 dz=-2.6797 dy=-0.2957 gen=-2.3850\n",
            " step 800/1535 | recon=0.0082 dz=-2.7187 dy=-0.2563 gen=-2.1984\n",
            " step 900/1535 | recon=0.0079 dz=-2.6974 dy=-0.2789 gen=-2.0244\n",
            " step 1000/1535 | recon=0.0073 dz=-2.6731 dy=-0.2627 gen=-2.0419\n",
            " step 1100/1535 | recon=0.0079 dz=-2.6524 dy=-0.2753 gen=-1.9988\n",
            " step 1200/1535 | recon=0.0077 dz=-2.7594 dy=-0.2615 gen=-1.9126\n",
            " step 1300/1535 | recon=0.0074 dz=-2.6522 dy=-0.3103 gen=-1.8996\n",
            " step 1400/1535 | recon=0.0077 dz=-2.6366 dy=-0.2681 gen=-2.0475\n",
            " step 1500/1535 | recon=0.0080 dz=-2.5505 dy=-0.2912 gen=-1.9691\n",
            "[TRAIN] Epoch 18/30\n",
            " step 0/1535 | recon=0.0089 dz=-2.4408 dy=-0.2842 gen=-2.0925\n",
            " step 100/1535 | recon=0.0096 dz=-2.3115 dy=-0.3265 gen=-2.2318\n",
            " step 200/1535 | recon=0.0086 dz=-2.3802 dy=-0.3349 gen=-2.1685\n",
            " step 300/1535 | recon=0.0078 dz=-2.6618 dy=-0.2730 gen=-2.1555\n",
            " step 400/1535 | recon=0.0085 dz=-2.6105 dy=-0.3011 gen=-2.2834\n",
            " step 500/1535 | recon=0.0081 dz=-2.6821 dy=-0.2948 gen=-2.2182\n",
            " step 600/1535 | recon=0.0079 dz=-2.9516 dy=-0.2795 gen=-2.1714\n",
            " step 700/1535 | recon=0.0076 dz=-2.7239 dy=-0.2628 gen=-2.1271\n",
            " step 800/1535 | recon=0.0076 dz=-2.7913 dy=-0.2578 gen=-2.1379\n",
            " step 900/1535 | recon=0.0073 dz=-2.7013 dy=-0.2710 gen=-2.1200\n",
            " step 1000/1535 | recon=0.0070 dz=-2.5693 dy=-0.2774 gen=-2.0675\n",
            " step 1100/1535 | recon=0.0072 dz=-2.5822 dy=-0.2574 gen=-1.9964\n",
            " step 1200/1535 | recon=0.0073 dz=-2.6588 dy=-0.2572 gen=-2.0114\n",
            " step 1300/1535 | recon=0.0076 dz=-2.3558 dy=-0.2789 gen=-1.9378\n",
            " step 1400/1535 | recon=0.0070 dz=-2.5482 dy=-0.2831 gen=-1.7977\n",
            " step 1500/1535 | recon=0.0071 dz=-2.7445 dy=-0.2608 gen=-1.7914\n",
            "[TRAIN] Epoch 19/30\n",
            " step 0/1535 | recon=0.0093 dz=-2.2710 dy=-0.2840 gen=-2.3090\n",
            " step 100/1535 | recon=0.0081 dz=-2.6916 dy=-0.2940 gen=-2.0536\n",
            " step 200/1535 | recon=0.0087 dz=-2.5220 dy=-0.3128 gen=-2.2436\n",
            " step 300/1535 | recon=0.0084 dz=-2.8473 dy=-0.2693 gen=-2.1927\n",
            " step 400/1535 | recon=0.0084 dz=-2.5045 dy=-0.3000 gen=-1.9966\n",
            " step 500/1535 | recon=0.0071 dz=-2.5211 dy=-0.2760 gen=-2.1344\n",
            " step 600/1535 | recon=0.0076 dz=-2.6367 dy=-0.2758 gen=-2.1394\n",
            " step 700/1535 | recon=0.0082 dz=-2.8780 dy=-0.2709 gen=-1.9977\n",
            " step 800/1535 | recon=0.0082 dz=-2.6691 dy=-0.2652 gen=-1.9595\n",
            " step 900/1535 | recon=0.0073 dz=-2.5654 dy=-0.2408 gen=-1.9018\n",
            " step 1000/1535 | recon=0.0067 dz=-2.7051 dy=-0.2842 gen=-1.6925\n",
            " step 1100/1535 | recon=0.0077 dz=-2.7344 dy=-0.2648 gen=-1.7079\n",
            " step 1200/1535 | recon=0.0068 dz=-2.5100 dy=-0.2617 gen=-1.5644\n",
            " step 1300/1535 | recon=0.0072 dz=-2.5077 dy=-0.2551 gen=-1.6504\n",
            " step 1400/1535 | recon=0.0073 dz=-2.6728 dy=-0.2674 gen=-1.5992\n",
            " step 1500/1535 | recon=0.0073 dz=-2.2702 dy=-0.2346 gen=-1.7079\n",
            "[TRAIN] Epoch 20/30\n",
            " step 0/1535 | recon=0.0089 dz=-2.1409 dy=-0.2883 gen=-1.7829\n",
            " step 100/1535 | recon=0.0084 dz=-2.6595 dy=-0.3000 gen=-1.7861\n",
            " step 200/1535 | recon=0.0080 dz=-2.7244 dy=-0.2601 gen=-1.7916\n",
            " step 300/1535 | recon=0.0080 dz=-2.8668 dy=-0.2900 gen=-1.8422\n",
            " step 400/1535 | recon=0.0080 dz=-2.5792 dy=-0.3195 gen=-1.8046\n",
            " step 500/1535 | recon=0.0080 dz=-2.7716 dy=-0.3325 gen=-1.6634\n",
            " step 600/1535 | recon=0.0080 dz=-2.6607 dy=-0.2897 gen=-1.7352\n",
            " step 700/1535 | recon=0.0076 dz=-2.6814 dy=-0.2971 gen=-1.7045\n",
            " step 800/1535 | recon=0.0073 dz=-2.5332 dy=-0.2892 gen=-1.6189\n",
            " step 900/1535 | recon=0.0075 dz=-2.6162 dy=-0.2741 gen=-1.6739\n",
            " step 1000/1535 | recon=0.0073 dz=-2.4459 dy=-0.2695 gen=-1.5136\n",
            " step 1100/1535 | recon=0.0075 dz=-2.6037 dy=-0.2501 gen=-1.6380\n",
            " step 1200/1535 | recon=0.0073 dz=-2.6484 dy=-0.2536 gen=-1.3464\n",
            " step 1300/1535 | recon=0.0067 dz=-2.5539 dy=-0.2786 gen=-1.5267\n",
            " step 1400/1535 | recon=0.0066 dz=-2.7332 dy=-0.2683 gen=-1.4049\n",
            " step 1500/1535 | recon=0.0071 dz=-2.5387 dy=-0.2877 gen=-1.3251\n",
            "[TRAIN] Epoch 21/30\n",
            " step 0/1535 | recon=0.0086 dz=-2.2830 dy=-0.3126 gen=-1.6322\n",
            " step 100/1535 | recon=0.0095 dz=-2.6899 dy=-0.3071 gen=-1.3569\n",
            " step 200/1535 | recon=0.0074 dz=-2.6845 dy=-0.2946 gen=-1.4689\n",
            " step 300/1535 | recon=0.0074 dz=-2.5453 dy=-0.2908 gen=-1.8461\n",
            " step 400/1535 | recon=0.0079 dz=-2.7215 dy=-0.3035 gen=-1.5547\n",
            " step 500/1535 | recon=0.0077 dz=-2.6019 dy=-0.2599 gen=-1.6442\n",
            " step 600/1535 | recon=0.0075 dz=-2.5409 dy=-0.3199 gen=-1.6185\n",
            " step 700/1535 | recon=0.0071 dz=-2.6659 dy=-0.2739 gen=-1.7371\n",
            " step 800/1535 | recon=0.0068 dz=-2.6811 dy=-0.3015 gen=-1.4866\n",
            " step 900/1535 | recon=0.0066 dz=-2.5567 dy=-0.2795 gen=-1.6529\n",
            " step 1000/1535 | recon=0.0068 dz=-2.6280 dy=-0.2759 gen=-1.3300\n",
            " step 1100/1535 | recon=0.0070 dz=-2.5519 dy=-0.2613 gen=-1.4882\n",
            " step 1200/1535 | recon=0.0070 dz=-2.5205 dy=-0.2455 gen=-1.4051\n",
            " step 1300/1535 | recon=0.0068 dz=-2.3731 dy=-0.2593 gen=-1.4194\n",
            " step 1400/1535 | recon=0.0067 dz=-2.2497 dy=-0.2374 gen=-1.4432\n",
            " step 1500/1535 | recon=0.0065 dz=-2.5815 dy=-0.2361 gen=-1.2465\n",
            "[TRAIN] Epoch 22/30\n",
            " step 0/1535 | recon=0.0077 dz=-2.1407 dy=-0.3063 gen=-1.3561\n",
            " step 100/1535 | recon=0.0071 dz=-2.7779 dy=-0.3327 gen=-1.3710\n",
            " step 200/1535 | recon=0.0077 dz=-2.9627 dy=-0.2891 gen=-1.5346\n",
            " step 300/1535 | recon=0.0077 dz=-2.6193 dy=-0.3271 gen=-1.6256\n",
            " step 400/1535 | recon=0.0080 dz=-2.6644 dy=-0.2811 gen=-1.6023\n",
            " step 500/1535 | recon=0.0066 dz=-2.7737 dy=-0.3120 gen=-1.3696\n",
            " step 600/1535 | recon=0.0077 dz=-2.4731 dy=-0.2608 gen=-1.7132\n",
            " step 700/1535 | recon=0.0067 dz=-2.8312 dy=-0.3128 gen=-1.6372\n",
            " step 800/1535 | recon=0.0069 dz=-2.3448 dy=-0.2603 gen=-1.6677\n",
            " step 900/1535 | recon=0.0069 dz=-2.3780 dy=-0.2545 gen=-1.7947\n",
            " step 1000/1535 | recon=0.0073 dz=-2.5605 dy=-0.2470 gen=-1.4806\n",
            " step 1100/1535 | recon=0.0064 dz=-2.6612 dy=-0.2491 gen=-1.4455\n",
            " step 1200/1535 | recon=0.0069 dz=-2.5544 dy=-0.2539 gen=-1.4665\n",
            " step 1300/1535 | recon=0.0070 dz=-2.4766 dy=-0.2964 gen=-1.3036\n",
            " step 1400/1535 | recon=0.0067 dz=-2.4604 dy=-0.2616 gen=-1.4960\n",
            " step 1500/1535 | recon=0.0072 dz=-2.5429 dy=-0.2516 gen=-1.3543\n",
            "[TRAIN] Epoch 23/30\n",
            " step 0/1535 | recon=0.0075 dz=-2.4540 dy=-0.2804 gen=-1.5110\n",
            " step 100/1535 | recon=0.0075 dz=-2.6906 dy=-0.3412 gen=-1.4588\n",
            " step 200/1535 | recon=0.0071 dz=-2.4980 dy=-0.2914 gen=-1.5478\n",
            " step 300/1535 | recon=0.0074 dz=-2.6330 dy=-0.2850 gen=-1.4677\n",
            " step 400/1535 | recon=0.0077 dz=-2.9746 dy=-0.2616 gen=-1.4350\n",
            " step 500/1535 | recon=0.0079 dz=-2.7879 dy=-0.3234 gen=-1.3546\n",
            " step 600/1535 | recon=0.0074 dz=-2.6555 dy=-0.2916 gen=-1.5797\n",
            " step 700/1535 | recon=0.0076 dz=-2.5291 dy=-0.2813 gen=-1.6909\n",
            " step 800/1535 | recon=0.0074 dz=-2.4875 dy=-0.2729 gen=-1.5474\n",
            " step 900/1535 | recon=0.0068 dz=-2.5871 dy=-0.2562 gen=-1.5539\n",
            " step 1000/1535 | recon=0.0065 dz=-2.6919 dy=-0.2554 gen=-1.2169\n",
            " step 1100/1535 | recon=0.0062 dz=-2.6405 dy=-0.2598 gen=-1.2895\n",
            " step 1200/1535 | recon=0.0066 dz=-2.7347 dy=-0.2784 gen=-1.4036\n",
            " step 1300/1535 | recon=0.0066 dz=-2.6349 dy=-0.2900 gen=-1.3191\n",
            " step 1400/1535 | recon=0.0063 dz=-2.6016 dy=-0.2662 gen=-1.2755\n",
            " step 1500/1535 | recon=0.0065 dz=-2.4244 dy=-0.2487 gen=-1.3543\n",
            "[TRAIN] Epoch 24/30\n",
            " step 0/1535 | recon=0.0082 dz=-2.2522 dy=-0.2919 gen=-1.5003\n",
            " step 100/1535 | recon=0.0079 dz=-2.8328 dy=-0.3056 gen=-1.2611\n",
            " step 200/1535 | recon=0.0084 dz=-2.7739 dy=-0.2873 gen=-1.5201\n",
            " step 300/1535 | recon=0.0075 dz=-2.7310 dy=-0.2822 gen=-1.5994\n",
            " step 400/1535 | recon=0.0072 dz=-2.7318 dy=-0.2682 gen=-1.5337\n",
            " step 500/1535 | recon=0.0067 dz=-2.8530 dy=-0.3457 gen=-1.3716\n",
            " step 600/1535 | recon=0.0068 dz=-2.7217 dy=-0.2854 gen=-1.4772\n",
            " step 700/1535 | recon=0.0059 dz=-2.8228 dy=-0.2572 gen=-1.4357\n",
            " step 800/1535 | recon=0.0072 dz=-2.6175 dy=-0.2643 gen=-1.4507\n",
            " step 900/1535 | recon=0.0065 dz=-2.8700 dy=-0.2569 gen=-1.3686\n",
            " step 1000/1535 | recon=0.0062 dz=-2.7519 dy=-0.2642 gen=-1.4914\n",
            " step 1100/1535 | recon=0.0062 dz=-2.6249 dy=-0.2475 gen=-1.5422\n",
            " step 1200/1535 | recon=0.0065 dz=-2.6835 dy=-0.2660 gen=-1.6214\n",
            " step 1300/1535 | recon=0.0068 dz=-2.4517 dy=-0.2367 gen=-1.6032\n",
            " step 1400/1535 | recon=0.0059 dz=-2.6296 dy=-0.2736 gen=-1.5244\n",
            " step 1500/1535 | recon=0.0062 dz=-2.4066 dy=-0.2601 gen=-1.4318\n",
            "[TRAIN] Epoch 25/30\n",
            " step 0/1535 | recon=0.0072 dz=-2.0178 dy=-0.2698 gen=-2.0903\n",
            " step 100/1535 | recon=0.0076 dz=-2.3614 dy=-0.2537 gen=-1.7936\n",
            " step 200/1535 | recon=0.0074 dz=-2.8283 dy=-0.3291 gen=-1.5314\n",
            " step 300/1535 | recon=0.0068 dz=-2.7095 dy=-0.3078 gen=-1.8580\n",
            " step 400/1535 | recon=0.0070 dz=-2.6380 dy=-0.2853 gen=-1.7006\n",
            " step 500/1535 | recon=0.0069 dz=-2.5906 dy=-0.2421 gen=-2.4060\n",
            " step 600/1535 | recon=0.0065 dz=-2.8333 dy=-0.2660 gen=-1.9351\n",
            " step 700/1535 | recon=0.0067 dz=-2.4809 dy=-0.2738 gen=-1.7900\n",
            " step 800/1535 | recon=0.0070 dz=-2.5707 dy=-0.2405 gen=-2.1299\n",
            " step 900/1535 | recon=0.0064 dz=-2.3496 dy=-0.2507 gen=-2.2495\n",
            " step 1000/1535 | recon=0.0072 dz=-2.1651 dy=-0.2710 gen=-2.1752\n",
            " step 1100/1535 | recon=0.0062 dz=-2.5493 dy=-0.2170 gen=-2.5751\n",
            " step 1200/1535 | recon=0.0067 dz=-2.5303 dy=-0.2816 gen=-2.0902\n",
            " step 1300/1535 | recon=0.0057 dz=-2.6285 dy=-0.2319 gen=-2.3173\n",
            " step 1400/1535 | recon=0.0061 dz=-2.5148 dy=-0.2211 gen=-2.3214\n",
            " step 1500/1535 | recon=0.0066 dz=-2.2777 dy=-0.2486 gen=-2.6516\n",
            "[TRAIN] Epoch 26/30\n",
            " step 0/1535 | recon=0.0073 dz=-2.0645 dy=-0.3007 gen=-2.7699\n",
            " step 100/1535 | recon=0.0073 dz=-2.4467 dy=-0.2897 gen=-2.1235\n",
            " step 200/1535 | recon=0.0076 dz=-2.4182 dy=-0.2609 gen=-1.9344\n",
            " step 300/1535 | recon=0.0073 dz=-2.3342 dy=-0.3356 gen=-2.5253\n",
            " step 400/1535 | recon=0.0069 dz=-2.3649 dy=-0.3071 gen=-2.1411\n",
            " step 500/1535 | recon=0.0074 dz=-2.4097 dy=-0.3259 gen=-2.6584\n",
            " step 600/1535 | recon=0.0068 dz=-2.2233 dy=-0.2677 gen=-3.0864\n",
            " step 700/1535 | recon=0.0076 dz=-2.1030 dy=-0.2678 gen=-3.2834\n",
            " step 800/1535 | recon=0.0063 dz=-2.3539 dy=-0.2491 gen=-3.0741\n",
            " step 900/1535 | recon=0.0069 dz=-2.0311 dy=-0.2706 gen=-2.9739\n",
            " step 1000/1535 | recon=0.0060 dz=-2.2300 dy=-0.2689 gen=-2.5775\n",
            " step 1100/1535 | recon=0.0064 dz=-1.8732 dy=-0.2864 gen=-2.4672\n",
            " step 1200/1535 | recon=0.0064 dz=-1.6978 dy=-0.2611 gen=-3.1091\n",
            " step 1300/1535 | recon=0.0066 dz=-1.6172 dy=-0.2670 gen=-2.3862\n",
            " step 1400/1535 | recon=0.0058 dz=-1.4802 dy=-0.2640 gen=-2.5832\n",
            " step 1500/1535 | recon=0.0060 dz=-1.4638 dy=-0.2701 gen=-2.7294\n",
            "[TRAIN] Epoch 27/30\n",
            " step 0/1535 | recon=0.0070 dz=-1.3687 dy=-0.2662 gen=-2.8215\n",
            " step 100/1535 | recon=0.0070 dz=-1.3864 dy=-0.3035 gen=-2.4088\n",
            " step 200/1535 | recon=0.0074 dz=-1.5109 dy=-0.3157 gen=-2.1802\n",
            " step 300/1535 | recon=0.0072 dz=-1.0958 dy=-0.3100 gen=-2.2371\n",
            " step 400/1535 | recon=0.0068 dz=-1.2602 dy=-0.2959 gen=-1.9788\n",
            " step 500/1535 | recon=0.0070 dz=-1.0826 dy=-0.2925 gen=-1.8226\n",
            " step 600/1535 | recon=0.0061 dz=-1.2341 dy=-0.2707 gen=-1.7595\n",
            " step 700/1535 | recon=0.0068 dz=-1.3546 dy=-0.3013 gen=-2.0021\n",
            " step 800/1535 | recon=0.0061 dz=-0.9548 dy=-0.2740 gen=-2.1635\n",
            " step 900/1535 | recon=0.0065 dz=-0.8326 dy=-0.2431 gen=-2.0936\n",
            " step 1000/1535 | recon=0.0062 dz=-0.9787 dy=-0.2255 gen=-1.5570\n",
            " step 1100/1535 | recon=0.0056 dz=-0.7884 dy=-0.2579 gen=-1.8530\n",
            " step 1200/1535 | recon=0.0059 dz=-0.7588 dy=-0.2599 gen=-1.5988\n",
            " step 1300/1535 | recon=0.0060 dz=-0.4662 dy=-0.2864 gen=-1.4489\n",
            " step 1400/1535 | recon=0.0061 dz=-0.7344 dy=-0.2499 gen=-1.6654\n",
            " step 1500/1535 | recon=0.0059 dz=-0.7299 dy=-0.2650 gen=-1.3231\n",
            "[TRAIN] Epoch 28/30\n",
            " step 0/1535 | recon=0.0068 dz=-0.4174 dy=-0.2903 gen=-2.0612\n",
            " step 100/1535 | recon=0.0070 dz=-0.7126 dy=-0.2853 gen=-1.1806\n",
            " step 200/1535 | recon=0.0067 dz=-0.6506 dy=-0.2899 gen=-0.9515\n",
            " step 300/1535 | recon=0.0078 dz=-0.6643 dy=-0.3388 gen=-1.0118\n",
            " step 400/1535 | recon=0.0065 dz=-0.4581 dy=-0.2976 gen=-0.9765\n",
            " step 500/1535 | recon=0.0073 dz=-0.4627 dy=-0.2676 gen=-1.3144\n",
            " step 600/1535 | recon=0.0068 dz=-0.3917 dy=-0.2504 gen=-1.2666\n",
            " step 700/1535 | recon=0.0072 dz=-0.3992 dy=-0.2920 gen=-1.3173\n",
            " step 800/1535 | recon=0.0060 dz=-0.3600 dy=-0.2624 gen=-0.9483\n",
            " step 900/1535 | recon=0.0064 dz=-0.5451 dy=-0.2556 gen=-1.3526\n",
            " step 1000/1535 | recon=0.0060 dz=-0.6792 dy=-0.2487 gen=-1.3830\n",
            " step 1100/1535 | recon=0.0059 dz=-0.4200 dy=-0.2720 gen=-0.9855\n",
            " step 1200/1535 | recon=0.0056 dz=-0.5162 dy=-0.2572 gen=-1.3064\n",
            " step 1300/1535 | recon=0.0065 dz=-0.3925 dy=-0.2462 gen=-1.1663\n",
            " step 1400/1535 | recon=0.0060 dz=-0.5302 dy=-0.2473 gen=-1.4681\n",
            " step 1500/1535 | recon=0.0054 dz=-0.5270 dy=-0.2368 gen=-1.1894\n",
            "[TRAIN] Epoch 29/30\n",
            " step 0/1535 | recon=0.0070 dz=-0.1696 dy=-0.2475 gen=-1.3780\n",
            " step 100/1535 | recon=0.0065 dz=-0.3583 dy=-0.3268 gen=-0.9788\n",
            " step 200/1535 | recon=0.0075 dz=-0.3604 dy=-0.2787 gen=-0.9659\n",
            " step 300/1535 | recon=0.0068 dz=-0.3840 dy=-0.3123 gen=-0.6785\n",
            " step 400/1535 | recon=0.0063 dz=-0.2819 dy=-0.3005 gen=-0.7255\n",
            " step 500/1535 | recon=0.0059 dz=-0.3910 dy=-0.2641 gen=-0.5911\n",
            " step 600/1535 | recon=0.0063 dz=-0.1399 dy=-0.2959 gen=-0.5375\n",
            " step 700/1535 | recon=0.0066 dz=-0.1372 dy=-0.3159 gen=-0.4047\n",
            " step 800/1535 | recon=0.0059 dz=-0.3100 dy=-0.2706 gen=-0.6932\n",
            " step 900/1535 | recon=0.0061 dz=-0.4661 dy=-0.2331 gen=-0.7308\n",
            " step 1000/1535 | recon=0.0062 dz=-0.3239 dy=-0.2278 gen=-0.9845\n",
            " step 1100/1535 | recon=0.0059 dz=-0.4172 dy=-0.2201 gen=-0.5847\n",
            " step 1200/1535 | recon=0.0065 dz=-0.2326 dy=-0.2436 gen=-1.0032\n",
            " step 1300/1535 | recon=0.0056 dz=-0.2128 dy=-0.2551 gen=-0.9342\n",
            " step 1400/1535 | recon=0.0065 dz=-0.4016 dy=-0.2092 gen=-1.1242\n",
            " step 1500/1535 | recon=0.0058 dz=-0.3002 dy=-0.2384 gen=-1.0294\n",
            "[TRAIN] Epoch 30/30\n",
            " step 0/1535 | recon=0.0070 dz=-0.0187 dy=-0.2290 gen=-1.3939\n",
            " step 100/1535 | recon=0.0067 dz=-0.4295 dy=-0.2868 gen=-0.7465\n",
            " step 200/1535 | recon=0.0064 dz=-0.3192 dy=-0.2663 gen=-1.0980\n",
            " step 300/1535 | recon=0.0065 dz=-0.3107 dy=-0.2537 gen=-0.7689\n",
            " step 400/1535 | recon=0.0065 dz=-0.2606 dy=-0.3102 gen=-0.6487\n",
            " step 500/1535 | recon=0.0066 dz=-0.1484 dy=-0.2660 gen=-0.4742\n",
            " step 600/1535 | recon=0.0056 dz=-0.1870 dy=-0.2791 gen=-0.4582\n",
            " step 700/1535 | recon=0.0063 dz=0.0509 dy=-0.2704 gen=-0.4639\n",
            " step 800/1535 | recon=0.0069 dz=-0.3427 dy=-0.2147 gen=-0.4143\n",
            " step 900/1535 | recon=0.0063 dz=-0.2805 dy=-0.2458 gen=-0.2636\n",
            " step 1000/1535 | recon=0.0059 dz=-0.1825 dy=-0.2128 gen=-0.3300\n",
            " step 1100/1535 | recon=0.0063 dz=-0.2540 dy=-0.2269 gen=-0.2933\n",
            " step 1200/1535 | recon=0.0054 dz=-0.2936 dy=-0.2176 gen=-0.4657\n",
            " step 1300/1535 | recon=0.0060 dz=-0.0802 dy=-0.2470 gen=-0.3573\n",
            " step 1400/1535 | recon=0.0059 dz=-0.2499 dy=-0.2080 gen=-0.5391\n",
            " step 1500/1535 | recon=0.0053 dz=-0.3270 dy=-0.1999 gen=-0.6664\n",
            "[SAVE] Encoder & decoder saved\n",
            "[RESULT] ROC AUC: 0.9820, Thr: 0.015617, TPR: 0.948, FPR: 0.058\n",
            "[RESULT] Confusion Matrix:\n",
            "[[39695  2427]\n",
            " [ 1208 21783]]\n",
            "[RESULT] Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.97      0.94      0.96     42122\n",
            "      Attack       0.90      0.95      0.92     22991\n",
            "\n",
            "    accuracy                           0.94     65113\n",
            "   macro avg       0.94      0.94      0.94     65113\n",
            "weighted avg       0.95      0.94      0.94     65113\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0) GPU setup (optional)\n",
        "# ------------------------------------------------------------\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Hyperparameters\n",
        "# ------------------------------------------------------------\n",
        "FEATURE_DIM = 29 * 29 * 2\n",
        "N_LABELS   = 2\n",
        "BATCH      = 128\n",
        "EPOCHS     = 30\n",
        "\n",
        "# AAE-specific\n",
        "N_L1       = 1024\n",
        "N_L2       = 768\n",
        "LATENT_DIM = 64\n",
        "λ_gp       = 10.0\n",
        "\n",
        "# Learning rates\n",
        "LR_AE = 0.0005\n",
        "LR_DZ = 0.0001\n",
        "LR_DY = 0.0001\n",
        "LR_G  = 5e-5\n",
        "\n",
        "# Architecture options\n",
        "ACTIVATION = 'elu'\n",
        "DROPOUT    = 0.2\n",
        "NORM_TYPE  = 'layer'  # 'layer' or 'batch'\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Helper functions: preprocessing & TFRecord creation\n",
        "# ------------------------------------------------------------\n",
        "datasets = ['DoS', 'Fuzzy', 'RPM', 'gear', 'parsed_dataset']\n",
        "csv_map = {\n",
        "    'DoS': 'DoS_dataset.csv',\n",
        "    'Fuzzy': 'Fuzzy_dataset.csv',\n",
        "    'RPM': 'RPM_dataset.csv',\n",
        "    'gear': 'gear_dataset.csv',\n",
        "    'parsed_dataset': 'parsed_dataset.csv'\n",
        "}\n",
        "\n",
        "def fill_flag(row):\n",
        "    if not isinstance(row['Flag'], str):\n",
        "        col = 'Data' + str(int(row['DLC']))\n",
        "        row['Flag'] = row.get(col, row['Flag'])\n",
        "    return row\n",
        "\n",
        "def convert_canid_bits(cid):\n",
        "    try:\n",
        "        b = bin(int(str(cid), 16))[2:].zfill(29)\n",
        "        return np.array(list(map(int, b)), dtype=np.uint8)\n",
        "    except:\n",
        "        return np.zeros(29, dtype=np.uint8)\n",
        "\n",
        "def hex_to_int(x):\n",
        "    try:\n",
        "        return int(str(x).strip(), 16)\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def preprocess_windows(csv_file):\n",
        "    print(f\"[DATA] Processing {csv_file}\")\n",
        "    attrs = ['Timestamp', 'canID', 'DLC'] + [f'Data{i}' for i in range(8)] + ['Flag']\n",
        "    df = pd.read_csv(csv_file, header=None, names=attrs, low_memory=False)\n",
        "    df['Timestamp'] = pd.to_numeric(df['Timestamp'], errors='coerce')\n",
        "    df['DLC']       = pd.to_numeric(df['DLC'], errors='coerce').fillna(0).astype(int)\n",
        "    df = df.dropna(subset=['Timestamp', 'canID']).apply(fill_flag, axis=1)\n",
        "    for i in range(8):\n",
        "        df[f'Data{i}'] = df[f'Data{i}'].apply(hex_to_int).astype(np.uint8)\n",
        "    df['Flag']    = df['Flag'].astype(str).str.upper().eq('T').astype(np.uint8)\n",
        "    df['canBits'] = df['canID'].apply(convert_canid_bits)\n",
        "    df = df.sort_values('Timestamp')\n",
        "\n",
        "    bits_all   = np.stack(df['canBits'].values)\n",
        "    data_bytes = df[[f'Data{i}' for i in range(8)]].values\n",
        "    flags_all  = df['Flag'].values\n",
        "\n",
        "    win = 29\n",
        "    N   = len(bits_all) // win\n",
        "    bits   = bits_all[:N * win].reshape(N, win, 29)\n",
        "    data   = data_bytes[:N * win].reshape(N, win, 8)\n",
        "    flags  = flags_all[:N * win].reshape(N, win)\n",
        "\n",
        "    rows = []\n",
        "    for i in range(N):\n",
        "        id_img   = bits[i].astype(np.uint8)\n",
        "        last_b   = data[i, -1, :]\n",
        "        b8       = np.unpackbits(last_b, axis=0).reshape(8,8)\n",
        "        data_img = cv2.resize(b8.astype(np.float32), (29,29), interpolation=cv2.INTER_NEAREST) > 0.5\n",
        "        two_ch   = np.stack([id_img, data_img.astype(np.uint8)], axis=-1)\n",
        "        feat_int = two_ch.flatten().tolist()\n",
        "        lbl      = int(flags[i].any())\n",
        "        rows.append((feat_int, lbl))\n",
        "    return rows\n",
        "\n",
        "def write_tfrecord(rows, base):\n",
        "    np.random.shuffle(rows)\n",
        "    ntr = int(0.7 * len(rows))\n",
        "    nvl = int(0.15 * len(rows))\n",
        "    splits = {'train': rows[:ntr], 'val': rows[ntr:ntr+nvl], 'test': rows[ntr+nvl:]}\n",
        "    for ph, ch in splits.items():\n",
        "        fn = f\"{base}_{ph}.tfrecord\"\n",
        "        with tf.io.TFRecordWriter(fn) as writer:\n",
        "            for feat, lbl in ch:\n",
        "                ex = tf.train.Example(features=tf.train.Features(feature={\n",
        "                    'features': tf.train.Feature(int64_list=tf.train.Int64List(value=feat)),\n",
        "                    'label':    tf.train.Feature(int64_list=tf.train.Int64List(value=[lbl]))\n",
        "                }))\n",
        "                writer.write(ex.SerializeToString())\n",
        "\n",
        "# Create/check TFRecords\n",
        "expected = []\n",
        "for a in datasets:\n",
        "    for ph in ('train', 'val', 'test'):\n",
        "        expected.append(f\"{a}_{ph}.tfrecord\")\n",
        "        if a != 'parsed_dataset':\n",
        "            expected.append(f\"Normal_{a}_{ph}.tfrecord\")\n",
        "if not all(os.path.exists(f) for f in expected):\n",
        "    print(\"[DATA] TFRecords missing, preprocessing...\")\n",
        "    for a in datasets:\n",
        "        src = csv_map[a]\n",
        "        if not os.path.exists(src):\n",
        "            print(f\"[WARN] {src} not found\")\n",
        "        else:\n",
        "            rows    = preprocess_windows(src)\n",
        "            normals = [r for r in rows if r[1] == 0]\n",
        "            attacks = [r for r in rows if r[1] == 1]\n",
        "            write_tfrecord(normals, f\"Normal_{a}\")\n",
        "            if attacks:\n",
        "                write_tfrecord(attacks, a)\n",
        "else:\n",
        "    print(\"[DATA] All TFRecords found.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) tf.data pipeline\n",
        "# ------------------------------------------------------------\n",
        "def parse_feat(proto):\n",
        "    feat = tf.io.parse_single_example(proto, {\n",
        "        'features': tf.io.FixedLenFeature([FEATURE_DIM], tf.int64),\n",
        "        'label':    tf.io.FixedLenFeature([1], tf.int64)\n",
        "    })\n",
        "    x = tf.cast(feat['features'], tf.float32)\n",
        "    y = tf.one_hot(tf.cast(feat['label'][0], tf.int32), N_LABELS)\n",
        "    return x, y\n",
        "\n",
        "train_files = glob.glob('Normal_*_train.tfrecord')\n",
        "train_ds = (\n",
        "    tf.data.TFRecordDataset(train_files, num_parallel_reads=tf.data.AUTOTUNE)\n",
        "    .map(parse_feat, tf.data.AUTOTUNE)\n",
        "    .map(lambda x, y: (x + tf.random.normal(tf.shape(x), 0, 0.01), x, y), tf.data.AUTOTUNE)\n",
        "    .shuffle(10000).repeat()\n",
        "    .batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "total = sum(1 for _ in tf.data.TFRecordDataset(train_files))\n",
        "steps_per_epoch = total // BATCH\n",
        "print(f\"[PIPE] Total records: {total}, steps/epoch: {steps_per_epoch}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) AAE Model definition\n",
        "# ------------------------------------------------------------\n",
        "class AAE(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def dense_block(units):\n",
        "            layers = [tf.keras.layers.Dense(units)]\n",
        "            if NORM_TYPE == 'layer': layers.append(tf.keras.layers.LayerNormalization())\n",
        "            elif NORM_TYPE == 'batch': layers.append(tf.keras.layers.BatchNormalization())\n",
        "            layers.append(tf.keras.layers.Activation(ACTIVATION))\n",
        "            if DROPOUT > 0: layers.append(tf.keras.layers.Dropout(DROPOUT))\n",
        "            return tf.keras.Sequential(layers)\n",
        "\n",
        "        self.e1   = dense_block(N_L1)\n",
        "        self.e2   = dense_block(N_L2)\n",
        "        self.ez   = tf.keras.layers.Dense(LATENT_DIM)\n",
        "        self.ey   = tf.keras.layers.Dense(N_LABELS)\n",
        "\n",
        "        self.d1   = dense_block(N_L2)\n",
        "        self.d2   = dense_block(N_L1)\n",
        "        self.dout = tf.keras.layers.Dense(FEATURE_DIM, activation='sigmoid')\n",
        "\n",
        "        self.dz1  = dense_block(N_L1)\n",
        "        self.dz2  = dense_block(N_L2)\n",
        "        self.dzout= tf.keras.layers.Dense(1)\n",
        "\n",
        "        self.dy1  = dense_block(N_L1)\n",
        "        self.dy2  = dense_block(N_L2)\n",
        "        self.dyout= tf.keras.layers.Dense(1)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h      = self.e2(self.e1(x))\n",
        "        z      = self.ez(h)\n",
        "        logits = self.ey(h)\n",
        "        return z, tf.nn.softmax(logits), logits\n",
        "\n",
        "    def decode(self, z, y):\n",
        "        h = tf.concat([z, y], axis=1)\n",
        "        h = self.d1(h)\n",
        "        h = self.d2(h)\n",
        "        return self.dout(h)\n",
        "\n",
        "    def discriminate_z(self, z):\n",
        "        h = self.dz1(z)\n",
        "        h = self.dz2(h)\n",
        "        return self.dzout(h)\n",
        "\n",
        "    def discriminate_y(self, y):\n",
        "        h = self.dy1(y)\n",
        "        h = self.dy2(h)\n",
        "        return self.dyout(h)\n",
        "\n",
        "    def gradient_penalty(self, f, real, fake):\n",
        "        alpha = tf.random.uniform([real.shape[0], 1], 0, 1)\n",
        "        interm = real + alpha * (fake - real)\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(interm)\n",
        "            pred = f(interm)\n",
        "        grads = tape.gradient(pred, interm)\n",
        "        slopes= tf.sqrt(tf.reduce_sum(tf.square(grads), axis=1) + 1e-8)\n",
        "        return tf.reduce_mean((slopes - 1)**2)\n",
        "\n",
        "aae = AAE()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4) Losses & Optimizers\n",
        "# ------------------------------------------------------------\n",
        "mse    = tf.keras.losses.MeanSquaredError()\n",
        "ce     = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "opt_ae = tf.keras.optimizers.Adam(LR_AE)\n",
        "opt_dz = tf.keras.optimizers.Adam(LR_DZ)\n",
        "opt_dy = tf.keras.optimizers.Adam(LR_DY)\n",
        "opt_g  = tf.keras.optimizers.Adam(LR_G)\n",
        "\n",
        "@tf.function\n",
        "def train_step(xn, xc, y):\n",
        "    with tf.GradientTape() as t_ae:\n",
        "        z, yp, logits = aae.encode(xn)\n",
        "        xr = aae.decode(z, yp)\n",
        "        loss_re = mse(xc, xr)\n",
        "    vars_ae = aae.e1.trainable_variables + aae.e2.trainable_variables + aae.ez.trainable_variables + aae.ey.trainable_variables + aae.d1.trainable_variables + aae.d2.trainable_variables + aae.dout.trainable_variables\n",
        "    grads_ae = t_ae.gradient(loss_re, vars_ae)\n",
        "    opt_ae.apply_gradients(zip(grads_ae, vars_ae))\n",
        "\n",
        "    with tf.GradientTape() as t_dz:\n",
        "        z_real = tf.random.normal([xn.shape[0], LATENT_DIM])\n",
        "        dz_r = aae.discriminate_z(z_real)\n",
        "        dz_f = aae.discriminate_z(z)\n",
        "        gp   = aae.gradient_penalty(aae.discriminate_z, z_real, z)\n",
        "        loss_dz = tf.reduce_mean(dz_f) - tf.reduce_mean(dz_r) + λ_gp * gp\n",
        "    vars_dz = aae.dz1.trainable_variables + aae.dz2.trainable_variables + aae.dzout.trainable_variables\n",
        "    grads_dz = t_dz.gradient(loss_dz, vars_dz)\n",
        "    opt_dz.apply_gradients(zip(grads_dz, vars_dz))\n",
        "\n",
        "    with tf.GradientTape() as t_dy:\n",
        "        dy_r = aae.discriminate_y(y)\n",
        "        _, yp_enc, _ = aae.encode(xc)\n",
        "        dy_f = aae.discriminate_y(yp_enc)\n",
        "        gp_y = aae.gradient_penalty(aae.discriminate_y, y, yp_enc)\n",
        "        loss_dy = tf.reduce_mean(dy_f) - tf.reduce_mean(dy_r) + λ_gp * gp_y\n",
        "    vars_dy = aae.dy1.trainable_variables + aae.dy2.trainable_variables + aae.dyout.trainable_variables\n",
        "    grads_dy = t_dy.gradient(loss_dy, vars_dy)\n",
        "    opt_dy.apply_gradients(zip(grads_dy, vars_dy))\n",
        "\n",
        "    with tf.GradientTape() as t_g:\n",
        "        z_enc, y_enc, logits_enc = aae.encode(xc)\n",
        "        loss_g = -tf.reduce_mean(aae.discriminate_z(z_enc))\n",
        "        loss_g += -tf.reduce_mean(aae.discriminate_y(y_enc))\n",
        "        loss_g += ce(y, logits_enc)\n",
        "    vars_g = aae.e1.trainable_variables + aae.e2.trainable_variables + aae.ez.trainable_variables + aae.ey.trainable_variables\n",
        "    grads_g = t_g.gradient(loss_g, vars_g)\n",
        "    opt_g.apply_gradients(zip(grads_g, vars_g))\n",
        "\n",
        "    return loss_re, loss_dz, loss_dy, loss_g\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5) Training loop\n",
        "# ------------------------------------------------------------\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    print(f\"[TRAIN] Epoch {epoch}/{EPOCHS}\")\n",
        "    it = iter(train_ds)\n",
        "    for step in range(steps_per_epoch):\n",
        "        xn, xc, y = next(it)\n",
        "        lr, ldz, ldy, lg = train_step(xn, xc, y)\n",
        "        if step % 100 == 0:\n",
        "            print(f\" step {step}/{steps_per_epoch} | recon={lr:.4f} dz={ldz:.4f} dy={ldy:.4f} gen={lg:.4f}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6) Save encoder & decoder\n",
        "# ------------------------------------------------------------\n",
        "from tensorflow.keras.layers import Input, Activation, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "enc_in = Input(shape=(FEATURE_DIM,))\n",
        "h = aae.e2(aae.e1(enc_in))\n",
        "z_enc = aae.ez(h)\n",
        "y_logits = aae.ey(h)\n",
        "y_enc = Activation('softmax')(y_logits)\n",
        "encoder = Model(enc_in, [z_enc, y_enc], name='aae_encoder')\n",
        "\n",
        "z_in = Input(shape=(LATENT_DIM,))\n",
        "y_in = Input(shape=(N_LABELS,))\n",
        "h2 = aae.d2(aae.d1(Concatenate()([z_in, y_in])))\n",
        "dec_out = aae.dout(h2)\n",
        "decoder = Model([z_in, y_in], dec_out, name='aae_decoder')\n",
        "\n",
        "encoder.save('aae_encoder.keras')\n",
        "decoder.save('aae_decoder.keras')\n",
        "print(\"[SAVE] Encoder & decoder saved\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7) Evaluation\n",
        "# ------------------------------------------------------------\n",
        "errs, ys = [], []\n",
        "for fn in glob.glob('*_test.tfrecord'):\n",
        "    label = 0 if fn.startswith('Normal_') else 1\n",
        "    ds_eval = tf.data.TFRecordDataset(fn).map(parse_feat).batch(256)\n",
        "    for x_batch, _ in ds_eval:\n",
        "        z_p, y_p = encoder(x_batch)\n",
        "        x_r = decoder([z_p, y_p])\n",
        "        e = tf.reduce_mean((x_batch - x_r)**2, axis=1).numpy()\n",
        "        errs.append(e)\n",
        "        ys.append(np.full(e.shape, label))\n",
        "errs = np.concatenate(errs)\n",
        "ys   = np.concatenate(ys)\n",
        "\n",
        "fpr, tpr, ths = roc_curve(ys, errs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "opt_idx = np.argmax(tpr - fpr)\n",
        "opt_thr = ths[opt_idx]\n",
        "\n",
        "print(f\"[RESULT] ROC AUC: {roc_auc:.4f}, Thr: {opt_thr:.6f}, TPR: {tpr[opt_idx]:.3f}, FPR: {fpr[opt_idx]:.3f}\")\n",
        "print(\"[RESULT] Confusion Matrix:\")\n",
        "print(confusion_matrix(ys, (errs > opt_thr).astype(int)))\n",
        "print(\"[RESULT] Classification Report:\")\n",
        "print(classification_report(ys, (errs > opt_thr).astype(int), target_names=['Normal','Attack']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m7VDB4nBcmN"
      },
      "source": [
        "data swt number 2 small size of data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ-dlVuYBb_7",
        "outputId": "9aa7c311-fa00-4e59-e6f2-d7fc6269bc64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DATA] TFRecords missing, preprocessing...\n",
            "[DATA] Processing Attack_free_CHEVROLET_Spark_train.csv\n",
            "[DATA] Processing Attack_free_HYUNDAI_Sonata_train.csv\n",
            "[DATA] Processing Attack_free_KIA_Soul_train.csv\n",
            "[DATA] Processing Flooding_CHEVROLET_Spark_train.csv\n",
            "[DATA] Processing Flooding_HYUNDAI_Sonata_train.csv\n",
            "[DATA] Processing Flooding_KIA_Soul_train.csv\n",
            "[DATA] Processing Fuzzy_CHEVROLET_Spark_train.csv\n",
            "[DATA] Processing Fuzzy_HYUNDAI_Sonata_train.csv\n",
            "[DATA] Processing Fuzzy_KIA_Soul_train.csv\n",
            "[DATA] Processing Malfunction_CHEVROLET_Spark_train.csv\n",
            "[DATA] Processing Malfunction_HYUNDAI_Sonata_train.csv\n",
            "[DATA] Processing Malfunction_KIA_Soul_train.csv\n",
            "[WARN] Replay_dataset_HY_Sonata_train.csv not found\n",
            "[WARN] Replay_dataset_KIA_Soul_train.csv not found\n",
            "[PIPE] Total records: 23578, steps/epoch: 184\n",
            "[TRAIN] Epoch 1/30\n",
            " step 0/184 | recon=0.2737 dz=3.0691 dy=1.8532 gen=0.5951\n",
            " step 100/184 | recon=0.0628 dz=-3.7954 dy=-0.0054 gen=5.0743\n",
            "[TRAIN] Epoch 2/30\n",
            " step 0/184 | recon=0.0440 dz=-3.0442 dy=-0.0038 gen=4.0200\n",
            " step 100/184 | recon=0.0356 dz=-1.9440 dy=-0.0013 gen=2.3201\n",
            "[TRAIN] Epoch 3/30\n",
            " step 0/184 | recon=0.0326 dz=-1.7025 dy=-0.0012 gen=1.3916\n",
            " step 100/184 | recon=0.0301 dz=-1.1544 dy=-0.0013 gen=0.7478\n",
            "[TRAIN] Epoch 4/30\n",
            " step 0/184 | recon=0.0306 dz=-1.1694 dy=-0.0011 gen=0.9552\n",
            " step 100/184 | recon=0.0280 dz=-0.9383 dy=-0.0011 gen=0.9620\n",
            "[TRAIN] Epoch 5/30\n",
            " step 0/184 | recon=0.0272 dz=-1.2574 dy=-0.0013 gen=1.0743\n",
            " step 100/184 | recon=0.0263 dz=-0.8244 dy=-0.0013 gen=0.7308\n",
            "[TRAIN] Epoch 6/30\n",
            " step 0/184 | recon=0.0260 dz=-1.1270 dy=-0.0012 gen=0.5942\n",
            " step 100/184 | recon=0.0248 dz=-0.8853 dy=-0.0017 gen=0.6089\n",
            "[TRAIN] Epoch 7/30\n",
            " step 0/184 | recon=0.0260 dz=-1.1709 dy=-0.0014 gen=0.5489\n",
            " step 100/184 | recon=0.0248 dz=-0.6608 dy=-0.0019 gen=0.0483\n",
            "[TRAIN] Epoch 8/30\n",
            " step 0/184 | recon=0.0246 dz=-0.9109 dy=-0.0016 gen=-0.2279\n",
            " step 100/184 | recon=0.0226 dz=-0.8480 dy=-0.0025 gen=-0.3831\n",
            "[TRAIN] Epoch 9/30\n",
            " step 0/184 | recon=0.0241 dz=-1.0170 dy=-0.0020 gen=-0.5769\n",
            " step 100/184 | recon=0.0209 dz=-0.8730 dy=-0.0035 gen=-0.8376\n",
            "[TRAIN] Epoch 10/30\n",
            " step 0/184 | recon=0.0220 dz=-1.1562 dy=-0.0037 gen=-1.0478\n",
            " step 100/184 | recon=0.0220 dz=-1.1398 dy=-0.0121 gen=-1.4356\n",
            "[TRAIN] Epoch 11/30\n",
            " step 0/184 | recon=0.0223 dz=-1.1310 dy=-0.0132 gen=-1.8297\n",
            " step 100/184 | recon=0.0200 dz=-1.0154 dy=-0.0140 gen=-1.5475\n",
            "[TRAIN] Epoch 12/30\n",
            " step 0/184 | recon=0.0208 dz=-1.1759 dy=-0.0227 gen=-1.3903\n",
            " step 100/184 | recon=0.0202 dz=-1.1324 dy=-0.0674 gen=-1.4907\n",
            "[TRAIN] Epoch 13/30\n",
            " step 0/184 | recon=0.0202 dz=-1.3287 dy=-0.0734 gen=-1.7790\n",
            " step 100/184 | recon=0.0203 dz=-1.1542 dy=-0.0732 gen=-2.6150\n",
            "[TRAIN] Epoch 14/30\n",
            " step 0/184 | recon=0.0206 dz=-1.5842 dy=-0.1911 gen=-2.7600\n",
            " step 100/184 | recon=0.0193 dz=-1.6991 dy=-0.1485 gen=-3.0656\n",
            "[TRAIN] Epoch 15/30\n",
            " step 0/184 | recon=0.0187 dz=-1.9993 dy=-0.1245 gen=-3.4641\n",
            " step 100/184 | recon=0.0185 dz=-1.6831 dy=-0.2833 gen=-3.9404\n",
            "[TRAIN] Epoch 16/30\n",
            " step 0/184 | recon=0.0193 dz=-1.9354 dy=-0.1924 gen=-4.5712\n",
            " step 100/184 | recon=0.0176 dz=-2.0525 dy=-0.2850 gen=-4.5218\n",
            "[TRAIN] Epoch 17/30\n",
            " step 0/184 | recon=0.0186 dz=-2.1154 dy=-0.1697 gen=-5.0608\n",
            " step 100/184 | recon=0.0173 dz=-1.8876 dy=-0.2644 gen=-5.3151\n",
            "[TRAIN] Epoch 18/30\n",
            " step 0/184 | recon=0.0187 dz=-1.9417 dy=-0.1839 gen=-5.3870\n",
            " step 100/184 | recon=0.0172 dz=-2.0470 dy=-0.1990 gen=-5.3690\n",
            "[TRAIN] Epoch 19/30\n",
            " step 0/184 | recon=0.0192 dz=-2.1231 dy=-0.1145 gen=-5.1263\n",
            " step 100/184 | recon=0.0168 dz=-1.9903 dy=-0.2393 gen=-4.9065\n",
            "[TRAIN] Epoch 20/30\n",
            " step 0/184 | recon=0.0184 dz=-2.3948 dy=-0.2005 gen=-4.4305\n",
            " step 100/184 | recon=0.0168 dz=-1.9816 dy=-0.2048 gen=-4.6809\n",
            "[TRAIN] Epoch 21/30\n",
            " step 0/184 | recon=0.0182 dz=-2.1845 dy=-0.1586 gen=-4.1470\n",
            " step 100/184 | recon=0.0164 dz=-2.1387 dy=-0.2459 gen=-3.7852\n",
            "[TRAIN] Epoch 22/30\n",
            " step 0/184 | recon=0.0178 dz=-2.1515 dy=-0.1888 gen=-3.6236\n",
            " step 100/184 | recon=0.0154 dz=-2.1132 dy=-0.2958 gen=-3.2527\n",
            "[TRAIN] Epoch 23/30\n",
            " step 0/184 | recon=0.0165 dz=-2.4885 dy=-0.2152 gen=-3.0838\n",
            " step 100/184 | recon=0.0158 dz=-2.2599 dy=-0.2223 gen=-2.8119\n",
            "[TRAIN] Epoch 24/30\n",
            " step 0/184 | recon=0.0164 dz=-2.4773 dy=-0.2429 gen=-2.4691\n",
            " step 100/184 | recon=0.0146 dz=-2.1759 dy=-0.2143 gen=-2.6306\n",
            "[TRAIN] Epoch 25/30\n",
            " step 0/184 | recon=0.0163 dz=-2.6392 dy=-0.2635 gen=-2.0250\n",
            " step 100/184 | recon=0.0148 dz=-2.5259 dy=-0.2465 gen=-1.8359\n",
            "[TRAIN] Epoch 26/30\n",
            " step 0/184 | recon=0.0161 dz=-2.4207 dy=-0.2574 gen=-1.9006\n",
            " step 100/184 | recon=0.0150 dz=-2.1722 dy=-0.2448 gen=-1.2202\n",
            "[TRAIN] Epoch 27/30\n",
            " step 0/184 | recon=0.0161 dz=-2.5673 dy=-0.2233 gen=-1.2573\n",
            " step 100/184 | recon=0.0147 dz=-2.5607 dy=-0.1655 gen=-1.0223\n",
            "[TRAIN] Epoch 28/30\n",
            " step 0/184 | recon=0.0159 dz=-2.5513 dy=-0.2394 gen=-1.1794\n",
            " step 100/184 | recon=0.0150 dz=-2.7139 dy=-0.2624 gen=-1.1452\n",
            "[TRAIN] Epoch 29/30\n",
            " step 0/184 | recon=0.0161 dz=-2.6383 dy=-0.2473 gen=-1.3357\n",
            " step 100/184 | recon=0.0136 dz=-2.5914 dy=-0.2600 gen=-1.2135\n",
            "[TRAIN] Epoch 30/30\n",
            " step 0/184 | recon=0.0155 dz=-2.6532 dy=-0.2572 gen=-1.2873\n",
            " step 100/184 | recon=0.0146 dz=-2.4730 dy=-0.2025 gen=-1.5818\n",
            "[SAVE] Encoder & decoder saved\n",
            "[RESULT] ROC AUC: 0.9571, Thr: 0.026829, TPR: 0.903, FPR: 0.092\n",
            "[RESULT] Confusion Matrix:\n",
            "[[4599  466]\n",
            " [ 150 1382]]\n",
            "[RESULT] Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.97      0.91      0.94      5065\n",
            "      Attack       0.75      0.90      0.82      1532\n",
            "\n",
            "    accuracy                           0.91      6597\n",
            "   macro avg       0.86      0.91      0.88      6597\n",
            "weighted avg       0.92      0.91      0.91      6597\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
        "import csv\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0) GPU setup (optional)\n",
        "# ------------------------------------------------------------\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Hyperparameters\n",
        "# ------------------------------------------------------------\n",
        "FEATURE_DIM = 29 * 29 * 2\n",
        "N_LABELS   = 2\n",
        "BATCH      = 128\n",
        "EPOCHS     = 30\n",
        "\n",
        "# AAE-specific\n",
        "N_L1       = 1024\n",
        "N_L2       = 768\n",
        "LATENT_DIM = 64\n",
        "λ_gp       = 10.0\n",
        "\n",
        "# Learning rates\n",
        "LR_AE = 0.0005\n",
        "LR_DZ = 0.0001\n",
        "LR_DY = 0.0001\n",
        "LR_G  = 5e-5\n",
        "\n",
        "# Architecture options\n",
        "ACTIVATION = 'elu'\n",
        "DROPOUT    = 0.2\n",
        "NORM_TYPE  = 'layer'  # 'layer' or 'batch'\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Helper functions: preprocessing & TFRecord creation\n",
        "# ------------------------------------------------------------\n",
        "datasets = [\n",
        "    'Attack_free_CHEVROLET_Spark_train',\n",
        "    'Attack_free_HYUNDAI_Sonata_train',\n",
        "    'Attack_free_KIA_Soul_train',\n",
        "    'Flooding_CHEVROLET_Spark_train',\n",
        "    'Flooding_HYUNDAI_Sonata_train',\n",
        "    'Flooding_KIA_Soul_train',\n",
        "    'Fuzzy_CHEVROLET_Spark_train',\n",
        "    'Fuzzy_HYUNDAI_Sonata_train',\n",
        "    'Fuzzy_KIA_Soul_train',\n",
        "    'Malfunction_CHEVROLET_Spark_train',\n",
        "    'Malfunction_HYUNDAI_Sonata_train',\n",
        "    'Malfunction_KIA_Soul_train',\n",
        "    'Replay_dataset_HY_Sonata_train',\n",
        "    'Replay_dataset_KIA_Soul_train'\n",
        "]\n",
        "\n",
        "csv_map = {d: d + '.csv' for d in datasets}\n",
        "\n",
        "def fix_attack_free_csv(path):\n",
        "    fixed_rows = []\n",
        "    with open(path, 'r') as infile:\n",
        "        reader = csv.reader(infile)\n",
        "        for row in reader:\n",
        "            if not row or row[0] == \"Timestamp\":\n",
        "                continue\n",
        "            timestamp = row[0]\n",
        "            can_id    = row[1]\n",
        "            dlc       = int(row[2])\n",
        "            raw_data  = row[3].strip().split()\n",
        "            raw_data += ['00'] * (8 - len(raw_data)) if len(raw_data) < 8 else []\n",
        "            raw_data = raw_data[:8]\n",
        "            fixed_row = [timestamp, can_id, dlc] + raw_data + ['R']\n",
        "            fixed_rows.append(fixed_row)\n",
        "    with open(path, 'w', newline='') as outfile:\n",
        "        writer = csv.writer(outfile)\n",
        "        writer.writerow([\"Timestamp\", \"CAN ID\", \"DLC\"] + [f\"DATA[{i}]\" for i in range(8)] + [\"Label\"])\n",
        "        writer.writerows(fixed_rows)\n",
        "\n",
        "def fix_attack_csv(path):\n",
        "    fixed_rows = []\n",
        "    with open(path, 'r') as infile:\n",
        "        reader = csv.reader(infile)\n",
        "        for row in reader:\n",
        "            if not row or row[0] == \"Timestamp\":\n",
        "                continue\n",
        "            timestamp = row[0]\n",
        "            can_id    = row[1]\n",
        "            dlc       = int(row[2])\n",
        "            raw_data  = row[3].strip().split()\n",
        "            raw_data += ['00'] * (8 - len(raw_data)) if len(raw_data) < 8 else []\n",
        "            raw_data = raw_data[:8]\n",
        "            rest = row[4:] if len(row) > 4 else []\n",
        "            fixed_row = [timestamp, can_id, dlc] + raw_data + rest\n",
        "            fixed_rows.append(fixed_row)\n",
        "    with open(path, 'w', newline='') as outfile:\n",
        "        writer = csv.writer(outfile)\n",
        "        header = [\"Timestamp\", \"CAN ID\", \"DLC\"] + [f\"DATA[{i}]\" for i in range(8)]\n",
        "        if len(fixed_rows[0]) == 12:\n",
        "            header.append(\"Label\")\n",
        "        writer.writerow(header)\n",
        "        writer.writerows(fixed_rows)\n",
        "\n",
        "def fill_flag(row):\n",
        "    if not isinstance(row['Flag'], str):\n",
        "        col = 'Data' + str(int(row['DLC']))\n",
        "        row['Flag'] = row.get(col, row['Flag'])\n",
        "    return row\n",
        "\n",
        "def convert_canid_bits(cid):\n",
        "    try:\n",
        "        b = bin(int(str(cid), 16))[2:].zfill(29)\n",
        "        return np.array(list(map(int, b)), dtype=np.uint8)\n",
        "    except:\n",
        "        return np.zeros(29, dtype=np.uint8)\n",
        "\n",
        "def hex_to_int(x):\n",
        "    try:\n",
        "        return int(str(x).strip(), 16)\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def preprocess_windows(csv_file):\n",
        "    print(f\"[DATA] Processing {csv_file}\")\n",
        "    attrs = ['Timestamp', 'canID', 'DLC'] + [f'Data{i}' for i in range(8)] + ['Flag']\n",
        "    df = pd.read_csv(csv_file, header=None, names=attrs, low_memory=False)\n",
        "    df['Timestamp'] = pd.to_numeric(df['Timestamp'], errors='coerce')\n",
        "    df['DLC']       = pd.to_numeric(df['DLC'], errors='coerce').fillna(0).astype(int)\n",
        "    df = df.dropna(subset=['Timestamp', 'canID']).apply(fill_flag, axis=1)\n",
        "    for i in range(8):\n",
        "        df[f'Data{i}'] = df[f'Data{i}'].apply(hex_to_int).astype(np.uint8)\n",
        "    df['Flag']    = df['Flag'].astype(str).str.upper().eq('T').astype(np.uint8)\n",
        "    df['canBits'] = df['canID'].apply(convert_canid_bits)\n",
        "    df = df.sort_values('Timestamp')\n",
        "\n",
        "    bits_all   = np.stack(df['canBits'].values)\n",
        "    data_bytes = df[[f'Data{i}' for i in range(8)]].values\n",
        "    flags_all  = df['Flag'].values\n",
        "\n",
        "    win = 29\n",
        "    N   = len(bits_all) // win\n",
        "    bits   = bits_all[:N * win].reshape(N, win, 29)\n",
        "    data   = data_bytes[:N * win].reshape(N, win, 8)\n",
        "    flags  = flags_all[:N * win].reshape(N, win)\n",
        "\n",
        "    rows = []\n",
        "    for i in range(N):\n",
        "        id_img   = bits[i].astype(np.uint8)\n",
        "        last_b   = data[i, -1, :]\n",
        "        b8       = np.unpackbits(last_b, axis=0).reshape(8,8)\n",
        "        data_img = cv2.resize(b8.astype(np.float32), (29,29), interpolation=cv2.INTER_NEAREST) > 0.5\n",
        "        two_ch   = np.stack([id_img, data_img.astype(np.uint8)], axis=-1)\n",
        "        feat_int = two_ch.flatten().tolist()\n",
        "        lbl      = int(flags[i].any())\n",
        "        rows.append((feat_int, lbl))\n",
        "    return rows\n",
        "\n",
        "def write_tfrecord(rows, base):\n",
        "    np.random.shuffle(rows)\n",
        "    ntr = int(0.7 * len(rows))\n",
        "    nvl = int(0.15 * len(rows))\n",
        "    splits = {'train': rows[:ntr], 'val': rows[ntr:ntr+nvl], 'test': rows[ntr+nvl:]}\n",
        "    for ph, ch in splits.items():\n",
        "        fn = f\"{base}_{ph}.tfrecord\"\n",
        "        with tf.io.TFRecordWriter(fn) as writer:\n",
        "            for feat, lbl in ch:\n",
        "                ex = tf.train.Example(features=tf.train.Features(feature={\n",
        "                    'features': tf.train.Feature(int64_list=tf.train.Int64List(value=feat)),\n",
        "                    'label':    tf.train.Feature(int64_list=tf.train.Int64List(value=[lbl]))\n",
        "                }))\n",
        "                writer.write(ex.SerializeToString())\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1.5) Fix & preprocess CSV files\n",
        "# ------------------------------------------------------------\n",
        "expected = []\n",
        "for a in datasets:\n",
        "    for ph in ('train', 'val', 'test'):\n",
        "        expected.append(f\"{a}_{ph}.tfrecord\")\n",
        "        if a != 'parsed_dataset':\n",
        "            expected.append(f\"Normal_{a}_{ph}.tfrecord\")\n",
        "\n",
        "if not all(os.path.exists(f) for f in expected):\n",
        "    print(\"[DATA] TFRecords missing, preprocessing...\")\n",
        "    for a in datasets:\n",
        "        src = csv_map[a]\n",
        "        if not os.path.exists(src):\n",
        "            print(f\"[WARN] {src} not found\")\n",
        "        else:\n",
        "            if \"attack_free\" in src.lower():\n",
        "                fix_attack_free_csv(src)\n",
        "            else:\n",
        "                fix_attack_csv(src)\n",
        "\n",
        "            rows    = preprocess_windows(src)\n",
        "            normals = [r for r in rows if r[1] == 0]\n",
        "            attacks = [r for r in rows if r[1] == 1]\n",
        "            write_tfrecord(normals, f\"Normal_{a}\")\n",
        "            if attacks:\n",
        "                write_tfrecord(attacks, a)\n",
        "else:\n",
        "    print(\"[DATA] All TFRecords found.\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) tf.data pipeline\n",
        "# ------------------------------------------------------------\n",
        "def parse_feat(proto):\n",
        "    feat = tf.io.parse_single_example(proto, {\n",
        "        'features': tf.io.FixedLenFeature([FEATURE_DIM], tf.int64),\n",
        "        'label':    tf.io.FixedLenFeature([1], tf.int64)\n",
        "    })\n",
        "    x = tf.cast(feat['features'], tf.float32)\n",
        "    y = tf.one_hot(tf.cast(feat['label'][0], tf.int32), N_LABELS)\n",
        "    return x, y\n",
        "\n",
        "train_files = glob.glob('Normal_*_train.tfrecord')\n",
        "train_ds = (\n",
        "    tf.data.TFRecordDataset(train_files, num_parallel_reads=tf.data.AUTOTUNE)\n",
        "    .map(parse_feat, tf.data.AUTOTUNE)\n",
        "    .map(lambda x, y: (x + tf.random.normal(tf.shape(x), 0, 0.01), x, y), tf.data.AUTOTUNE)\n",
        "    .shuffle(10000).repeat()\n",
        "    .batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "total = sum(1 for _ in tf.data.TFRecordDataset(train_files))\n",
        "steps_per_epoch = total // BATCH\n",
        "print(f\"[PIPE] Total records: {total}, steps/epoch: {steps_per_epoch}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) AAE Model definition\n",
        "# ------------------------------------------------------------\n",
        "class AAE(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def dense_block(units):\n",
        "            layers = [tf.keras.layers.Dense(units)]\n",
        "            if NORM_TYPE == 'layer': layers.append(tf.keras.layers.LayerNormalization())\n",
        "            elif NORM_TYPE == 'batch': layers.append(tf.keras.layers.BatchNormalization())\n",
        "            layers.append(tf.keras.layers.Activation(ACTIVATION))\n",
        "            if DROPOUT > 0: layers.append(tf.keras.layers.Dropout(DROPOUT))\n",
        "            return tf.keras.Sequential(layers)\n",
        "\n",
        "        self.e1   = dense_block(N_L1)\n",
        "        self.e2   = dense_block(N_L2)\n",
        "        self.ez   = tf.keras.layers.Dense(LATENT_DIM)\n",
        "        self.ey   = tf.keras.layers.Dense(N_LABELS)\n",
        "\n",
        "        self.d1   = dense_block(N_L2)\n",
        "        self.d2   = dense_block(N_L1)\n",
        "        self.dout = tf.keras.layers.Dense(FEATURE_DIM, activation='sigmoid')\n",
        "\n",
        "        self.dz1  = dense_block(N_L1)\n",
        "        self.dz2  = dense_block(N_L2)\n",
        "        self.dzout= tf.keras.layers.Dense(1)\n",
        "\n",
        "        self.dy1  = dense_block(N_L1)\n",
        "        self.dy2  = dense_block(N_L2)\n",
        "        self.dyout= tf.keras.layers.Dense(1)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h      = self.e2(self.e1(x))\n",
        "        z      = self.ez(h)\n",
        "        logits = self.ey(h)\n",
        "        return z, tf.nn.softmax(logits), logits\n",
        "\n",
        "    def decode(self, z, y):\n",
        "        h = tf.concat([z, y], axis=1)\n",
        "        h = self.d1(h)\n",
        "        h = self.d2(h)\n",
        "        return self.dout(h)\n",
        "\n",
        "    def discriminate_z(self, z):\n",
        "        h = self.dz1(z)\n",
        "        h = self.dz2(h)\n",
        "        return self.dzout(h)\n",
        "\n",
        "    def discriminate_y(self, y):\n",
        "        h = self.dy1(y)\n",
        "        h = self.dy2(h)\n",
        "        return self.dyout(h)\n",
        "\n",
        "    def gradient_penalty(self, f, real, fake):\n",
        "        alpha = tf.random.uniform([real.shape[0], 1], 0, 1)\n",
        "        interm = real + alpha * (fake - real)\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(interm)\n",
        "            pred = f(interm)\n",
        "        grads = tape.gradient(pred, interm)\n",
        "        slopes= tf.sqrt(tf.reduce_sum(tf.square(grads), axis=1) + 1e-8)\n",
        "        return tf.reduce_mean((slopes - 1)**2)\n",
        "\n",
        "aae = AAE()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4) Losses & Optimizers\n",
        "# ------------------------------------------------------------\n",
        "mse    = tf.keras.losses.MeanSquaredError()\n",
        "ce     = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "opt_ae = tf.keras.optimizers.Adam(LR_AE)\n",
        "opt_dz = tf.keras.optimizers.Adam(LR_DZ)\n",
        "opt_dy = tf.keras.optimizers.Adam(LR_DY)\n",
        "opt_g  = tf.keras.optimizers.Adam(LR_G)\n",
        "\n",
        "@tf.function\n",
        "def train_step(xn, xc, y):\n",
        "    with tf.GradientTape() as t_ae:\n",
        "        z, yp, logits = aae.encode(xn)\n",
        "        xr = aae.decode(z, yp)\n",
        "        loss_re = mse(xc, xr)\n",
        "    vars_ae = aae.e1.trainable_variables + aae.e2.trainable_variables + aae.ez.trainable_variables + aae.ey.trainable_variables + aae.d1.trainable_variables + aae.d2.trainable_variables + aae.dout.trainable_variables\n",
        "    grads_ae = t_ae.gradient(loss_re, vars_ae)\n",
        "    opt_ae.apply_gradients(zip(grads_ae, vars_ae))\n",
        "\n",
        "    with tf.GradientTape() as t_dz:\n",
        "        z_real = tf.random.normal([xn.shape[0], LATENT_DIM])\n",
        "        dz_r = aae.discriminate_z(z_real)\n",
        "        dz_f = aae.discriminate_z(z)\n",
        "        gp   = aae.gradient_penalty(aae.discriminate_z, z_real, z)\n",
        "        loss_dz = tf.reduce_mean(dz_f) - tf.reduce_mean(dz_r) + λ_gp * gp\n",
        "    vars_dz = aae.dz1.trainable_variables + aae.dz2.trainable_variables + aae.dzout.trainable_variables\n",
        "    grads_dz = t_dz.gradient(loss_dz, vars_dz)\n",
        "    opt_dz.apply_gradients(zip(grads_dz, vars_dz))\n",
        "\n",
        "    with tf.GradientTape() as t_dy:\n",
        "        dy_r = aae.discriminate_y(y)\n",
        "        _, yp_enc, _ = aae.encode(xc)\n",
        "        dy_f = aae.discriminate_y(yp_enc)\n",
        "        gp_y = aae.gradient_penalty(aae.discriminate_y, y, yp_enc)\n",
        "        loss_dy = tf.reduce_mean(dy_f) - tf.reduce_mean(dy_r) + λ_gp * gp_y\n",
        "    vars_dy = aae.dy1.trainable_variables + aae.dy2.trainable_variables + aae.dyout.trainable_variables\n",
        "    grads_dy = t_dy.gradient(loss_dy, vars_dy)\n",
        "    opt_dy.apply_gradients(zip(grads_dy, vars_dy))\n",
        "\n",
        "    with tf.GradientTape() as t_g:\n",
        "        z_enc, y_enc, logits_enc = aae.encode(xc)\n",
        "        loss_g = -tf.reduce_mean(aae.discriminate_z(z_enc))\n",
        "        loss_g += -tf.reduce_mean(aae.discriminate_y(y_enc))\n",
        "        loss_g += ce(y, logits_enc)\n",
        "    vars_g = aae.e1.trainable_variables + aae.e2.trainable_variables + aae.ez.trainable_variables + aae.ey.trainable_variables\n",
        "    grads_g = t_g.gradient(loss_g, vars_g)\n",
        "    opt_g.apply_gradients(zip(grads_g, vars_g))\n",
        "\n",
        "    return loss_re, loss_dz, loss_dy, loss_g\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5) Training loop\n",
        "# ------------------------------------------------------------\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    print(f\"[TRAIN] Epoch {epoch}/{EPOCHS}\")\n",
        "    it = iter(train_ds)\n",
        "    for step in range(steps_per_epoch):\n",
        "        xn, xc, y = next(it)\n",
        "        lr, ldz, ldy, lg = train_step(xn, xc, y)\n",
        "        if step % 100 == 0:\n",
        "            print(f\" step {step}/{steps_per_epoch} | recon={lr:.4f} dz={ldz:.4f} dy={ldy:.4f} gen={lg:.4f}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6) Save encoder & decoder\n",
        "# ------------------------------------------------------------\n",
        "from tensorflow.keras.layers import Input, Activation, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "enc_in = Input(shape=(FEATURE_DIM,))\n",
        "h = aae.e2(aae.e1(enc_in))\n",
        "z_enc = aae.ez(h)\n",
        "y_logits = aae.ey(h)\n",
        "y_enc = Activation('softmax')(y_logits)\n",
        "encoder = Model(enc_in, [z_enc, y_enc], name='aae_encoder')\n",
        "\n",
        "z_in = Input(shape=(LATENT_DIM,))\n",
        "y_in = Input(shape=(N_LABELS,))\n",
        "h2 = aae.d2(aae.d1(Concatenate()([z_in, y_in])))\n",
        "dec_out = aae.dout(h2)\n",
        "decoder = Model([z_in, y_in], dec_out, name='aae_decoder')\n",
        "\n",
        "encoder.save('aae_encoder.keras')\n",
        "decoder.save('aae_decoder.keras')\n",
        "print(\"[SAVE] Encoder & decoder saved\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7) Evaluation\n",
        "# ------------------------------------------------------------\n",
        "errs, ys = [], []\n",
        "for fn in glob.glob('*_test.tfrecord'):\n",
        "    label = 0 if fn.startswith('Normal_') else 1\n",
        "    ds_eval = tf.data.TFRecordDataset(fn).map(parse_feat).batch(256)\n",
        "    for x_batch, _ in ds_eval:\n",
        "        z_p, y_p = encoder(x_batch)\n",
        "        x_r = decoder([z_p, y_p])\n",
        "        e = tf.reduce_mean((x_batch - x_r)**2, axis=1).numpy()\n",
        "        errs.append(e)\n",
        "        ys.append(np.full(e.shape, label))\n",
        "errs = np.concatenate(errs)\n",
        "ys   = np.concatenate(ys)\n",
        "\n",
        "fpr, tpr, ths = roc_curve(ys, errs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "opt_idx = np.argmax(tpr - fpr)\n",
        "opt_thr = ths[opt_idx]\n",
        "\n",
        "print(f\"[RESULT] ROC AUC: {roc_auc:.4f}, Thr: {opt_thr:.6f}, TPR: {tpr[opt_idx]:.3f}, FPR: {fpr[opt_idx]:.3f}\")\n",
        "print(\"[RESULT] Confusion Matrix:\")\n",
        "print(confusion_matrix(ys, (errs > opt_thr).astype(int)))\n",
        "print(\"[RESULT] Classification Report:\")\n",
        "print(classification_report(ys, (errs > opt_thr).astype(int), target_names=['Normal','Attack']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWZLnohrMPeS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
        "import csv\n",
        "\n",
        "\n",
        "def convert_file_format():\n",
        "    for i in range(1, 9):\n",
        "        in_file = f\"File_{i}.csv\"\n",
        "        out_rows = []\n",
        "        if not os.path.exists(in_file):\n",
        "            print(f\"[SKIP] {in_file} not found\")\n",
        "            continue\n",
        "\n",
        "        with open(in_file, 'r') as infile:\n",
        "            reader = csv.reader(infile)\n",
        "            for row in reader:\n",
        "                if not row:\n",
        "                    continue\n",
        "                timestamp = row[1]\n",
        "                can_id = row[2]\n",
        "                dlc = int(row[3])\n",
        "                data = row[4].strip().split()\n",
        "                if len(data) < 8:\n",
        "                    data += ['00'] * (8 - len(data))\n",
        "                data = data[:8]  # Ensure 8 bytes\n",
        "                label = row[5] if len(row) > 5 else 'R'\n",
        "                out_rows.append([timestamp, can_id, dlc] + data + [label])\n",
        "\n",
        "        with open(in_file, 'w', newline='') as outfile:\n",
        "            writer = csv.writer(outfile)\n",
        "            writer.writerow([\"Timestamp\", \"CAN ID\", \"DLC\"] + [f\"DATA[{j}]\" for j in range(8)] + [\"Label\"])\n",
        "            writer.writerows(out_rows)\n",
        "\n",
        "convert_file_format()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSNMiMASKtft",
        "outputId": "532914c8-0275-46a7-af1e-ac05f813d8fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[DATA] TFRecords missing, preprocessing...\n",
            "[DATA] Processing File_1.csv\n",
            "[DATA] Processing File_2.csv\n",
            "[DATA] Processing File_3.csv\n",
            "[DATA] Processing File_4.csv\n",
            "[WARN] File_5.csv not found\n",
            "[WARN] File_6.csv not found\n",
            "[DATA] Processing File_7.csv\n",
            "[DATA] Processing File_8.csv\n",
            "[PIPE] Total records: 7475, steps/epoch: 58\n",
            "[TRAIN] Epoch 1/30\n",
            " step 0/58 | recon=0.2727 dz=3.4219 dy=4.7893 gen=0.8533\n",
            "[TRAIN] Epoch 2/30\n",
            " step 0/58 | recon=0.0011 dz=-20.2077 dy=0.0249 gen=23.8840\n",
            "[TRAIN] Epoch 3/30\n",
            " step 0/58 | recon=0.0003 dz=-22.4862 dy=-0.0021 gen=22.8380\n",
            "[TRAIN] Epoch 4/30\n",
            " step 0/58 | recon=0.0002 dz=-19.7906 dy=-0.0017 gen=18.7928\n",
            "[TRAIN] Epoch 5/30\n",
            " step 0/58 | recon=0.0002 dz=-18.9347 dy=-0.0023 gen=16.5857\n",
            "[TRAIN] Epoch 6/30\n",
            " step 0/58 | recon=0.0001 dz=-17.7121 dy=-0.0015 gen=13.6698\n",
            "[TRAIN] Epoch 7/30\n",
            " step 0/58 | recon=0.0000 dz=-14.9067 dy=-0.0010 gen=12.3121\n",
            "[TRAIN] Epoch 8/30\n",
            " step 0/58 | recon=0.0001 dz=-18.6896 dy=-0.0008 gen=14.3189\n",
            "[TRAIN] Epoch 9/30\n",
            " step 0/58 | recon=0.0000 dz=-18.6291 dy=-0.0015 gen=11.7379\n",
            "[TRAIN] Epoch 10/30\n",
            " step 0/58 | recon=0.0001 dz=-16.3255 dy=-0.0013 gen=11.3261\n",
            "[TRAIN] Epoch 11/30\n",
            " step 0/58 | recon=0.0001 dz=-15.5736 dy=-0.0008 gen=9.5266\n",
            "[TRAIN] Epoch 12/30\n",
            " step 0/58 | recon=0.0000 dz=-16.8292 dy=-0.0009 gen=9.4152\n",
            "[TRAIN] Epoch 13/30\n",
            " step 0/58 | recon=0.0000 dz=-18.1555 dy=-0.0013 gen=11.7550\n",
            "[TRAIN] Epoch 14/30\n",
            " step 0/58 | recon=0.0000 dz=-16.6194 dy=-0.0010 gen=10.0374\n",
            "[TRAIN] Epoch 15/30\n",
            " step 0/58 | recon=0.0000 dz=-16.9837 dy=-0.0014 gen=8.8410\n",
            "[TRAIN] Epoch 16/30\n",
            " step 0/58 | recon=0.0000 dz=-17.1639 dy=-0.0012 gen=-3.5942\n",
            "[TRAIN] Epoch 17/30\n",
            " step 0/58 | recon=0.0000 dz=-15.6688 dy=-0.0009 gen=-4.5527\n",
            "[TRAIN] Epoch 18/30\n",
            " step 0/58 | recon=0.0000 dz=-10.7548 dy=-0.0009 gen=-12.6701\n",
            "[TRAIN] Epoch 19/30\n",
            " step 0/58 | recon=0.0000 dz=4.5746 dy=-0.0015 gen=-31.7237\n",
            "[TRAIN] Epoch 20/30\n",
            " step 0/58 | recon=0.0000 dz=1.4007 dy=-0.0004 gen=-28.1546\n",
            "[TRAIN] Epoch 21/30\n",
            " step 0/58 | recon=0.0000 dz=-8.8210 dy=-0.0001 gen=-17.4350\n",
            "[TRAIN] Epoch 22/30\n",
            " step 0/58 | recon=0.0000 dz=-7.4811 dy=-0.0008 gen=-17.8151\n",
            "[TRAIN] Epoch 23/30\n",
            " step 0/58 | recon=0.0000 dz=0.8120 dy=-0.0002 gen=-27.2779\n",
            "[TRAIN] Epoch 24/30\n",
            " step 0/58 | recon=0.0000 dz=5.9558 dy=-0.0004 gen=-34.7804\n",
            "[TRAIN] Epoch 25/30\n",
            " step 0/58 | recon=0.0044 dz=-20.9562 dy=0.0000 gen=-4.6025\n",
            "[TRAIN] Epoch 26/30\n",
            " step 0/58 | recon=0.0037 dz=-22.2430 dy=-0.0000 gen=-4.2227\n",
            "[TRAIN] Epoch 27/30\n",
            " step 0/58 | recon=0.0045 dz=-16.8646 dy=-0.0042 gen=-9.6400\n",
            "[TRAIN] Epoch 28/30\n",
            " step 0/58 | recon=0.0017 dz=-7.7534 dy=-0.0001 gen=-26.0297\n",
            "[TRAIN] Epoch 29/30\n",
            " step 0/58 | recon=0.0008 dz=-6.1252 dy=-0.0000 gen=-28.7288\n",
            "[TRAIN] Epoch 30/30\n",
            " step 0/58 | recon=0.0004 dz=-4.1153 dy=-0.0000 gen=-31.6077\n",
            "[SAVE] Encoder & decoder saved\n",
            "[RESULT] ROC AUC: 0.4717, Thr: 0.000002, TPR: 1.000, FPR: 0.854\n",
            "[RESULT] Confusion Matrix:\n",
            "[[1282  326]\n",
            " [   3    0]]\n",
            "[RESULT] Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       1.00      0.80      0.89      1608\n",
            "      Attack       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.80      1611\n",
            "   macro avg       0.50      0.40      0.44      1611\n",
            "weighted avg       1.00      0.80      0.88      1611\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0) GPU setup (optional)\n",
        "# ------------------------------------------------------------\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Hyperparameters\n",
        "# ------------------------------------------------------------\n",
        "FEATURE_DIM = 29 * 29 * 2\n",
        "N_LABELS   = 2\n",
        "BATCH      = 128\n",
        "EPOCHS     = 30\n",
        "\n",
        "# AAE-specific\n",
        "N_L1       = 1024\n",
        "N_L2       = 768\n",
        "LATENT_DIM = 64\n",
        "λ_gp       = 10.0\n",
        "\n",
        "# Learning rates\n",
        "LR_AE = 0.0005\n",
        "LR_DZ = 0.0001\n",
        "LR_DY = 0.0001\n",
        "LR_G  = 5e-5\n",
        "\n",
        "# Architecture options\n",
        "ACTIVATION = 'elu'\n",
        "DROPOUT    = 0.2\n",
        "NORM_TYPE  = 'layer'  # 'layer' or 'batch'\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Helper functions: preprocessing & TFRecord creation\n",
        "# ------------------------------------------------------------\n",
        "datasets = ['File_1','File_2','File_3','File_4','File_5','File_6','File_7','File_8' ]\n",
        "csv_map = {\n",
        "    'File_1': 'File_1.csv',\n",
        "    'File_2': 'File_2.csv',\n",
        "    'File_3': 'File_3.csv',\n",
        "    'File_4': 'File_4.csv',\n",
        "    'File_5': 'File_5.csv',\n",
        "    'File_6': 'File_6.csv',\n",
        "    'File_7': 'File_7.csv',\n",
        "    'File_8': 'File_8.csv'\n",
        "}\n",
        "\n",
        "def fill_flag(row):\n",
        "    if not isinstance(row['Flag'], str):\n",
        "        col = 'Data' + str(int(row['DLC']))\n",
        "        row['Flag'] = row.get(col, row['Flag'])\n",
        "    return row\n",
        "\n",
        "def convert_canid_bits(cid):\n",
        "    try:\n",
        "        b = bin(int(str(cid), 16))[2:].zfill(29)\n",
        "        return np.array(list(map(int, b)), dtype=np.uint8)\n",
        "    except:\n",
        "        return np.zeros(29, dtype=np.uint8)\n",
        "\n",
        "def hex_to_int(x):\n",
        "    try:\n",
        "        return int(str(x).strip(), 16)\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def preprocess_windows(csv_file):\n",
        "    print(f\"[DATA] Processing {csv_file}\")\n",
        "    attrs = ['Timestamp', 'canID', 'DLC'] + [f'Data{i}' for i in range(8)] + ['Flag']\n",
        "    df = pd.read_csv(csv_file, header=None, names=attrs, low_memory=False)\n",
        "    df['Timestamp'] = pd.to_numeric(df['Timestamp'], errors='coerce')\n",
        "    df['DLC']       = pd.to_numeric(df['DLC'], errors='coerce').fillna(0).astype(int)\n",
        "    df = df.dropna(subset=['Timestamp', 'canID']).apply(fill_flag, axis=1)\n",
        "    for i in range(8):\n",
        "        df[f'Data{i}'] = df[f'Data{i}'].apply(hex_to_int).astype(np.uint8)\n",
        "    df['Flag']    = df['Flag'].astype(str).str.upper().eq('T').astype(np.uint8)\n",
        "    df['canBits'] = df['canID'].apply(convert_canid_bits)\n",
        "    df = df.sort_values('Timestamp')\n",
        "\n",
        "    bits_all   = np.stack(df['canBits'].values)\n",
        "    data_bytes = df[[f'Data{i}' for i in range(8)]].values\n",
        "    flags_all  = df['Flag'].values\n",
        "\n",
        "    win = 29\n",
        "    N   = len(bits_all) // win\n",
        "    bits   = bits_all[:N * win].reshape(N, win, 29)\n",
        "    data   = data_bytes[:N * win].reshape(N, win, 8)\n",
        "    flags  = flags_all[:N * win].reshape(N, win)\n",
        "\n",
        "    rows = []\n",
        "    for i in range(N):\n",
        "        id_img   = bits[i].astype(np.uint8)\n",
        "        last_b   = data[i, -1, :]\n",
        "        b8       = np.unpackbits(last_b, axis=0).reshape(8,8)\n",
        "        data_img = cv2.resize(b8.astype(np.float32), (29,29), interpolation=cv2.INTER_NEAREST) > 0.5\n",
        "        two_ch   = np.stack([id_img, data_img.astype(np.uint8)], axis=-1)\n",
        "        feat_int = two_ch.flatten().tolist()\n",
        "        lbl      = int(flags[i].any())\n",
        "        rows.append((feat_int, lbl))\n",
        "    return rows\n",
        "\n",
        "def write_tfrecord(rows, base):\n",
        "    np.random.shuffle(rows)\n",
        "    ntr = int(0.7 * len(rows))\n",
        "    nvl = int(0.15 * len(rows))\n",
        "    splits = {'train': rows[:ntr], 'val': rows[ntr:ntr+nvl], 'test': rows[ntr+nvl:]}\n",
        "    for ph, ch in splits.items():\n",
        "        fn = f\"{base}_{ph}.tfrecord\"\n",
        "        with tf.io.TFRecordWriter(fn) as writer:\n",
        "            for feat, lbl in ch:\n",
        "                ex = tf.train.Example(features=tf.train.Features(feature={\n",
        "                    'features': tf.train.Feature(int64_list=tf.train.Int64List(value=feat)),\n",
        "                    'label':    tf.train.Feature(int64_list=tf.train.Int64List(value=[lbl]))\n",
        "                }))\n",
        "                writer.write(ex.SerializeToString())\n",
        "\n",
        "# Create/check TFRecords\n",
        "expected = []\n",
        "for a in datasets:\n",
        "    for ph in ('train', 'val', 'test'):\n",
        "        expected.append(f\"{a}_{ph}.tfrecord\")\n",
        "        if a != 'parsed_dataset':\n",
        "            expected.append(f\"Normal_{a}_{ph}.tfrecord\")\n",
        "if not all(os.path.exists(f) for f in expected):\n",
        "    print(\"[DATA] TFRecords missing, preprocessing...\")\n",
        "    for a in datasets:\n",
        "        src = csv_map[a]\n",
        "        if not os.path.exists(src):\n",
        "            print(f\"[WARN] {src} not found\")\n",
        "        else:\n",
        "            rows    = preprocess_windows(src)\n",
        "            normals = [r for r in rows if r[1] == 0]\n",
        "            attacks = [r for r in rows if r[1] == 1]\n",
        "            write_tfrecord(normals, f\"Normal_{a}\")\n",
        "            if attacks:\n",
        "                write_tfrecord(attacks, a)\n",
        "else:\n",
        "    print(\"[DATA] All TFRecords found.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) tf.data pipeline\n",
        "# ------------------------------------------------------------\n",
        "def parse_feat(proto):\n",
        "    feat = tf.io.parse_single_example(proto, {\n",
        "        'features': tf.io.FixedLenFeature([FEATURE_DIM], tf.int64),\n",
        "        'label':    tf.io.FixedLenFeature([1], tf.int64)\n",
        "    })\n",
        "    x = tf.cast(feat['features'], tf.float32)\n",
        "    y = tf.one_hot(tf.cast(feat['label'][0], tf.int32), N_LABELS)\n",
        "    return x, y\n",
        "\n",
        "train_files = glob.glob('Normal_*_train.tfrecord')\n",
        "train_ds = (\n",
        "    tf.data.TFRecordDataset(train_files, num_parallel_reads=tf.data.AUTOTUNE)\n",
        "    .map(parse_feat, tf.data.AUTOTUNE)\n",
        "    .map(lambda x, y: (x + tf.random.normal(tf.shape(x), 0, 0.01), x, y), tf.data.AUTOTUNE)\n",
        "    .shuffle(10000).repeat()\n",
        "    .batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "total = sum(1 for _ in tf.data.TFRecordDataset(train_files))\n",
        "steps_per_epoch = total // BATCH\n",
        "print(f\"[PIPE] Total records: {total}, steps/epoch: {steps_per_epoch}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) AAE Model definition\n",
        "# ------------------------------------------------------------\n",
        "class AAE(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def dense_block(units):\n",
        "            layers = [tf.keras.layers.Dense(units)]\n",
        "            if NORM_TYPE == 'layer': layers.append(tf.keras.layers.LayerNormalization())\n",
        "            elif NORM_TYPE == 'batch': layers.append(tf.keras.layers.BatchNormalization())\n",
        "            layers.append(tf.keras.layers.Activation(ACTIVATION))\n",
        "            if DROPOUT > 0: layers.append(tf.keras.layers.Dropout(DROPOUT))\n",
        "            return tf.keras.Sequential(layers)\n",
        "\n",
        "        self.e1   = dense_block(N_L1)\n",
        "        self.e2   = dense_block(N_L2)\n",
        "        self.ez   = tf.keras.layers.Dense(LATENT_DIM)\n",
        "        self.ey   = tf.keras.layers.Dense(N_LABELS)\n",
        "\n",
        "        self.d1   = dense_block(N_L2)\n",
        "        self.d2   = dense_block(N_L1)\n",
        "        self.dout = tf.keras.layers.Dense(FEATURE_DIM, activation='sigmoid')\n",
        "\n",
        "        self.dz1  = dense_block(N_L1)\n",
        "        self.dz2  = dense_block(N_L2)\n",
        "        self.dzout= tf.keras.layers.Dense(1)\n",
        "\n",
        "        self.dy1  = dense_block(N_L1)\n",
        "        self.dy2  = dense_block(N_L2)\n",
        "        self.dyout= tf.keras.layers.Dense(1)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h      = self.e2(self.e1(x))\n",
        "        z      = self.ez(h)\n",
        "        logits = self.ey(h)\n",
        "        return z, tf.nn.softmax(logits), logits\n",
        "\n",
        "    def decode(self, z, y):\n",
        "        h = tf.concat([z, y], axis=1)\n",
        "        h = self.d1(h)\n",
        "        h = self.d2(h)\n",
        "        return self.dout(h)\n",
        "\n",
        "    def discriminate_z(self, z):\n",
        "        h = self.dz1(z)\n",
        "        h = self.dz2(h)\n",
        "        return self.dzout(h)\n",
        "\n",
        "    def discriminate_y(self, y):\n",
        "        h = self.dy1(y)\n",
        "        h = self.dy2(h)\n",
        "        return self.dyout(h)\n",
        "\n",
        "    def gradient_penalty(self, f, real, fake):\n",
        "        alpha = tf.random.uniform([real.shape[0], 1], 0, 1)\n",
        "        interm = real + alpha * (fake - real)\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(interm)\n",
        "            pred = f(interm)\n",
        "        grads = tape.gradient(pred, interm)\n",
        "        slopes= tf.sqrt(tf.reduce_sum(tf.square(grads), axis=1) + 1e-8)\n",
        "        return tf.reduce_mean((slopes - 1)**2)\n",
        "\n",
        "aae = AAE()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4) Losses & Optimizers\n",
        "# ------------------------------------------------------------\n",
        "mse    = tf.keras.losses.MeanSquaredError()\n",
        "ce     = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "opt_ae = tf.keras.optimizers.Adam(LR_AE)\n",
        "opt_dz = tf.keras.optimizers.Adam(LR_DZ)\n",
        "opt_dy = tf.keras.optimizers.Adam(LR_DY)\n",
        "opt_g  = tf.keras.optimizers.Adam(LR_G)\n",
        "\n",
        "@tf.function\n",
        "def train_step(xn, xc, y):\n",
        "    with tf.GradientTape() as t_ae:\n",
        "        z, yp, logits = aae.encode(xn)\n",
        "        xr = aae.decode(z, yp)\n",
        "        loss_re = mse(xc, xr)\n",
        "    vars_ae = aae.e1.trainable_variables + aae.e2.trainable_variables + aae.ez.trainable_variables + aae.ey.trainable_variables + aae.d1.trainable_variables + aae.d2.trainable_variables + aae.dout.trainable_variables\n",
        "    grads_ae = t_ae.gradient(loss_re, vars_ae)\n",
        "    opt_ae.apply_gradients(zip(grads_ae, vars_ae))\n",
        "\n",
        "    with tf.GradientTape() as t_dz:\n",
        "        z_real = tf.random.normal([xn.shape[0], LATENT_DIM])\n",
        "        dz_r = aae.discriminate_z(z_real)\n",
        "        dz_f = aae.discriminate_z(z)\n",
        "        gp   = aae.gradient_penalty(aae.discriminate_z, z_real, z)\n",
        "        loss_dz = tf.reduce_mean(dz_f) - tf.reduce_mean(dz_r) + λ_gp * gp\n",
        "    vars_dz = aae.dz1.trainable_variables + aae.dz2.trainable_variables + aae.dzout.trainable_variables\n",
        "    grads_dz = t_dz.gradient(loss_dz, vars_dz)\n",
        "    opt_dz.apply_gradients(zip(grads_dz, vars_dz))\n",
        "\n",
        "    with tf.GradientTape() as t_dy:\n",
        "        dy_r = aae.discriminate_y(y)\n",
        "        _, yp_enc, _ = aae.encode(xc)\n",
        "        dy_f = aae.discriminate_y(yp_enc)\n",
        "        gp_y = aae.gradient_penalty(aae.discriminate_y, y, yp_enc)\n",
        "        loss_dy = tf.reduce_mean(dy_f) - tf.reduce_mean(dy_r) + λ_gp * gp_y\n",
        "    vars_dy = aae.dy1.trainable_variables + aae.dy2.trainable_variables + aae.dyout.trainable_variables\n",
        "    grads_dy = t_dy.gradient(loss_dy, vars_dy)\n",
        "    opt_dy.apply_gradients(zip(grads_dy, vars_dy))\n",
        "\n",
        "    with tf.GradientTape() as t_g:\n",
        "        z_enc, y_enc, logits_enc = aae.encode(xc)\n",
        "        loss_g = -tf.reduce_mean(aae.discriminate_z(z_enc))\n",
        "        loss_g += -tf.reduce_mean(aae.discriminate_y(y_enc))\n",
        "        loss_g += ce(y, logits_enc)\n",
        "    vars_g = aae.e1.trainable_variables + aae.e2.trainable_variables + aae.ez.trainable_variables + aae.ey.trainable_variables\n",
        "    grads_g = t_g.gradient(loss_g, vars_g)\n",
        "    opt_g.apply_gradients(zip(grads_g, vars_g))\n",
        "\n",
        "    return loss_re, loss_dz, loss_dy, loss_g\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5) Training loop\n",
        "# ------------------------------------------------------------\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    print(f\"[TRAIN] Epoch {epoch}/{EPOCHS}\")\n",
        "    it = iter(train_ds)\n",
        "    for step in range(steps_per_epoch):\n",
        "        xn, xc, y = next(it)\n",
        "        lr, ldz, ldy, lg = train_step(xn, xc, y)\n",
        "        if step % 100 == 0:\n",
        "            print(f\" step {step}/{steps_per_epoch} | recon={lr:.4f} dz={ldz:.4f} dy={ldy:.4f} gen={lg:.4f}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6) Save encoder & decoder\n",
        "# ------------------------------------------------------------\n",
        "from tensorflow.keras.layers import Input, Activation, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "enc_in = Input(shape=(FEATURE_DIM,))\n",
        "h = aae.e2(aae.e1(enc_in))\n",
        "z_enc = aae.ez(h)\n",
        "y_logits = aae.ey(h)\n",
        "y_enc = Activation('softmax')(y_logits)\n",
        "encoder = Model(enc_in, [z_enc, y_enc], name='aae_encoder')\n",
        "\n",
        "z_in = Input(shape=(LATENT_DIM,))\n",
        "y_in = Input(shape=(N_LABELS,))\n",
        "h2 = aae.d2(aae.d1(Concatenate()([z_in, y_in])))\n",
        "dec_out = aae.dout(h2)\n",
        "decoder = Model([z_in, y_in], dec_out, name='aae_decoder')\n",
        "\n",
        "encoder.save('aae_encoder.keras')\n",
        "decoder.save('aae_decoder.keras')\n",
        "print(\"[SAVE] Encoder & decoder saved\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7) Evaluation\n",
        "# ------------------------------------------------------------\n",
        "errs, ys = [], []\n",
        "for fn in glob.glob('*_test.tfrecord'):\n",
        "    label = 0 if fn.startswith('Normal_') else 1\n",
        "    ds_eval = tf.data.TFRecordDataset(fn).map(parse_feat).batch(256)\n",
        "    for x_batch, _ in ds_eval:\n",
        "        z_p, y_p = encoder(x_batch)\n",
        "        x_r = decoder([z_p, y_p])\n",
        "        e = tf.reduce_mean((x_batch - x_r)**2, axis=1).numpy()\n",
        "        errs.append(e)\n",
        "        ys.append(np.full(e.shape, label))\n",
        "errs = np.concatenate(errs)\n",
        "ys   = np.concatenate(ys)\n",
        "\n",
        "fpr, tpr, ths = roc_curve(ys, errs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "opt_idx = np.argmax(tpr - fpr)\n",
        "opt_thr = ths[opt_idx]\n",
        "\n",
        "print(f\"[RESULT] ROC AUC: {roc_auc:.4f}, Thr: {opt_thr:.6f}, TPR: {tpr[opt_idx]:.3f}, FPR: {fpr[opt_idx]:.3f}\")\n",
        "print(\"[RESULT] Confusion Matrix:\")\n",
        "print(confusion_matrix(ys, (errs > opt_thr).astype(int)))\n",
        "print(\"[RESULT] Classification Report:\")\n",
        "print(classification_report(ys, (errs > opt_thr).astype(int), target_names=['Normal','Attack']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ2UDIblO5Pr"
      },
      "source": [
        "third dataset -Medium size of samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mJmihmGPmg3"
      },
      "source": [
        "data set 4 very large data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZEuLI6kPqh8",
        "outputId": "d462adbf-f953-4e32-899a-055601335c5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DATA] TFRecords missing, preprocessing...\n",
            "[DATA] Processing DoS_dataset.csv\n",
            "[DATA] Processing Fuzzy_dataset.csv\n",
            "[DATA] Processing RPM_dataset.csv\n",
            "[DATA] Processing gear_dataset.csv\n",
            "[DATA] Processing parsed_dataset.csv\n",
            "[DATA] Processing File_1.csv\n",
            "[DATA] Processing File_2.csv\n",
            "[DATA] Processing File_3.csv\n",
            "[DATA] Processing File_4.csv\n",
            "[DATA] Processing File_5.csv\n",
            "[DATA] Processing File_6.csv\n",
            "[DATA] Processing File_7.csv\n",
            "[DATA] Processing File_8.csv\n",
            "[PIPE] Total records: 253631, steps/epoch: 1981\n",
            "[TRAIN] Epoch 1/30\n",
            " step 0/1981 | recon=0.2733 dz=4.3593 dy=4.8458 gen=0.4717\n",
            " step 100/1981 | recon=0.0640 dz=-4.1722 dy=-0.0117 gen=6.2472\n",
            " step 200/1981 | recon=0.0413 dz=-2.7700 dy=-0.0060 gen=3.6004\n",
            " step 300/1981 | recon=0.0349 dz=-1.4208 dy=-0.0027 gen=1.3232\n",
            " step 400/1981 | recon=0.0306 dz=-1.0711 dy=-0.0028 gen=0.0371\n",
            " step 500/1981 | recon=0.0282 dz=-0.9534 dy=-0.0027 gen=-0.2749\n",
            " step 600/1981 | recon=0.0279 dz=-0.5286 dy=-0.0020 gen=-0.3724\n",
            " step 700/1981 | recon=0.0252 dz=-0.8746 dy=-0.0022 gen=-0.3580\n",
            " step 800/1981 | recon=0.0250 dz=-0.8149 dy=-0.0017 gen=-0.7041\n",
            " step 900/1981 | recon=0.0278 dz=-1.0768 dy=-0.0027 gen=-0.4586\n",
            " step 1000/1981 | recon=0.0274 dz=-0.8376 dy=-0.0020 gen=-0.7722\n",
            " step 1100/1981 | recon=0.0243 dz=-0.8561 dy=-0.0019 gen=-0.8814\n",
            " step 1200/1981 | recon=0.0287 dz=-1.1980 dy=-0.0034 gen=-0.7268\n",
            " step 1300/1981 | recon=0.0235 dz=-0.8623 dy=-0.0029 gen=-1.3215\n",
            " step 1400/1981 | recon=0.0218 dz=-0.4460 dy=-0.0029 gen=-1.6038\n",
            " step 1500/1981 | recon=0.0197 dz=-0.6553 dy=-0.0026 gen=-1.7218\n",
            " step 1600/1981 | recon=0.0217 dz=-0.6055 dy=-0.0028 gen=-2.3732\n",
            " step 1700/1981 | recon=0.0197 dz=-0.4460 dy=-0.0027 gen=-2.6809\n",
            " step 1800/1981 | recon=0.0193 dz=-0.6934 dy=-0.0029 gen=-2.8631\n",
            " step 1900/1981 | recon=0.0183 dz=-0.8025 dy=-0.0027 gen=-3.2111\n",
            "[TRAIN] Epoch 2/30\n",
            " step 0/1981 | recon=0.0261 dz=-0.4493 dy=-0.0033 gen=-3.8834\n",
            " step 100/1981 | recon=0.0219 dz=-0.8219 dy=-0.0070 gen=-4.0068\n",
            " step 200/1981 | recon=0.0240 dz=-0.9575 dy=-0.0215 gen=-3.7142\n",
            " step 300/1981 | recon=0.0214 dz=-1.0780 dy=-0.0131 gen=-3.5473\n",
            " step 400/1981 | recon=0.0211 dz=-0.7954 dy=-0.0076 gen=-4.1761\n",
            " step 500/1981 | recon=0.0185 dz=-1.1587 dy=-0.0307 gen=-4.0184\n",
            " step 600/1981 | recon=0.0191 dz=-1.1662 dy=-0.0318 gen=-4.7418\n",
            " step 700/1981 | recon=0.0183 dz=-1.1658 dy=0.0083 gen=-5.1743\n",
            " step 800/1981 | recon=0.0182 dz=-1.4095 dy=-0.0602 gen=-5.3787\n",
            " step 900/1981 | recon=0.0209 dz=-1.6103 dy=-0.0500 gen=-5.8033\n",
            " step 1000/1981 | recon=0.0204 dz=-1.7226 dy=-0.0766 gen=-5.6109\n",
            " step 1100/1981 | recon=0.0194 dz=-1.5228 dy=-0.1046 gen=-5.5451\n",
            " step 1200/1981 | recon=0.0231 dz=-1.8045 dy=-0.1127 gen=-5.4067\n",
            " step 1300/1981 | recon=0.0188 dz=-1.4665 dy=-0.0636 gen=-6.1690\n",
            " step 1400/1981 | recon=0.0168 dz=-1.5773 dy=-0.1042 gen=-5.5161\n",
            " step 1500/1981 | recon=0.0152 dz=-1.6954 dy=-0.1156 gen=-4.8547\n",
            " step 1600/1981 | recon=0.0176 dz=-1.6178 dy=-0.0704 gen=-4.7295\n",
            " step 1700/1981 | recon=0.0166 dz=-1.9496 dy=-0.0529 gen=-4.4965\n",
            " step 1800/1981 | recon=0.0152 dz=-1.9191 dy=-0.1434 gen=-3.7904\n",
            " step 1900/1981 | recon=0.0153 dz=-2.1254 dy=-0.0897 gen=-3.3301\n",
            "[TRAIN] Epoch 3/30\n",
            " step 0/1981 | recon=0.0217 dz=-1.4319 dy=-0.0976 gen=-3.6274\n",
            " step 100/1981 | recon=0.0170 dz=-1.8478 dy=-0.1145 gen=-2.8742\n",
            " step 200/1981 | recon=0.0217 dz=-2.1029 dy=-0.1026 gen=-4.0700\n",
            " step 300/1981 | recon=0.0185 dz=-1.9270 dy=-0.1941 gen=-3.7029\n",
            " step 400/1981 | recon=0.0177 dz=-1.7900 dy=-0.1031 gen=-4.2174\n",
            " step 500/1981 | recon=0.0156 dz=-1.8288 dy=-0.1688 gen=-3.8453\n",
            " step 600/1981 | recon=0.0164 dz=-1.9699 dy=-0.1323 gen=-4.1930\n",
            " step 700/1981 | recon=0.0159 dz=-1.9414 dy=-0.1794 gen=-3.9350\n",
            " step 800/1981 | recon=0.0157 dz=-1.9897 dy=-0.1416 gen=-3.8485\n",
            " step 900/1981 | recon=0.0181 dz=-2.1036 dy=-0.1223 gen=-4.0794\n",
            " step 1000/1981 | recon=0.0185 dz=-2.3177 dy=-0.1496 gen=-3.7318\n",
            " step 1100/1981 | recon=0.0177 dz=-2.3460 dy=-0.1255 gen=-3.3985\n",
            " step 1200/1981 | recon=0.0206 dz=-2.1700 dy=-0.1244 gen=-3.7908\n",
            " step 1300/1981 | recon=0.0159 dz=-2.2057 dy=-0.1240 gen=-3.7283\n",
            " step 1400/1981 | recon=0.0151 dz=-2.1423 dy=-0.1248 gen=-3.1817\n",
            " step 1500/1981 | recon=0.0133 dz=-2.3362 dy=-0.1468 gen=-2.5994\n",
            " step 1600/1981 | recon=0.0149 dz=-2.1378 dy=-0.1664 gen=-2.7045\n",
            " step 1700/1981 | recon=0.0139 dz=-2.3806 dy=-0.2005 gen=-2.3392\n",
            " step 1800/1981 | recon=0.0141 dz=-2.1609 dy=-0.1921 gen=-1.8286\n",
            " step 1900/1981 | recon=0.0136 dz=-2.2847 dy=-0.1598 gen=-1.7028\n",
            "[TRAIN] Epoch 4/30\n",
            " step 0/1981 | recon=0.0181 dz=-1.8526 dy=-0.1732 gen=-1.8440\n",
            " step 100/1981 | recon=0.0174 dz=-2.2678 dy=-0.2878 gen=-1.7474\n",
            " step 200/1981 | recon=0.0183 dz=-2.2450 dy=-0.2755 gen=-2.5123\n",
            " step 300/1981 | recon=0.0170 dz=-2.0770 dy=-0.2524 gen=-2.7879\n",
            " step 400/1981 | recon=0.0154 dz=-2.1663 dy=-0.3750 gen=-2.7804\n",
            " step 500/1981 | recon=0.0152 dz=-2.3116 dy=-0.2720 gen=-2.7651\n",
            " step 600/1981 | recon=0.0142 dz=-2.4696 dy=-0.2730 gen=-2.8421\n",
            " step 700/1981 | recon=0.0144 dz=-2.1986 dy=-0.3028 gen=-2.8221\n",
            " step 800/1981 | recon=0.0142 dz=-2.1184 dy=-0.3201 gen=-2.7625\n",
            " step 900/1981 | recon=0.0178 dz=-2.5640 dy=-0.2560 gen=-3.0284\n",
            " step 1000/1981 | recon=0.0172 dz=-2.4852 dy=-0.2883 gen=-2.9271\n",
            " step 1100/1981 | recon=0.0150 dz=-2.4961 dy=-0.2929 gen=-2.7526\n",
            " step 1200/1981 | recon=0.0190 dz=-2.3817 dy=-0.3199 gen=-3.0828\n",
            " step 1300/1981 | recon=0.0161 dz=-2.4104 dy=-0.3274 gen=-3.2162\n",
            " step 1400/1981 | recon=0.0140 dz=-2.4614 dy=-0.2816 gen=-3.0706\n",
            " step 1500/1981 | recon=0.0119 dz=-2.5006 dy=-0.3132 gen=-2.7706\n",
            " step 1600/1981 | recon=0.0142 dz=-2.4456 dy=-0.2681 gen=-3.2792\n",
            " step 1700/1981 | recon=0.0126 dz=-2.4001 dy=-0.2595 gen=-2.8347\n",
            " step 1800/1981 | recon=0.0128 dz=-2.4344 dy=-0.2544 gen=-2.8889\n",
            " step 1900/1981 | recon=0.0132 dz=-2.2481 dy=-0.2989 gen=-2.9214\n",
            "[TRAIN] Epoch 5/30\n",
            " step 0/1981 | recon=0.0187 dz=-1.8548 dy=-0.2329 gen=-3.3600\n",
            " step 100/1981 | recon=0.0164 dz=-2.4733 dy=-0.3397 gen=-3.1192\n",
            " step 200/1981 | recon=0.0165 dz=-2.5690 dy=-0.2952 gen=-3.5722\n",
            " step 300/1981 | recon=0.0155 dz=-2.3330 dy=-0.3857 gen=-3.3464\n",
            " step 400/1981 | recon=0.0145 dz=-2.2897 dy=-0.3723 gen=-3.5029\n",
            " step 500/1981 | recon=0.0134 dz=-2.5011 dy=-0.3239 gen=-3.7416\n",
            " step 600/1981 | recon=0.0134 dz=-2.4369 dy=-0.3219 gen=-3.7803\n",
            " step 700/1981 | recon=0.0133 dz=-2.2502 dy=-0.3601 gen=-3.7865\n",
            " step 800/1981 | recon=0.0139 dz=-2.3169 dy=-0.3582 gen=-3.9322\n",
            " step 900/1981 | recon=0.0159 dz=-2.5464 dy=-0.3187 gen=-4.1224\n",
            " step 1000/1981 | recon=0.0168 dz=-2.6423 dy=-0.2947 gen=-4.2695\n",
            " step 1100/1981 | recon=0.0160 dz=-2.5705 dy=-0.3222 gen=-4.3002\n",
            " step 1200/1981 | recon=0.0192 dz=-2.4471 dy=-0.3137 gen=-4.4167\n",
            " step 1300/1981 | recon=0.0144 dz=-2.4117 dy=-0.3435 gen=-4.6024\n",
            " step 1400/1981 | recon=0.0121 dz=-2.4413 dy=-0.3388 gen=-4.5270\n",
            " step 1500/1981 | recon=0.0114 dz=-2.2865 dy=-0.3371 gen=-4.4200\n",
            " step 1600/1981 | recon=0.0136 dz=-2.4504 dy=-0.3326 gen=-4.7589\n",
            " step 1700/1981 | recon=0.0115 dz=-2.4996 dy=-0.3188 gen=-4.5410\n",
            " step 1800/1981 | recon=0.0117 dz=-2.6966 dy=-0.2859 gen=-4.3566\n",
            " step 1900/1981 | recon=0.0118 dz=-2.4530 dy=-0.2659 gen=-4.1423\n",
            "[TRAIN] Epoch 6/30\n",
            " step 0/1981 | recon=0.0167 dz=-1.8826 dy=-0.2487 gen=-4.7507\n",
            " step 100/1981 | recon=0.0162 dz=-2.4487 dy=-0.3307 gen=-4.4441\n",
            " step 200/1981 | recon=0.0157 dz=-2.4856 dy=-0.3108 gen=-4.5991\n",
            " step 300/1981 | recon=0.0151 dz=-2.2754 dy=-0.3359 gen=-4.8954\n",
            " step 400/1981 | recon=0.0139 dz=-2.1706 dy=-0.3937 gen=-4.8633\n",
            " step 500/1981 | recon=0.0140 dz=-2.4161 dy=-0.3193 gen=-4.9310\n",
            " step 600/1981 | recon=0.0122 dz=-2.3787 dy=-0.3573 gen=-4.7728\n",
            " step 700/1981 | recon=0.0125 dz=-2.4699 dy=-0.2829 gen=-4.8962\n",
            " step 800/1981 | recon=0.0127 dz=-2.4145 dy=-0.2873 gen=-5.0276\n",
            " step 900/1981 | recon=0.0154 dz=-2.3122 dy=-0.2554 gen=-5.2335\n",
            " step 1000/1981 | recon=0.0144 dz=-2.6317 dy=-0.2147 gen=-5.1536\n",
            " step 1100/1981 | recon=0.0139 dz=-2.4656 dy=-0.2387 gen=-5.3345\n",
            " step 1200/1981 | recon=0.0168 dz=-2.4894 dy=-0.1908 gen=-5.5528\n",
            " step 1300/1981 | recon=0.0126 dz=-2.4809 dy=-0.2240 gen=-5.4407\n",
            " step 1400/1981 | recon=0.0106 dz=-2.7942 dy=-0.2523 gen=-5.4953\n",
            " step 1500/1981 | recon=0.0104 dz=-2.7824 dy=-0.2189 gen=-5.3494\n",
            " step 1600/1981 | recon=0.0130 dz=-2.4640 dy=-0.2028 gen=-5.4150\n",
            " step 1700/1981 | recon=0.0115 dz=-2.5495 dy=-0.1774 gen=-5.3457\n",
            " step 1800/1981 | recon=0.0118 dz=-2.2371 dy=-0.1745 gen=-5.4189\n",
            " step 1900/1981 | recon=0.0104 dz=-2.5439 dy=-0.2054 gen=-4.8726\n",
            "[TRAIN] Epoch 7/30\n",
            " step 0/1981 | recon=0.0152 dz=-2.0469 dy=-0.1883 gen=-5.4189\n",
            " step 100/1981 | recon=0.0142 dz=-2.4536 dy=-0.2328 gen=-5.3722\n",
            " step 200/1981 | recon=0.0156 dz=-2.5193 dy=-0.2082 gen=-5.5010\n",
            " step 300/1981 | recon=0.0134 dz=-2.1271 dy=-0.2171 gen=-5.6816\n",
            " step 400/1981 | recon=0.0128 dz=-2.4499 dy=-0.2556 gen=-5.7829\n",
            " step 500/1981 | recon=0.0130 dz=-2.3874 dy=-0.2894 gen=-5.6814\n",
            " step 600/1981 | recon=0.0114 dz=-2.4331 dy=-0.3561 gen=-5.4069\n",
            " step 700/1981 | recon=0.0127 dz=-2.4202 dy=-0.2844 gen=-5.6059\n",
            " step 800/1981 | recon=0.0120 dz=-2.5559 dy=-0.2427 gen=-5.8520\n",
            " step 900/1981 | recon=0.0145 dz=-2.6270 dy=-0.2682 gen=-5.8252\n",
            " step 1000/1981 | recon=0.0136 dz=-2.6748 dy=-0.2519 gen=-5.8987\n",
            " step 1100/1981 | recon=0.0135 dz=-2.5234 dy=-0.2594 gen=-5.5649\n",
            " step 1200/1981 | recon=0.0173 dz=-2.6487 dy=-0.2721 gen=-5.5561\n",
            " step 1300/1981 | recon=0.0139 dz=-2.4777 dy=-0.2273 gen=-6.0187\n",
            " step 1400/1981 | recon=0.0109 dz=-2.6529 dy=-0.2522 gen=-5.8208\n",
            " step 1500/1981 | recon=0.0104 dz=-2.6160 dy=-0.2319 gen=-5.6963\n",
            " step 1600/1981 | recon=0.0114 dz=-2.5991 dy=-0.2541 gen=-5.6951\n",
            " step 1700/1981 | recon=0.0117 dz=-2.7496 dy=-0.2077 gen=-5.4919\n",
            " step 1800/1981 | recon=0.0105 dz=-2.6952 dy=-0.2339 gen=-5.2602\n",
            " step 1900/1981 | recon=0.0107 dz=-2.7286 dy=-0.2496 gen=-5.0075\n",
            "[TRAIN] Epoch 8/30\n",
            " step 0/1981 | recon=0.0164 dz=-2.1812 dy=-0.2045 gen=-5.4884\n",
            " step 100/1981 | recon=0.0141 dz=-2.6166 dy=-0.2763 gen=-5.5021\n",
            " step 200/1981 | recon=0.0135 dz=-2.5670 dy=-0.2058 gen=-5.8769\n",
            " step 300/1981 | recon=0.0133 dz=-2.3821 dy=-0.2697 gen=-5.7937\n",
            " step 400/1981 | recon=0.0122 dz=-2.7567 dy=-0.2958 gen=-5.7255\n",
            " step 500/1981 | recon=0.0121 dz=-2.2568 dy=-0.2604 gen=-6.3246\n",
            " step 600/1981 | recon=0.0106 dz=-2.7119 dy=-0.3502 gen=-5.7470\n",
            " step 700/1981 | recon=0.0117 dz=-2.6921 dy=-0.3327 gen=-5.8978\n",
            " step 800/1981 | recon=0.0117 dz=-2.5820 dy=-0.3451 gen=-5.7283\n",
            " step 900/1981 | recon=0.0144 dz=-2.6260 dy=-0.2803 gen=-6.1399\n",
            " step 1000/1981 | recon=0.0142 dz=-2.5984 dy=-0.2812 gen=-5.9589\n",
            " step 1100/1981 | recon=0.0160 dz=-2.6310 dy=-0.2754 gen=-6.1134\n",
            " step 1200/1981 | recon=0.0187 dz=-2.5956 dy=-0.2918 gen=-6.2050\n",
            " step 1300/1981 | recon=0.0123 dz=-2.5660 dy=-0.2923 gen=-6.4581\n",
            " step 1400/1981 | recon=0.0101 dz=-2.7008 dy=-0.2757 gen=-6.1915\n",
            " step 1500/1981 | recon=0.0110 dz=-2.7455 dy=-0.3084 gen=-6.0324\n",
            " step 1600/1981 | recon=0.0121 dz=-2.5356 dy=-0.3115 gen=-5.9719\n",
            " step 1700/1981 | recon=0.0108 dz=-2.5624 dy=-0.2855 gen=-5.8268\n",
            " step 1800/1981 | recon=0.0102 dz=-2.6402 dy=-0.2818 gen=-5.7545\n",
            " step 1900/1981 | recon=0.0106 dz=-2.5922 dy=-0.2930 gen=-5.5394\n",
            "[TRAIN] Epoch 9/30\n",
            " step 0/1981 | recon=0.0146 dz=-2.3331 dy=-0.2651 gen=-5.8368\n",
            " step 100/1981 | recon=0.0147 dz=-2.6261 dy=-0.3025 gen=-5.7934\n",
            " step 200/1981 | recon=0.0138 dz=-2.6904 dy=-0.2833 gen=-5.9260\n",
            " step 300/1981 | recon=0.0131 dz=-2.4319 dy=-0.2824 gen=-5.9356\n",
            " step 400/1981 | recon=0.0122 dz=-2.6941 dy=-0.2965 gen=-6.0141\n",
            " step 500/1981 | recon=0.0124 dz=-2.7554 dy=-0.3062 gen=-6.0165\n",
            " step 600/1981 | recon=0.0116 dz=-2.5632 dy=-0.2807 gen=-6.0524\n",
            " step 700/1981 | recon=0.0103 dz=-2.8580 dy=-0.2811 gen=-5.8758\n",
            " step 800/1981 | recon=0.0116 dz=-2.4080 dy=-0.2779 gen=-6.1116\n",
            " step 900/1981 | recon=0.0138 dz=-2.6398 dy=-0.2830 gen=-5.9790\n",
            " step 1000/1981 | recon=0.0145 dz=-2.6912 dy=-0.2543 gen=-5.9892\n",
            " step 1100/1981 | recon=0.0129 dz=-2.8496 dy=-0.2443 gen=-6.0945\n",
            " step 1200/1981 | recon=0.0164 dz=-2.7782 dy=-0.2285 gen=-6.1208\n",
            " step 1300/1981 | recon=0.0113 dz=-2.6079 dy=-0.2357 gen=-6.2853\n",
            " step 1400/1981 | recon=0.0103 dz=-2.5835 dy=-0.2690 gen=-6.1461\n",
            " step 1500/1981 | recon=0.0096 dz=-2.5941 dy=-0.2379 gen=-6.0036\n",
            " step 1600/1981 | recon=0.0112 dz=-2.5861 dy=-0.2315 gen=-6.1304\n",
            " step 1700/1981 | recon=0.0103 dz=-2.7016 dy=-0.2403 gen=-5.8538\n",
            " step 1800/1981 | recon=0.0101 dz=-2.7068 dy=-0.2438 gen=-5.6604\n",
            " step 1900/1981 | recon=0.0107 dz=-2.5920 dy=-0.2146 gen=-5.6113\n",
            "[TRAIN] Epoch 10/30\n",
            " step 0/1981 | recon=0.0142 dz=-2.1215 dy=-0.2006 gen=-6.1141\n",
            " step 100/1981 | recon=0.0148 dz=-2.5912 dy=-0.2371 gen=-5.6659\n",
            " step 200/1981 | recon=0.0144 dz=-2.7944 dy=-0.2300 gen=-5.8024\n",
            " step 300/1981 | recon=0.0135 dz=-2.4271 dy=-0.2385 gen=-6.1055\n",
            " step 400/1981 | recon=0.0103 dz=-2.7567 dy=-0.2364 gen=-6.0332\n",
            " step 500/1981 | recon=0.0112 dz=-2.5870 dy=-0.2266 gen=-6.3946\n",
            " step 600/1981 | recon=0.0108 dz=-2.3869 dy=-0.2334 gen=-6.3013\n",
            " step 700/1981 | recon=0.0108 dz=-2.4983 dy=-0.2535 gen=-6.1676\n",
            " step 800/1981 | recon=0.0107 dz=-2.6015 dy=-0.2173 gen=-6.0835\n",
            " step 900/1981 | recon=0.0131 dz=-2.5582 dy=-0.2225 gen=-6.2215\n",
            " step 1000/1981 | recon=0.0136 dz=-2.5204 dy=-0.2164 gen=-6.4478\n",
            " step 1100/1981 | recon=0.0123 dz=-2.7685 dy=-0.2258 gen=-6.2580\n",
            " step 1200/1981 | recon=0.0140 dz=-2.5598 dy=-0.2411 gen=-6.3967\n",
            " step 1300/1981 | recon=0.0126 dz=-2.5997 dy=-0.2367 gen=-6.6913\n",
            " step 1400/1981 | recon=0.0114 dz=-2.4445 dy=-0.2286 gen=-6.4454\n",
            " step 1500/1981 | recon=0.0088 dz=-2.5860 dy=-0.2359 gen=-6.3883\n",
            " step 1600/1981 | recon=0.0102 dz=-2.5428 dy=-0.2208 gen=-6.4212\n",
            " step 1700/1981 | recon=0.0096 dz=-2.5800 dy=-0.2098 gen=-6.2744\n",
            " step 1800/1981 | recon=0.0090 dz=-2.8226 dy=-0.2309 gen=-5.8134\n",
            " step 1900/1981 | recon=0.0099 dz=-2.5466 dy=-0.1788 gen=-5.9303\n",
            "[TRAIN] Epoch 11/30\n",
            " step 0/1981 | recon=0.0133 dz=-2.3016 dy=-0.2221 gen=-6.2036\n",
            " step 100/1981 | recon=0.0134 dz=-2.5961 dy=-0.2232 gen=-5.9476\n",
            " step 200/1981 | recon=0.0146 dz=-2.8338 dy=-0.2102 gen=-6.4533\n",
            " step 300/1981 | recon=0.0129 dz=-2.5100 dy=-0.2348 gen=-6.4683\n",
            " step 400/1981 | recon=0.0115 dz=-2.6428 dy=-0.2135 gen=-6.6287\n",
            " step 500/1981 | recon=0.0109 dz=-2.6396 dy=-0.2434 gen=-6.5928\n",
            " step 600/1981 | recon=0.0109 dz=-2.9103 dy=-0.2132 gen=-6.3794\n",
            " step 700/1981 | recon=0.0110 dz=-2.3995 dy=-0.2327 gen=-6.5880\n",
            " step 800/1981 | recon=0.0097 dz=-2.6097 dy=-0.2443 gen=-6.3998\n",
            " step 900/1981 | recon=0.0122 dz=-2.6448 dy=-0.1985 gen=-6.6558\n",
            " step 1000/1981 | recon=0.0132 dz=-2.8809 dy=-0.2080 gen=-6.5132\n",
            " step 1100/1981 | recon=0.0127 dz=-2.5864 dy=-0.1988 gen=-6.7331\n",
            " step 1200/1981 | recon=0.0152 dz=-2.5497 dy=-0.1961 gen=-6.7702\n",
            " step 1300/1981 | recon=0.0118 dz=-2.5263 dy=-0.2060 gen=-7.0421\n",
            " step 1400/1981 | recon=0.0091 dz=-2.6953 dy=-0.2171 gen=-6.8778\n",
            " step 1500/1981 | recon=0.0078 dz=-2.6188 dy=-0.2015 gen=-6.6521\n",
            " step 1600/1981 | recon=0.0095 dz=-2.6807 dy=-0.1917 gen=-6.5595\n",
            " step 1700/1981 | recon=0.0097 dz=-2.4920 dy=-0.1890 gen=-6.4724\n",
            " step 1800/1981 | recon=0.0096 dz=-2.4444 dy=-0.2101 gen=-6.3244\n",
            " step 1900/1981 | recon=0.0086 dz=-2.6933 dy=-0.2000 gen=-5.9764\n",
            "[TRAIN] Epoch 12/30\n",
            " step 0/1981 | recon=0.0128 dz=-1.9820 dy=-0.2078 gen=-6.5752\n",
            " step 100/1981 | recon=0.0139 dz=-2.8641 dy=-0.2109 gen=-6.0797\n",
            " step 200/1981 | recon=0.0145 dz=-2.3507 dy=-0.2013 gen=-7.0046\n",
            " step 300/1981 | recon=0.0119 dz=-2.4796 dy=-0.2179 gen=-6.8849\n",
            " step 400/1981 | recon=0.0104 dz=-2.6398 dy=-0.2094 gen=-6.8735\n",
            " step 500/1981 | recon=0.0107 dz=-2.5973 dy=-0.2463 gen=-6.8658\n",
            " step 600/1981 | recon=0.0095 dz=-2.7122 dy=-0.2284 gen=-6.4419\n",
            " step 700/1981 | recon=0.0103 dz=-2.3364 dy=-0.2259 gen=-6.6884\n",
            " step 800/1981 | recon=0.0095 dz=-2.4773 dy=-0.2158 gen=-6.7692\n",
            " step 900/1981 | recon=0.0122 dz=-2.8229 dy=-0.2313 gen=-6.4673\n",
            " step 1000/1981 | recon=0.0120 dz=-2.7813 dy=-0.1979 gen=-6.8111\n",
            " step 1100/1981 | recon=0.0108 dz=-2.6466 dy=-0.1889 gen=-6.9862\n",
            " step 1200/1981 | recon=0.0138 dz=-2.9665 dy=-0.2151 gen=-7.0972\n",
            " step 1300/1981 | recon=0.0114 dz=-2.6823 dy=-0.2107 gen=-7.3956\n",
            " step 1400/1981 | recon=0.0092 dz=-2.4268 dy=-0.2005 gen=-7.4533\n",
            " step 1500/1981 | recon=0.0095 dz=-2.5392 dy=-0.2217 gen=-6.9396\n",
            " step 1600/1981 | recon=0.0101 dz=-2.5071 dy=-0.1975 gen=-6.9281\n",
            " step 1700/1981 | recon=0.0091 dz=-2.5503 dy=-0.1990 gen=-6.8264\n",
            " step 1800/1981 | recon=0.0090 dz=-2.5892 dy=-0.1976 gen=-6.5267\n",
            " step 1900/1981 | recon=0.0093 dz=-2.1605 dy=-0.2155 gen=-6.2193\n",
            "[TRAIN] Epoch 13/30\n",
            " step 0/1981 | recon=0.0148 dz=-1.9359 dy=-0.1857 gen=-7.2462\n",
            " step 100/1981 | recon=0.0133 dz=-2.4196 dy=-0.1831 gen=-6.6744\n",
            " step 200/1981 | recon=0.0138 dz=-2.6073 dy=-0.2115 gen=-6.9264\n",
            " step 300/1981 | recon=0.0113 dz=-2.5405 dy=-0.2117 gen=-7.0877\n",
            " step 400/1981 | recon=0.0110 dz=-2.5149 dy=-0.2082 gen=-7.3258\n",
            " step 500/1981 | recon=0.0097 dz=-2.5794 dy=-0.2501 gen=-7.0914\n",
            " step 600/1981 | recon=0.0092 dz=-2.6306 dy=-0.2526 gen=-6.8161\n",
            " step 700/1981 | recon=0.0101 dz=-2.7427 dy=-0.2210 gen=-6.5417\n",
            " step 800/1981 | recon=0.0095 dz=-2.4899 dy=-0.1933 gen=-6.7543\n",
            " step 900/1981 | recon=0.0118 dz=-2.4362 dy=-0.1972 gen=-6.8174\n",
            " step 1000/1981 | recon=0.0120 dz=-2.4609 dy=-0.2236 gen=-6.8376\n",
            " step 1100/1981 | recon=0.0104 dz=-2.8231 dy=-0.2192 gen=-7.0444\n",
            " step 1200/1981 | recon=0.0138 dz=-2.6690 dy=-0.2095 gen=-7.3719\n",
            " step 1300/1981 | recon=0.0112 dz=-2.2801 dy=-0.1894 gen=-7.7130\n",
            " step 1400/1981 | recon=0.0087 dz=-2.7983 dy=-0.1912 gen=-7.2383\n",
            " step 1500/1981 | recon=0.0080 dz=-2.5168 dy=-0.2123 gen=-7.1531\n",
            " step 1600/1981 | recon=0.0095 dz=-2.5100 dy=-0.1913 gen=-7.1115\n",
            " step 1700/1981 | recon=0.0080 dz=-2.5305 dy=-0.2017 gen=-6.9535\n",
            " step 1800/1981 | recon=0.0095 dz=-2.3496 dy=-0.1934 gen=-7.1211\n",
            " step 1900/1981 | recon=0.0087 dz=-2.5058 dy=-0.1812 gen=-6.8806\n",
            "[TRAIN] Epoch 14/30\n",
            " step 0/1981 | recon=0.0127 dz=-1.6317 dy=-0.2055 gen=-7.2872\n",
            " step 100/1981 | recon=0.0115 dz=-2.5631 dy=-0.1909 gen=-6.9511\n",
            " step 200/1981 | recon=0.0116 dz=-2.7779 dy=-0.1965 gen=-7.0171\n",
            " step 300/1981 | recon=0.0113 dz=-2.2674 dy=-0.2311 gen=-7.2039\n",
            " step 400/1981 | recon=0.0098 dz=-2.4016 dy=-0.2521 gen=-7.5185\n",
            " step 500/1981 | recon=0.0096 dz=-2.6735 dy=-0.2024 gen=-7.2981\n",
            " step 600/1981 | recon=0.0085 dz=-2.6256 dy=-0.2309 gen=-7.3783\n",
            " step 700/1981 | recon=0.0097 dz=-2.4593 dy=-0.2187 gen=-7.2413\n",
            " step 800/1981 | recon=0.0097 dz=-2.4685 dy=-0.2236 gen=-7.1598\n",
            " step 900/1981 | recon=0.0119 dz=-2.7289 dy=-0.1794 gen=-7.0204\n",
            " step 1000/1981 | recon=0.0113 dz=-2.6531 dy=-0.2111 gen=-6.6705\n",
            " step 1100/1981 | recon=0.0114 dz=-2.6963 dy=-0.2090 gen=-7.1263\n",
            " step 1200/1981 | recon=0.0140 dz=-2.5284 dy=-0.1923 gen=-7.2621\n",
            " step 1300/1981 | recon=0.0124 dz=-2.3348 dy=-0.1743 gen=-7.3623\n",
            " step 1400/1981 | recon=0.0080 dz=-2.6849 dy=-0.1935 gen=-7.3750\n",
            " step 1500/1981 | recon=0.0084 dz=-2.4307 dy=-0.2036 gen=-7.3867\n",
            " step 1600/1981 | recon=0.0097 dz=-1.8759 dy=-0.1884 gen=-7.9151\n",
            " step 1700/1981 | recon=0.0087 dz=-2.2982 dy=-0.2113 gen=-7.5704\n",
            " step 1800/1981 | recon=0.0084 dz=-2.5189 dy=-0.2176 gen=-7.8028\n",
            " step 1900/1981 | recon=0.0087 dz=-2.2224 dy=-0.2000 gen=-7.5123\n",
            "[TRAIN] Epoch 15/30\n",
            " step 0/1981 | recon=0.0113 dz=-1.6861 dy=-0.1851 gen=-8.1368\n",
            " step 100/1981 | recon=0.0125 dz=-2.4150 dy=-0.2161 gen=-7.0547\n",
            " step 200/1981 | recon=0.0127 dz=-2.6587 dy=-0.1896 gen=-6.9703\n",
            " step 300/1981 | recon=0.0103 dz=-2.4842 dy=-0.1802 gen=-7.3092\n",
            " step 400/1981 | recon=0.0104 dz=-2.2857 dy=-0.2111 gen=-7.5241\n",
            " step 500/1981 | recon=0.0086 dz=-2.7094 dy=-0.2122 gen=-7.3069\n",
            " step 600/1981 | recon=0.0086 dz=-2.5457 dy=-0.2200 gen=-7.2336\n",
            " step 700/1981 | recon=0.0083 dz=-2.6442 dy=-0.1997 gen=-7.1981\n",
            " step 800/1981 | recon=0.0092 dz=-2.1593 dy=-0.2325 gen=-7.0760\n",
            " step 900/1981 | recon=0.0115 dz=-2.5549 dy=-0.2124 gen=-7.3695\n",
            " step 1000/1981 | recon=0.0113 dz=-2.5921 dy=-0.1706 gen=-7.0823\n",
            " step 1100/1981 | recon=0.0104 dz=-2.6495 dy=-0.2075 gen=-7.1496\n",
            " step 1200/1981 | recon=0.0145 dz=-2.5937 dy=-0.1950 gen=-7.0895\n",
            " step 1300/1981 | recon=0.0099 dz=-2.2216 dy=-0.1979 gen=-7.6557\n",
            " step 1400/1981 | recon=0.0077 dz=-2.7038 dy=-0.2022 gen=-7.3837\n",
            " step 1500/1981 | recon=0.0073 dz=-2.6283 dy=-0.1961 gen=-7.7821\n",
            " step 1600/1981 | recon=0.0092 dz=-2.2104 dy=-0.1794 gen=-7.8836\n",
            " step 1700/1981 | recon=0.0088 dz=-2.3612 dy=-0.1703 gen=-7.8179\n",
            " step 1800/1981 | recon=0.0084 dz=-2.3961 dy=-0.2002 gen=-7.7732\n",
            " step 1900/1981 | recon=0.0090 dz=-2.2058 dy=-0.1986 gen=-7.5340\n",
            "[TRAIN] Epoch 16/30\n",
            " step 0/1981 | recon=0.0120 dz=-1.6840 dy=-0.1933 gen=-7.7528\n",
            " step 100/1981 | recon=0.0111 dz=-2.4701 dy=-0.2028 gen=-6.9868\n",
            " step 200/1981 | recon=0.0123 dz=-2.5452 dy=-0.2137 gen=-6.6726\n",
            " step 300/1981 | recon=0.0118 dz=-2.2399 dy=-0.2425 gen=-7.1822\n",
            " step 400/1981 | recon=0.0096 dz=-2.0800 dy=-0.2026 gen=-7.5277\n",
            " step 500/1981 | recon=0.0098 dz=-2.2523 dy=-0.2118 gen=-7.6864\n",
            " step 600/1981 | recon=0.0088 dz=-2.4236 dy=-0.2190 gen=-7.5345\n",
            " step 700/1981 | recon=0.0094 dz=-2.3182 dy=-0.2127 gen=-7.5546\n",
            " step 800/1981 | recon=0.0088 dz=-2.1533 dy=-0.2349 gen=-7.5951\n",
            " step 900/1981 | recon=0.0110 dz=-2.3893 dy=-0.1946 gen=-7.2246\n",
            " step 1000/1981 | recon=0.0116 dz=-2.4142 dy=-0.1944 gen=-6.8675\n",
            " step 1100/1981 | recon=0.0107 dz=-2.5567 dy=-0.2003 gen=-6.7241\n",
            " step 1200/1981 | recon=0.0134 dz=-2.4383 dy=-0.1920 gen=-6.9003\n",
            " step 1300/1981 | recon=0.0102 dz=-2.4049 dy=-0.2068 gen=-7.1964\n",
            " step 1400/1981 | recon=0.0083 dz=-2.3468 dy=-0.2107 gen=-7.5572\n",
            " step 1500/1981 | recon=0.0077 dz=-2.4440 dy=-0.1770 gen=-7.7443\n",
            " step 1600/1981 | recon=0.0089 dz=-2.3202 dy=-0.1941 gen=-7.6465\n",
            " step 1700/1981 | recon=0.0086 dz=-2.3454 dy=-0.1938 gen=-7.5595\n",
            " step 1800/1981 | recon=0.0081 dz=-2.1194 dy=-0.1722 gen=-7.7965\n",
            " step 1900/1981 | recon=0.0077 dz=-2.1834 dy=-0.1777 gen=-7.4907\n",
            "[TRAIN] Epoch 17/30\n",
            " step 0/1981 | recon=0.0122 dz=-1.5245 dy=-0.1771 gen=-7.7622\n",
            " step 100/1981 | recon=0.0123 dz=-2.2675 dy=-0.1799 gen=-7.3863\n",
            " step 200/1981 | recon=0.0119 dz=-2.2841 dy=-0.1891 gen=-6.9031\n",
            " step 300/1981 | recon=0.0107 dz=-2.0883 dy=-0.2208 gen=-6.8537\n",
            " step 400/1981 | recon=0.0092 dz=-2.3623 dy=-0.1870 gen=-7.6243\n",
            " step 500/1981 | recon=0.0086 dz=-2.2713 dy=-0.2361 gen=-7.7623\n",
            " step 600/1981 | recon=0.0097 dz=-2.1745 dy=-0.2187 gen=-7.8044\n",
            " step 700/1981 | recon=0.0094 dz=-2.1263 dy=-0.2252 gen=-7.7907\n",
            " step 800/1981 | recon=0.0085 dz=-2.2585 dy=-0.1962 gen=-7.7052\n",
            " step 900/1981 | recon=0.0107 dz=-2.3954 dy=-0.1772 gen=-7.1201\n",
            " step 1000/1981 | recon=0.0111 dz=-2.4830 dy=-0.1782 gen=-6.9096\n",
            " step 1100/1981 | recon=0.0097 dz=-2.3243 dy=-0.2020 gen=-6.8351\n",
            " step 1200/1981 | recon=0.0120 dz=-2.1686 dy=-0.1811 gen=-7.0022\n",
            " step 1300/1981 | recon=0.0108 dz=-2.1695 dy=-0.2015 gen=-7.2127\n",
            " step 1400/1981 | recon=0.0077 dz=-2.4887 dy=-0.1814 gen=-7.2942\n",
            " step 1500/1981 | recon=0.0078 dz=-2.4792 dy=-0.1908 gen=-7.7270\n",
            " step 1600/1981 | recon=0.0087 dz=-2.0658 dy=-0.1765 gen=-7.7671\n",
            " step 1700/1981 | recon=0.0084 dz=-2.3181 dy=-0.1732 gen=-7.8899\n",
            " step 1800/1981 | recon=0.0080 dz=-1.9570 dy=-0.1806 gen=-7.9623\n",
            " step 1900/1981 | recon=0.0083 dz=-2.0933 dy=-0.1953 gen=-7.7450\n",
            "[TRAIN] Epoch 18/30\n",
            " step 0/1981 | recon=0.0107 dz=-1.4406 dy=-0.1804 gen=-8.2372\n",
            " step 100/1981 | recon=0.0103 dz=-2.2260 dy=-0.1887 gen=-7.0618\n",
            " step 200/1981 | recon=0.0119 dz=-2.3237 dy=-0.1836 gen=-6.6688\n",
            " step 300/1981 | recon=0.0115 dz=-2.0716 dy=-0.1927 gen=-7.0818\n",
            " step 400/1981 | recon=0.0088 dz=-2.2387 dy=-0.1977 gen=-7.8083\n",
            " step 500/1981 | recon=0.0084 dz=-2.1054 dy=-0.2076 gen=-8.0453\n",
            " step 600/1981 | recon=0.0085 dz=-2.1125 dy=-0.2044 gen=-7.9744\n",
            " step 700/1981 | recon=0.0091 dz=-2.0381 dy=-0.2100 gen=-7.9952\n",
            " step 800/1981 | recon=0.0076 dz=-2.0116 dy=-0.2026 gen=-7.9307\n",
            " step 900/1981 | recon=0.0118 dz=-2.1802 dy=-0.1978 gen=-7.2622\n",
            " step 1000/1981 | recon=0.0105 dz=-2.1177 dy=-0.1811 gen=-7.2167\n",
            " step 1100/1981 | recon=0.0103 dz=-2.1873 dy=-0.1899 gen=-6.8232\n",
            " step 1200/1981 | recon=0.0127 dz=-2.2257 dy=-0.1926 gen=-6.6917\n",
            " step 1300/1981 | recon=0.0097 dz=-2.1781 dy=-0.2098 gen=-7.0353\n",
            " step 1400/1981 | recon=0.0072 dz=-2.5764 dy=-0.1831 gen=-7.5923\n",
            " step 1500/1981 | recon=0.0071 dz=-2.2297 dy=-0.1649 gen=-8.2650\n",
            " step 1600/1981 | recon=0.0084 dz=-2.0704 dy=-0.1822 gen=-8.3275\n",
            " step 1700/1981 | recon=0.0074 dz=-2.1500 dy=-0.1930 gen=-8.4664\n",
            " step 1800/1981 | recon=0.0070 dz=-1.9731 dy=-0.1786 gen=-8.3027\n",
            " step 1900/1981 | recon=0.0079 dz=-2.0167 dy=-0.1809 gen=-8.4933\n",
            "[TRAIN] Epoch 19/30\n",
            " step 0/1981 | recon=0.0107 dz=-1.5064 dy=-0.1968 gen=-8.5873\n",
            " step 100/1981 | recon=0.0108 dz=-1.9870 dy=-0.1800 gen=-7.4752\n",
            " step 200/1981 | recon=0.0110 dz=-2.2296 dy=-0.1609 gen=-7.0727\n",
            " step 300/1981 | recon=0.0108 dz=-2.0688 dy=-0.2039 gen=-7.1426\n",
            " step 400/1981 | recon=0.0089 dz=-1.8176 dy=-0.2125 gen=-8.0786\n",
            " step 500/1981 | recon=0.0087 dz=-1.8718 dy=-0.2125 gen=-8.9528\n",
            " step 600/1981 | recon=0.0079 dz=-2.1042 dy=-0.2016 gen=-8.7626\n",
            " step 700/1981 | recon=0.0091 dz=-1.8661 dy=-0.1989 gen=-8.7795\n",
            " step 800/1981 | recon=0.0081 dz=-1.8087 dy=-0.2000 gen=-9.0082\n",
            " step 900/1981 | recon=0.0091 dz=-2.0520 dy=-0.1895 gen=-7.8871\n",
            " step 1000/1981 | recon=0.0108 dz=-2.0749 dy=-0.1842 gen=-7.4615\n",
            " step 1100/1981 | recon=0.0094 dz=-2.1101 dy=-0.2000 gen=-7.0880\n",
            " step 1200/1981 | recon=0.0120 dz=-2.0666 dy=-0.1829 gen=-6.8140\n",
            " step 1300/1981 | recon=0.0113 dz=-1.9243 dy=-0.1929 gen=-6.8035\n",
            " step 1400/1981 | recon=0.0071 dz=-2.2402 dy=-0.1876 gen=-7.5883\n",
            " step 1500/1981 | recon=0.0063 dz=-2.2463 dy=-0.1734 gen=-8.4133\n",
            " step 1600/1981 | recon=0.0074 dz=-2.0625 dy=-0.1902 gen=-8.4416\n",
            " step 1700/1981 | recon=0.0078 dz=-1.9069 dy=-0.1773 gen=-8.7115\n",
            " step 1800/1981 | recon=0.0074 dz=-1.7191 dy=-0.1863 gen=-9.1836\n",
            " step 1900/1981 | recon=0.0081 dz=-1.8791 dy=-0.1781 gen=-9.0972\n",
            "[TRAIN] Epoch 20/30\n",
            " step 0/1981 | recon=0.0104 dz=-1.0812 dy=-0.1862 gen=-9.5802\n",
            " step 100/1981 | recon=0.0098 dz=-1.9092 dy=-0.1853 gen=-8.2808\n",
            " step 200/1981 | recon=0.0115 dz=-2.3715 dy=-0.1922 gen=-6.9573\n",
            " step 300/1981 | recon=0.0089 dz=-1.8016 dy=-0.2084 gen=-7.5800\n",
            " step 400/1981 | recon=0.0085 dz=-1.9686 dy=-0.2145 gen=-8.4837\n",
            " step 500/1981 | recon=0.0087 dz=-1.5666 dy=-0.2016 gen=-9.5410\n",
            " step 600/1981 | recon=0.0082 dz=-1.6254 dy=-0.2078 gen=-9.4146\n",
            " step 700/1981 | recon=0.0080 dz=-1.7239 dy=-0.2044 gen=-9.1816\n",
            " step 800/1981 | recon=0.0077 dz=-1.6972 dy=-0.2155 gen=-9.3523\n",
            " step 900/1981 | recon=0.0105 dz=-2.0601 dy=-0.1778 gen=-8.4457\n",
            " step 1000/1981 | recon=0.0107 dz=-2.2674 dy=-0.1890 gen=-7.7854\n",
            " step 1100/1981 | recon=0.0096 dz=-2.0572 dy=-0.1862 gen=-7.0918\n",
            " step 1200/1981 | recon=0.0124 dz=-2.3351 dy=-0.1815 gen=-6.3641\n",
            " step 1300/1981 | recon=0.0097 dz=-1.7963 dy=-0.1733 gen=-6.9470\n",
            " step 1400/1981 | recon=0.0072 dz=-2.0464 dy=-0.1878 gen=-7.4741\n",
            " step 1500/1981 | recon=0.0061 dz=-2.0241 dy=-0.1832 gen=-8.6971\n",
            " step 1600/1981 | recon=0.0080 dz=-1.7900 dy=-0.1880 gen=-8.9250\n",
            " step 1700/1981 | recon=0.0074 dz=-1.8670 dy=-0.1923 gen=-9.2165\n",
            " step 1800/1981 | recon=0.0073 dz=-1.8696 dy=-0.1677 gen=-9.4069\n",
            " step 1900/1981 | recon=0.0071 dz=-1.6547 dy=-0.1606 gen=-9.3894\n",
            "[TRAIN] Epoch 21/30\n",
            " step 0/1981 | recon=0.0110 dz=-0.6821 dy=-0.1775 gen=-9.7625\n",
            " step 100/1981 | recon=0.0105 dz=-1.9121 dy=-0.1890 gen=-7.9895\n",
            " step 200/1981 | recon=0.0120 dz=-2.1276 dy=-0.1684 gen=-6.9861\n",
            " step 300/1981 | recon=0.0090 dz=-1.7533 dy=-0.1991 gen=-7.4344\n",
            " step 400/1981 | recon=0.0077 dz=-1.7942 dy=-0.1939 gen=-8.4538\n",
            " step 500/1981 | recon=0.0081 dz=-1.8429 dy=-0.2105 gen=-9.5979\n",
            " step 600/1981 | recon=0.0080 dz=-1.6256 dy=-0.1902 gen=-9.9427\n",
            " step 700/1981 | recon=0.0082 dz=-1.4890 dy=-0.1916 gen=-10.0081\n",
            " step 800/1981 | recon=0.0083 dz=-1.3983 dy=-0.2021 gen=-9.8770\n",
            " step 900/1981 | recon=0.0095 dz=-1.7076 dy=-0.1690 gen=-8.7412\n",
            " step 1000/1981 | recon=0.0090 dz=-1.8776 dy=-0.1747 gen=-7.9525\n",
            " step 1100/1981 | recon=0.0103 dz=-1.9097 dy=-0.1878 gen=-7.3112\n",
            " step 1200/1981 | recon=0.0125 dz=-1.9126 dy=-0.1724 gen=-6.6521\n",
            " step 1300/1981 | recon=0.0082 dz=-1.8283 dy=-0.1798 gen=-7.0347\n",
            " step 1400/1981 | recon=0.0071 dz=-1.9555 dy=-0.1887 gen=-8.0636\n",
            " step 1500/1981 | recon=0.0066 dz=-1.8421 dy=-0.1861 gen=-9.4170\n",
            " step 1600/1981 | recon=0.0080 dz=-1.7410 dy=-0.1768 gen=-9.7253\n",
            " step 1700/1981 | recon=0.0068 dz=-1.7571 dy=-0.1857 gen=-10.0772\n",
            " step 1800/1981 | recon=0.0069 dz=-1.5202 dy=-0.1857 gen=-10.1414\n",
            " step 1900/1981 | recon=0.0068 dz=-1.4981 dy=-0.1782 gen=-10.3842\n",
            "[TRAIN] Epoch 22/30\n",
            " step 0/1981 | recon=0.0107 dz=-0.6339 dy=-0.1772 gen=-10.5788\n",
            " step 100/1981 | recon=0.0111 dz=-1.7888 dy=-0.1581 gen=-7.9257\n",
            " step 200/1981 | recon=0.0103 dz=-1.5461 dy=-0.1841 gen=-7.9007\n",
            " step 300/1981 | recon=0.0091 dz=-1.4455 dy=-0.2100 gen=-7.9795\n",
            " step 400/1981 | recon=0.0094 dz=-1.5039 dy=-0.2194 gen=-8.9035\n",
            " step 500/1981 | recon=0.0075 dz=-1.5443 dy=-0.1950 gen=-10.2956\n",
            " step 600/1981 | recon=0.0077 dz=-1.4589 dy=-0.1974 gen=-10.5167\n",
            " step 700/1981 | recon=0.0082 dz=-1.4129 dy=-0.2072 gen=-10.1555\n",
            " step 800/1981 | recon=0.0074 dz=-1.6329 dy=-0.2063 gen=-10.2193\n",
            " step 900/1981 | recon=0.0106 dz=-1.6155 dy=-0.1890 gen=-8.9216\n",
            " step 1000/1981 | recon=0.0095 dz=-1.8311 dy=-0.1848 gen=-7.9517\n",
            " step 1100/1981 | recon=0.0081 dz=-1.5077 dy=-0.1893 gen=-7.5305\n",
            " step 1200/1981 | recon=0.0120 dz=-1.6344 dy=-0.1630 gen=-6.4223\n",
            " step 1300/1981 | recon=0.0088 dz=-1.5038 dy=-0.1838 gen=-6.6603\n",
            " step 1400/1981 | recon=0.0063 dz=-1.8569 dy=-0.2047 gen=-7.5964\n",
            " step 1500/1981 | recon=0.0060 dz=-1.6614 dy=-0.1826 gen=-9.5050\n",
            " step 1600/1981 | recon=0.0076 dz=-1.5789 dy=-0.1862 gen=-9.7801\n",
            " step 1700/1981 | recon=0.0072 dz=-1.6071 dy=-0.1864 gen=-10.4455\n",
            " step 1800/1981 | recon=0.0069 dz=-1.3785 dy=-0.1746 gen=-10.8106\n",
            " step 1900/1981 | recon=0.0064 dz=-1.4931 dy=-0.1678 gen=-10.8396\n",
            "[TRAIN] Epoch 23/30\n",
            " step 0/1981 | recon=0.0100 dz=-0.2702 dy=-0.1735 gen=-11.7346\n",
            " step 100/1981 | recon=0.0104 dz=-1.2942 dy=-0.1951 gen=-9.3648\n",
            " step 200/1981 | recon=0.0096 dz=-1.4709 dy=-0.1811 gen=-7.7884\n",
            " step 300/1981 | recon=0.0092 dz=-1.4107 dy=-0.1867 gen=-7.8783\n",
            " step 400/1981 | recon=0.0081 dz=-1.5402 dy=-0.2016 gen=-8.9225\n",
            " step 500/1981 | recon=0.0080 dz=-1.6391 dy=-0.1888 gen=-10.4272\n",
            " step 600/1981 | recon=0.0078 dz=-1.3762 dy=-0.2170 gen=-10.6262\n",
            " step 700/1981 | recon=0.0075 dz=-1.4410 dy=-0.1830 gen=-10.7204\n",
            " step 800/1981 | recon=0.0074 dz=-1.2252 dy=-0.2018 gen=-11.1013\n",
            " step 900/1981 | recon=0.0097 dz=-1.4867 dy=-0.1782 gen=-9.5401\n",
            " step 1000/1981 | recon=0.0078 dz=-1.7368 dy=-0.1700 gen=-8.1986\n",
            " step 1100/1981 | recon=0.0089 dz=-1.4979 dy=-0.1805 gen=-8.0273\n",
            " step 1200/1981 | recon=0.0126 dz=-1.8332 dy=-0.1548 gen=-6.4861\n",
            " step 1300/1981 | recon=0.0093 dz=-1.3302 dy=-0.1771 gen=-6.8691\n",
            " step 1400/1981 | recon=0.0066 dz=-1.6761 dy=-0.1901 gen=-8.2871\n",
            " step 1500/1981 | recon=0.0065 dz=-1.5508 dy=-0.1628 gen=-10.4015\n",
            " step 1600/1981 | recon=0.0069 dz=-1.3392 dy=-0.1702 gen=-10.6233\n",
            " step 1700/1981 | recon=0.0066 dz=-1.2261 dy=-0.1778 gen=-11.7489\n",
            " step 1800/1981 | recon=0.0070 dz=-1.2903 dy=-0.1674 gen=-12.0437\n",
            " step 1900/1981 | recon=0.0063 dz=-1.2423 dy=-0.1670 gen=-12.2932\n",
            "[TRAIN] Epoch 24/30\n",
            " step 0/1981 | recon=0.0094 dz=-0.6590 dy=-0.1682 gen=-12.7106\n",
            " step 100/1981 | recon=0.0107 dz=-1.3402 dy=-0.1685 gen=-10.4444\n",
            " step 200/1981 | recon=0.0104 dz=-1.6615 dy=-0.1578 gen=-8.5488\n",
            " step 300/1981 | recon=0.0096 dz=-1.3544 dy=-0.1977 gen=-8.8043\n",
            " step 400/1981 | recon=0.0080 dz=-1.2987 dy=-0.1825 gen=-10.0018\n",
            " step 500/1981 | recon=0.0076 dz=-1.4543 dy=-0.1761 gen=-11.4064\n",
            " step 600/1981 | recon=0.0077 dz=-1.2302 dy=-0.1865 gen=-12.1065\n",
            " step 700/1981 | recon=0.0070 dz=-1.3110 dy=-0.1840 gen=-12.1678\n",
            " step 800/1981 | recon=0.0067 dz=-1.1821 dy=-0.1771 gen=-12.1925\n",
            " step 900/1981 | recon=0.0083 dz=-1.1695 dy=-0.1524 gen=-10.7599\n",
            " step 1000/1981 | recon=0.0095 dz=-1.4717 dy=-0.1831 gen=-9.2990\n",
            " step 1100/1981 | recon=0.0086 dz=-1.5595 dy=-0.1714 gen=-7.8905\n",
            " step 1200/1981 | recon=0.0113 dz=-1.8037 dy=-0.1476 gen=-6.6447\n",
            " step 1300/1981 | recon=0.0089 dz=-1.3071 dy=-0.1784 gen=-7.2822\n",
            " step 1400/1981 | recon=0.0066 dz=-1.5755 dy=-0.1663 gen=-9.1641\n",
            " step 1500/1981 | recon=0.0063 dz=-1.3353 dy=-0.1804 gen=-11.2171\n",
            " step 1600/1981 | recon=0.0071 dz=-1.2341 dy=-0.1792 gen=-11.9555\n",
            " step 1700/1981 | recon=0.0067 dz=-1.2101 dy=-0.1756 gen=-12.3607\n",
            " step 1800/1981 | recon=0.0069 dz=-0.9546 dy=-0.1718 gen=-13.6224\n",
            " step 1900/1981 | recon=0.0062 dz=-0.8922 dy=-0.1774 gen=-13.9141\n",
            "[TRAIN] Epoch 25/30\n",
            " step 0/1981 | recon=0.0100 dz=0.0829 dy=-0.1617 gen=-14.3994\n",
            " step 100/1981 | recon=0.0105 dz=-1.1935 dy=-0.1579 gen=-11.0470\n",
            " step 200/1981 | recon=0.0099 dz=-1.1122 dy=-0.1664 gen=-9.5641\n",
            " step 300/1981 | recon=0.0089 dz=-0.8675 dy=-0.1933 gen=-9.2581\n",
            " step 400/1981 | recon=0.0082 dz=-1.0048 dy=-0.2045 gen=-10.9287\n",
            " step 500/1981 | recon=0.0079 dz=-1.0255 dy=-0.1894 gen=-12.2535\n",
            " step 600/1981 | recon=0.0077 dz=-0.8924 dy=-0.1953 gen=-13.1361\n",
            " step 700/1981 | recon=0.0069 dz=-1.0567 dy=-0.1776 gen=-13.3331\n",
            " step 800/1981 | recon=0.0069 dz=-0.8696 dy=-0.1952 gen=-13.6389\n",
            " step 900/1981 | recon=0.0095 dz=-0.9201 dy=-0.1760 gen=-12.3700\n",
            " step 1000/1981 | recon=0.0090 dz=-0.9478 dy=-0.1727 gen=-11.2033\n",
            " step 1100/1981 | recon=0.0078 dz=-1.3357 dy=-0.1836 gen=-9.4496\n",
            " step 1200/1981 | recon=0.0118 dz=-1.5111 dy=-0.1640 gen=-7.6948\n",
            " step 1300/1981 | recon=0.0089 dz=-1.1487 dy=-0.1686 gen=-8.4995\n",
            " step 1400/1981 | recon=0.0063 dz=-1.2235 dy=-0.1724 gen=-10.5105\n",
            " step 1500/1981 | recon=0.0059 dz=-1.1745 dy=-0.1842 gen=-13.1724\n",
            " step 1600/1981 | recon=0.0070 dz=-1.1368 dy=-0.1786 gen=-14.3375\n",
            " step 1700/1981 | recon=0.0066 dz=-0.9810 dy=-0.1756 gen=-15.1475\n",
            " step 1800/1981 | recon=0.0063 dz=-0.7148 dy=-0.1874 gen=-16.3342\n",
            " step 1900/1981 | recon=0.0064 dz=-0.7143 dy=-0.1734 gen=-16.6821\n",
            "[TRAIN] Epoch 26/30\n",
            " step 0/1981 | recon=0.0094 dz=0.1876 dy=-0.1617 gen=-18.1904\n",
            " step 100/1981 | recon=0.0095 dz=-0.7525 dy=-0.1745 gen=-15.6490\n",
            " step 200/1981 | recon=0.0112 dz=-0.6815 dy=-0.1561 gen=-13.9598\n",
            " step 300/1981 | recon=0.0087 dz=-0.5799 dy=-0.1844 gen=-13.7637\n",
            " step 400/1981 | recon=0.0084 dz=-0.5115 dy=-0.1665 gen=-14.8732\n",
            " step 500/1981 | recon=0.0077 dz=-0.4025 dy=-0.2023 gen=-15.9953\n",
            " step 600/1981 | recon=0.0069 dz=-0.5955 dy=-0.2036 gen=-17.0169\n",
            " step 700/1981 | recon=0.0073 dz=-0.6252 dy=-0.1921 gen=-17.9909\n",
            " step 800/1981 | recon=0.0072 dz=-0.5158 dy=-0.1795 gen=-18.2790\n",
            " step 900/1981 | recon=0.0095 dz=-0.5185 dy=-0.1650 gen=-17.4210\n",
            " step 1000/1981 | recon=0.0084 dz=-0.4807 dy=-0.1625 gen=-16.6256\n",
            " step 1100/1981 | recon=0.0090 dz=-0.7736 dy=-0.1651 gen=-15.0204\n",
            " step 1200/1981 | recon=0.0100 dz=-0.6371 dy=-0.1759 gen=-13.3824\n",
            " step 1300/1981 | recon=0.0086 dz=-0.4112 dy=-0.1730 gen=-12.7801\n",
            " step 1400/1981 | recon=0.0069 dz=-0.8044 dy=-0.1899 gen=-14.8603\n",
            " step 1500/1981 | recon=0.0059 dz=-0.9154 dy=-0.1779 gen=-17.1841\n",
            " step 1600/1981 | recon=0.0076 dz=-0.3224 dy=-0.1771 gen=-18.2640\n",
            " step 1700/1981 | recon=0.0064 dz=-0.5466 dy=-0.1699 gen=-19.4038\n",
            " step 1800/1981 | recon=0.0064 dz=-0.4710 dy=-0.1851 gen=-20.4483\n",
            " step 1900/1981 | recon=0.0060 dz=-0.3468 dy=-0.1931 gen=-20.7077\n",
            "[TRAIN] Epoch 27/30\n",
            " step 0/1981 | recon=0.0096 dz=0.2961 dy=-0.1602 gen=-21.7000\n",
            " step 100/1981 | recon=0.0097 dz=-0.4761 dy=-0.1614 gen=-19.0041\n",
            " step 200/1981 | recon=0.0090 dz=-0.3539 dy=-0.1643 gen=-18.0643\n",
            " step 300/1981 | recon=0.0083 dz=0.0744 dy=-0.1645 gen=-17.7070\n",
            " step 400/1981 | recon=0.0076 dz=-0.1240 dy=-0.2136 gen=-18.8514\n",
            " step 500/1981 | recon=0.0077 dz=-0.0849 dy=-0.1870 gen=-20.5331\n",
            " step 600/1981 | recon=0.0067 dz=-0.2324 dy=-0.1907 gen=-21.2571\n",
            " step 700/1981 | recon=0.0071 dz=0.0209 dy=-0.1866 gen=-21.4050\n",
            " step 800/1981 | recon=0.0066 dz=-0.0791 dy=-0.1867 gen=-22.2733\n",
            " step 900/1981 | recon=0.0093 dz=0.1468 dy=-0.1623 gen=-21.3548\n",
            " step 1000/1981 | recon=0.0090 dz=-0.2903 dy=-0.1874 gen=-19.8955\n",
            " step 1100/1981 | recon=0.0075 dz=-0.2834 dy=-0.1645 gen=-19.1348\n",
            " step 1200/1981 | recon=0.0103 dz=0.0233 dy=-0.1682 gen=-17.7433\n",
            " step 1300/1981 | recon=0.0082 dz=-0.0191 dy=-0.1829 gen=-17.7532\n",
            " step 1400/1981 | recon=0.0060 dz=-0.2706 dy=-0.1949 gen=-19.2785\n",
            " step 1500/1981 | recon=0.0064 dz=-0.1226 dy=-0.1596 gen=-21.4364\n",
            " step 1600/1981 | recon=0.0074 dz=-0.2651 dy=-0.1772 gen=-21.9245\n",
            " step 1700/1981 | recon=0.0063 dz=-0.0787 dy=-0.1715 gen=-22.8335\n",
            " step 1800/1981 | recon=0.0063 dz=-0.2765 dy=-0.1823 gen=-23.6575\n",
            " step 1900/1981 | recon=0.0059 dz=-0.0745 dy=-0.1773 gen=-24.2151\n",
            "[TRAIN] Epoch 28/30\n",
            " step 0/1981 | recon=0.0090 dz=0.7572 dy=-0.1741 gen=-25.2422\n",
            " step 100/1981 | recon=0.0088 dz=0.2515 dy=-0.1661 gen=-23.2757\n",
            " step 200/1981 | recon=0.0098 dz=0.1234 dy=-0.1826 gen=-21.8816\n",
            " step 300/1981 | recon=0.0094 dz=0.1040 dy=-0.1871 gen=-21.1560\n",
            " step 400/1981 | recon=0.0078 dz=0.1482 dy=-0.2251 gen=-22.1894\n",
            " step 500/1981 | recon=0.0076 dz=-0.1952 dy=-0.1673 gen=-23.3032\n",
            " step 600/1981 | recon=0.0074 dz=0.1796 dy=-0.2263 gen=-23.8891\n",
            " step 700/1981 | recon=0.0073 dz=0.2006 dy=-0.2034 gen=-24.3135\n",
            " step 800/1981 | recon=0.0071 dz=0.1595 dy=-0.1909 gen=-24.1002\n",
            " step 900/1981 | recon=0.0082 dz=0.3156 dy=-0.1891 gen=-23.0589\n",
            " step 1000/1981 | recon=0.0094 dz=0.0398 dy=-0.1918 gen=-22.0904\n",
            " step 1100/1981 | recon=0.0076 dz=0.4142 dy=-0.1733 gen=-21.7334\n",
            " step 1200/1981 | recon=0.0103 dz=0.0148 dy=-0.1624 gen=-20.6200\n",
            " step 1300/1981 | recon=0.0085 dz=0.4961 dy=-0.1838 gen=-20.4482\n",
            " step 1400/1981 | recon=0.0058 dz=0.2086 dy=-0.1858 gen=-21.8933\n",
            " step 1500/1981 | recon=0.0057 dz=0.3049 dy=-0.2110 gen=-22.8525\n",
            " step 1600/1981 | recon=0.0062 dz=0.1601 dy=-0.1716 gen=-23.4099\n",
            " step 1700/1981 | recon=0.0063 dz=0.3900 dy=-0.1801 gen=-23.5014\n",
            " step 1800/1981 | recon=0.0060 dz=-0.0084 dy=-0.1900 gen=-23.7384\n",
            " step 1900/1981 | recon=0.0058 dz=0.1999 dy=-0.1719 gen=-24.1536\n",
            "[TRAIN] Epoch 29/30\n",
            " step 0/1981 | recon=0.0081 dz=0.7858 dy=-0.1815 gen=-24.6271\n",
            " step 100/1981 | recon=0.0088 dz=0.4632 dy=-0.1561 gen=-22.8579\n",
            " step 200/1981 | recon=0.0100 dz=0.1103 dy=-0.1707 gen=-21.0054\n",
            " step 300/1981 | recon=0.0084 dz=0.3844 dy=-0.1731 gen=-20.7744\n",
            " step 400/1981 | recon=0.0082 dz=0.8183 dy=-0.1767 gen=-21.8056\n",
            " step 500/1981 | recon=0.0073 dz=0.3660 dy=-0.1647 gen=-22.4732\n",
            " step 600/1981 | recon=0.0075 dz=0.6808 dy=-0.2045 gen=-23.4040\n",
            " step 700/1981 | recon=0.0076 dz=0.5804 dy=-0.1995 gen=-24.1185\n",
            " step 800/1981 | recon=0.0070 dz=0.7701 dy=-0.1801 gen=-24.3228\n",
            " step 900/1981 | recon=0.0079 dz=0.4501 dy=-0.1637 gen=-23.6245\n",
            " step 1000/1981 | recon=0.0084 dz=0.4106 dy=-0.1822 gen=-22.9542\n",
            " step 1100/1981 | recon=0.0087 dz=0.5108 dy=-0.1604 gen=-22.1578\n",
            " step 1200/1981 | recon=0.0093 dz=0.1075 dy=-0.1552 gen=-21.0927\n",
            " step 1300/1981 | recon=0.0083 dz=0.6631 dy=-0.1574 gen=-21.1087\n",
            " step 1400/1981 | recon=0.0059 dz=0.5956 dy=-0.1670 gen=-22.0038\n",
            " step 1500/1981 | recon=0.0059 dz=0.7036 dy=-0.1675 gen=-23.0249\n",
            " step 1600/1981 | recon=0.0068 dz=0.7190 dy=-0.1701 gen=-23.1302\n",
            " step 1700/1981 | recon=0.0063 dz=0.7428 dy=-0.1843 gen=-22.8541\n",
            " step 1800/1981 | recon=0.0064 dz=0.6004 dy=-0.1658 gen=-22.5567\n",
            " step 1900/1981 | recon=0.0059 dz=0.7740 dy=-0.1728 gen=-22.3875\n",
            "[TRAIN] Epoch 30/30\n",
            " step 0/1981 | recon=0.0087 dz=1.2608 dy=-0.1655 gen=-22.5381\n",
            " step 100/1981 | recon=0.0096 dz=1.2245 dy=-0.1843 gen=-21.4463\n",
            " step 200/1981 | recon=0.0079 dz=1.0763 dy=-0.1472 gen=-20.0969\n",
            " step 300/1981 | recon=0.0079 dz=0.9038 dy=-0.1887 gen=-19.3870\n",
            " step 400/1981 | recon=0.0065 dz=0.8696 dy=-0.1772 gen=-19.3638\n",
            " step 500/1981 | recon=0.0070 dz=0.5538 dy=-0.2057 gen=-19.6378\n",
            " step 600/1981 | recon=0.0075 dz=0.6029 dy=-0.2085 gen=-20.1206\n",
            " step 700/1981 | recon=0.0073 dz=0.7011 dy=-0.2139 gen=-20.4120\n",
            " step 800/1981 | recon=0.0064 dz=0.7479 dy=-0.1914 gen=-20.4839\n",
            " step 900/1981 | recon=0.0089 dz=0.7094 dy=-0.1650 gen=-20.2282\n",
            " step 1000/1981 | recon=0.0085 dz=0.3964 dy=-0.1607 gen=-19.3877\n",
            " step 1100/1981 | recon=0.0070 dz=0.4682 dy=-0.1639 gen=-19.1687\n",
            " step 1200/1981 | recon=0.0106 dz=-0.0214 dy=-0.1631 gen=-18.1761\n",
            " step 1300/1981 | recon=0.0075 dz=0.7420 dy=-0.1822 gen=-18.2812\n",
            " step 1400/1981 | recon=0.0062 dz=0.8523 dy=-0.1862 gen=-18.9000\n",
            " step 1500/1981 | recon=0.0058 dz=0.9840 dy=-0.1695 gen=-19.8335\n",
            " step 1600/1981 | recon=0.0067 dz=1.1841 dy=-0.1785 gen=-20.1696\n",
            " step 1700/1981 | recon=0.0061 dz=0.8369 dy=-0.1685 gen=-20.1705\n",
            " step 1800/1981 | recon=0.0061 dz=0.8746 dy=-0.1579 gen=-19.9486\n",
            " step 1900/1981 | recon=0.0056 dz=0.9340 dy=-0.1512 gen=-19.8993\n",
            "[SAVE] Encoder & decoder saved\n",
            "[RESULT] ROC AUC: 0.9651, Thr: 0.016098, TPR: 0.934, FPR: 0.105\n",
            "[RESULT] Confusion Matrix:\n",
            "[[48640  5736]\n",
            " [ 2023 28686]]\n",
            "[RESULT] Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.96      0.89      0.93     54376\n",
            "      Attack       0.83      0.93      0.88     30709\n",
            "\n",
            "    accuracy                           0.91     85085\n",
            "   macro avg       0.90      0.91      0.90     85085\n",
            "weighted avg       0.91      0.91      0.91     85085\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0) GPU setup (optional)\n",
        "# ------------------------------------------------------------\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Hyperparameters\n",
        "# ------------------------------------------------------------\n",
        "FEATURE_DIM = 29 * 29 * 2\n",
        "N_LABELS   = 2\n",
        "BATCH      = 128\n",
        "EPOCHS     = 30\n",
        "\n",
        "# AAE-specific\n",
        "N_L1       = 1024\n",
        "N_L2       = 768\n",
        "LATENT_DIM = 64\n",
        "λ_gp       = 10.0\n",
        "\n",
        "# Learning rates\n",
        "LR_AE = 0.0005\n",
        "LR_DZ = 0.0001\n",
        "LR_DY = 0.0001\n",
        "LR_G  = 5e-5\n",
        "\n",
        "# Architecture options\n",
        "ACTIVATION = 'elu'\n",
        "DROPOUT    = 0.2\n",
        "NORM_TYPE  = 'layer'  # 'layer' or 'batch'\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Helper functions: preprocessing & TFRecord creation\n",
        "# ------------------------------------------------------------\n",
        "datasets = ['DoS', 'Fuzzy', 'RPM', 'gear', 'parsed_dataset','File_1','File_2','File_3','File_4','File_5','File_6','File_7','File_8']\n",
        "csv_map = {\n",
        "    'DoS': 'DoS_dataset.csv',\n",
        "    'Fuzzy': 'Fuzzy_dataset.csv',\n",
        "    'RPM': 'RPM_dataset.csv',\n",
        "    'gear': 'gear_dataset.csv',\n",
        "    'parsed_dataset': 'parsed_dataset.csv',\n",
        "    'File_1': 'File_1.csv',\n",
        "    'File_2': 'File_2.csv',\n",
        "    'File_3': 'File_3.csv',\n",
        "    'File_4': 'File_4.csv',\n",
        "    'File_5': 'File_5.csv',\n",
        "    'File_6': 'File_6.csv',\n",
        "    'File_7': 'File_7.csv',\n",
        "    'File_8': 'File_8.csv'\n",
        "}\n",
        "\n",
        "def fill_flag(row):\n",
        "    if not isinstance(row['Flag'], str):\n",
        "        col = 'Data' + str(int(row['DLC']))\n",
        "        row['Flag'] = row.get(col, row['Flag'])\n",
        "    return row\n",
        "\n",
        "def convert_canid_bits(cid):\n",
        "    try:\n",
        "        b = bin(int(str(cid), 16))[2:].zfill(29)\n",
        "        return np.array(list(map(int, b)), dtype=np.uint8)\n",
        "    except:\n",
        "        return np.zeros(29, dtype=np.uint8)\n",
        "\n",
        "def hex_to_int(x):\n",
        "    try:\n",
        "        return int(str(x).strip(), 16)\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def preprocess_windows(csv_file):\n",
        "    print(f\"[DATA] Processing {csv_file}\")\n",
        "    attrs = ['Timestamp', 'canID', 'DLC'] + [f'Data{i}' for i in range(8)] + ['Flag']\n",
        "    df = pd.read_csv(csv_file, header=None, names=attrs, low_memory=False)\n",
        "    df['Timestamp'] = pd.to_numeric(df['Timestamp'], errors='coerce')\n",
        "    df['DLC']       = pd.to_numeric(df['DLC'], errors='coerce').fillna(0).astype(int)\n",
        "    df = df.dropna(subset=['Timestamp', 'canID']).apply(fill_flag, axis=1)\n",
        "    for i in range(8):\n",
        "        df[f'Data{i}'] = df[f'Data{i}'].apply(hex_to_int).astype(np.uint8)\n",
        "    df['Flag']    = df['Flag'].astype(str).str.upper().eq('T').astype(np.uint8)\n",
        "    df['canBits'] = df['canID'].apply(convert_canid_bits)\n",
        "    df = df.sort_values('Timestamp')\n",
        "\n",
        "    bits_all   = np.stack(df['canBits'].values)\n",
        "    data_bytes = df[[f'Data{i}' for i in range(8)]].values\n",
        "    flags_all  = df['Flag'].values\n",
        "\n",
        "    win = 29\n",
        "    N   = len(bits_all) // win\n",
        "    bits   = bits_all[:N * win].reshape(N, win, 29)\n",
        "    data   = data_bytes[:N * win].reshape(N, win, 8)\n",
        "    flags  = flags_all[:N * win].reshape(N, win)\n",
        "\n",
        "    rows = []\n",
        "    for i in range(N):\n",
        "        id_img   = bits[i].astype(np.uint8)\n",
        "        last_b   = data[i, -1, :]\n",
        "        b8       = np.unpackbits(last_b, axis=0).reshape(8,8)\n",
        "        data_img = cv2.resize(b8.astype(np.float32), (29,29), interpolation=cv2.INTER_NEAREST) > 0.5\n",
        "        two_ch   = np.stack([id_img, data_img.astype(np.uint8)], axis=-1)\n",
        "        feat_int = two_ch.flatten().tolist()\n",
        "        lbl      = int(flags[i].any())\n",
        "        rows.append((feat_int, lbl))\n",
        "    return rows\n",
        "\n",
        "def write_tfrecord(rows, base):\n",
        "    np.random.shuffle(rows)\n",
        "    ntr = int(0.7 * len(rows))\n",
        "    nvl = int(0.15 * len(rows))\n",
        "    splits = {'train': rows[:ntr], 'val': rows[ntr:ntr+nvl], 'test': rows[ntr+nvl:]}\n",
        "    for ph, ch in splits.items():\n",
        "        fn = f\"{base}_{ph}.tfrecord\"\n",
        "        with tf.io.TFRecordWriter(fn) as writer:\n",
        "            for feat, lbl in ch:\n",
        "                ex = tf.train.Example(features=tf.train.Features(feature={\n",
        "                    'features': tf.train.Feature(int64_list=tf.train.Int64List(value=feat)),\n",
        "                    'label':    tf.train.Feature(int64_list=tf.train.Int64List(value=[lbl]))\n",
        "                }))\n",
        "                writer.write(ex.SerializeToString())\n",
        "\n",
        "# Create/check TFRecords\n",
        "expected = []\n",
        "for a in datasets:\n",
        "    for ph in ('train', 'val', 'test'):\n",
        "        expected.append(f\"{a}_{ph}.tfrecord\")\n",
        "        if a != 'parsed_dataset':\n",
        "            expected.append(f\"Normal_{a}_{ph}.tfrecord\")\n",
        "if not all(os.path.exists(f) for f in expected):\n",
        "    print(\"[DATA] TFRecords missing, preprocessing...\")\n",
        "    for a in datasets:\n",
        "        src = csv_map[a]\n",
        "        if not os.path.exists(src):\n",
        "            print(f\"[WARN] {src} not found\")\n",
        "        else:\n",
        "            rows    = preprocess_windows(src)\n",
        "            normals = [r for r in rows if r[1] == 0]\n",
        "            attacks = [r for r in rows if r[1] == 1]\n",
        "            write_tfrecord(normals, f\"Normal_{a}\")\n",
        "            if attacks:\n",
        "                write_tfrecord(attacks, a)\n",
        "else:\n",
        "    print(\"[DATA] All TFRecords found.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) tf.data pipeline\n",
        "# ------------------------------------------------------------\n",
        "def parse_feat(proto):\n",
        "    feat = tf.io.parse_single_example(proto, {\n",
        "        'features': tf.io.FixedLenFeature([FEATURE_DIM], tf.int64),\n",
        "        'label':    tf.io.FixedLenFeature([1], tf.int64)\n",
        "    })\n",
        "    x = tf.cast(feat['features'], tf.float32)\n",
        "    y = tf.one_hot(tf.cast(feat['label'][0], tf.int32), N_LABELS)\n",
        "    return x, y\n",
        "\n",
        "train_files = glob.glob('Normal_*_train.tfrecord')\n",
        "train_ds = (\n",
        "    tf.data.TFRecordDataset(train_files, num_parallel_reads=tf.data.AUTOTUNE)\n",
        "    .map(parse_feat, tf.data.AUTOTUNE)\n",
        "    .map(lambda x, y: (x + tf.random.normal(tf.shape(x), 0, 0.01), x, y), tf.data.AUTOTUNE)\n",
        "    .shuffle(10000).repeat()\n",
        "    .batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "total = sum(1 for _ in tf.data.TFRecordDataset(train_files))\n",
        "steps_per_epoch = total // BATCH\n",
        "print(f\"[PIPE] Total records: {total}, steps/epoch: {steps_per_epoch}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) AAE Model definition\n",
        "# ------------------------------------------------------------\n",
        "class AAE(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def dense_block(units):\n",
        "            layers = [tf.keras.layers.Dense(units)]\n",
        "            if NORM_TYPE == 'layer': layers.append(tf.keras.layers.LayerNormalization())\n",
        "            elif NORM_TYPE == 'batch': layers.append(tf.keras.layers.BatchNormalization())\n",
        "            layers.append(tf.keras.layers.Activation(ACTIVATION))\n",
        "            if DROPOUT > 0: layers.append(tf.keras.layers.Dropout(DROPOUT))\n",
        "            return tf.keras.Sequential(layers)\n",
        "\n",
        "        self.e1   = dense_block(N_L1)\n",
        "        self.e2   = dense_block(N_L2)\n",
        "        self.ez   = tf.keras.layers.Dense(LATENT_DIM)\n",
        "        self.ey   = tf.keras.layers.Dense(N_LABELS)\n",
        "\n",
        "        self.d1   = dense_block(N_L2)\n",
        "        self.d2   = dense_block(N_L1)\n",
        "        self.dout = tf.keras.layers.Dense(FEATURE_DIM, activation='sigmoid')\n",
        "\n",
        "        self.dz1  = dense_block(N_L1)\n",
        "        self.dz2  = dense_block(N_L2)\n",
        "        self.dzout= tf.keras.layers.Dense(1)\n",
        "\n",
        "        self.dy1  = dense_block(N_L1)\n",
        "        self.dy2  = dense_block(N_L2)\n",
        "        self.dyout= tf.keras.layers.Dense(1)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h      = self.e2(self.e1(x))\n",
        "        z      = self.ez(h)\n",
        "        logits = self.ey(h)\n",
        "        return z, tf.nn.softmax(logits), logits\n",
        "\n",
        "    def decode(self, z, y):\n",
        "        h = tf.concat([z, y], axis=1)\n",
        "        h = self.d1(h)\n",
        "        h = self.d2(h)\n",
        "        return self.dout(h)\n",
        "\n",
        "    def discriminate_z(self, z):\n",
        "        h = self.dz1(z)\n",
        "        h = self.dz2(h)\n",
        "        return self.dzout(h)\n",
        "\n",
        "    def discriminate_y(self, y):\n",
        "        h = self.dy1(y)\n",
        "        h = self.dy2(h)\n",
        "        return self.dyout(h)\n",
        "\n",
        "    def gradient_penalty(self, f, real, fake):\n",
        "        alpha = tf.random.uniform([real.shape[0], 1], 0, 1)\n",
        "        interm = real + alpha * (fake - real)\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(interm)\n",
        "            pred = f(interm)\n",
        "        grads = tape.gradient(pred, interm)\n",
        "        slopes= tf.sqrt(tf.reduce_sum(tf.square(grads), axis=1) + 1e-8)\n",
        "        return tf.reduce_mean((slopes - 1)**2)\n",
        "\n",
        "aae = AAE()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4) Losses & Optimizers\n",
        "# ------------------------------------------------------------\n",
        "mse    = tf.keras.losses.MeanSquaredError()\n",
        "ce     = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "opt_ae = tf.keras.optimizers.Adam(LR_AE)\n",
        "opt_dz = tf.keras.optimizers.Adam(LR_DZ)\n",
        "opt_dy = tf.keras.optimizers.Adam(LR_DY)\n",
        "opt_g  = tf.keras.optimizers.Adam(LR_G)\n",
        "\n",
        "@tf.function\n",
        "def train_step(xn, xc, y):\n",
        "    with tf.GradientTape() as t_ae:\n",
        "        z, yp, logits = aae.encode(xn)\n",
        "        xr = aae.decode(z, yp)\n",
        "        loss_re = mse(xc, xr)\n",
        "    vars_ae = aae.e1.trainable_variables + aae.e2.trainable_variables + aae.ez.trainable_variables + aae.ey.trainable_variables + aae.d1.trainable_variables + aae.d2.trainable_variables + aae.dout.trainable_variables\n",
        "    grads_ae = t_ae.gradient(loss_re, vars_ae)\n",
        "    opt_ae.apply_gradients(zip(grads_ae, vars_ae))\n",
        "\n",
        "    with tf.GradientTape() as t_dz:\n",
        "        z_real = tf.random.normal([xn.shape[0], LATENT_DIM])\n",
        "        dz_r = aae.discriminate_z(z_real)\n",
        "        dz_f = aae.discriminate_z(z)\n",
        "        gp   = aae.gradient_penalty(aae.discriminate_z, z_real, z)\n",
        "        loss_dz = tf.reduce_mean(dz_f) - tf.reduce_mean(dz_r) + λ_gp * gp\n",
        "    vars_dz = aae.dz1.trainable_variables + aae.dz2.trainable_variables + aae.dzout.trainable_variables\n",
        "    grads_dz = t_dz.gradient(loss_dz, vars_dz)\n",
        "    opt_dz.apply_gradients(zip(grads_dz, vars_dz))\n",
        "\n",
        "    with tf.GradientTape() as t_dy:\n",
        "        dy_r = aae.discriminate_y(y)\n",
        "        _, yp_enc, _ = aae.encode(xc)\n",
        "        dy_f = aae.discriminate_y(yp_enc)\n",
        "        gp_y = aae.gradient_penalty(aae.discriminate_y, y, yp_enc)\n",
        "        loss_dy = tf.reduce_mean(dy_f) - tf.reduce_mean(dy_r) + λ_gp * gp_y\n",
        "    vars_dy = aae.dy1.trainable_variables + aae.dy2.trainable_variables + aae.dyout.trainable_variables\n",
        "    grads_dy = t_dy.gradient(loss_dy, vars_dy)\n",
        "    opt_dy.apply_gradients(zip(grads_dy, vars_dy))\n",
        "\n",
        "    with tf.GradientTape() as t_g:\n",
        "        z_enc, y_enc, logits_enc = aae.encode(xc)\n",
        "        loss_g = -tf.reduce_mean(aae.discriminate_z(z_enc))\n",
        "        loss_g += -tf.reduce_mean(aae.discriminate_y(y_enc))\n",
        "        loss_g += ce(y, logits_enc)\n",
        "    vars_g = aae.e1.trainable_variables + aae.e2.trainable_variables + aae.ez.trainable_variables + aae.ey.trainable_variables\n",
        "    grads_g = t_g.gradient(loss_g, vars_g)\n",
        "    opt_g.apply_gradients(zip(grads_g, vars_g))\n",
        "\n",
        "    return loss_re, loss_dz, loss_dy, loss_g\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5) Training loop\n",
        "# ------------------------------------------------------------\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    print(f\"[TRAIN] Epoch {epoch}/{EPOCHS}\")\n",
        "    it = iter(train_ds)\n",
        "    for step in range(steps_per_epoch):\n",
        "        xn, xc, y = next(it)\n",
        "        lr, ldz, ldy, lg = train_step(xn, xc, y)\n",
        "        if step % 100 == 0:\n",
        "            print(f\" step {step}/{steps_per_epoch} | recon={lr:.4f} dz={ldz:.4f} dy={ldy:.4f} gen={lg:.4f}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6) Save encoder & decoder\n",
        "# ------------------------------------------------------------\n",
        "from tensorflow.keras.layers import Input, Activation, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "enc_in = Input(shape=(FEATURE_DIM,))\n",
        "h = aae.e2(aae.e1(enc_in))\n",
        "z_enc = aae.ez(h)\n",
        "y_logits = aae.ey(h)\n",
        "y_enc = Activation('softmax')(y_logits)\n",
        "encoder = Model(enc_in, [z_enc, y_enc], name='aae_encoder')\n",
        "\n",
        "z_in = Input(shape=(LATENT_DIM,))\n",
        "y_in = Input(shape=(N_LABELS,))\n",
        "h2 = aae.d2(aae.d1(Concatenate()([z_in, y_in])))\n",
        "dec_out = aae.dout(h2)\n",
        "decoder = Model([z_in, y_in], dec_out, name='aae_decoder')\n",
        "\n",
        "encoder.save('aae_encoder.keras')\n",
        "decoder.save('aae_decoder.keras')\n",
        "print(\"[SAVE] Encoder & decoder saved\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7) Evaluation\n",
        "# ------------------------------------------------------------\n",
        "errs, ys = [], []\n",
        "for fn in glob.glob('*_test.tfrecord'):\n",
        "    label = 0 if fn.startswith('Normal_') else 1\n",
        "    ds_eval = tf.data.TFRecordDataset(fn).map(parse_feat).batch(256)\n",
        "    for x_batch, _ in ds_eval:\n",
        "        z_p, y_p = encoder(x_batch)\n",
        "        x_r = decoder([z_p, y_p])\n",
        "        e = tf.reduce_mean((x_batch - x_r)**2, axis=1).numpy()\n",
        "        errs.append(e)\n",
        "        ys.append(np.full(e.shape, label))\n",
        "errs = np.concatenate(errs)\n",
        "ys   = np.concatenate(ys)\n",
        "\n",
        "fpr, tpr, ths = roc_curve(ys, errs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "opt_idx = np.argmax(tpr - fpr)\n",
        "opt_thr = ths[opt_idx]\n",
        "\n",
        "print(f\"[RESULT] ROC AUC: {roc_auc:.4f}, Thr: {opt_thr:.6f}, TPR: {tpr[opt_idx]:.3f}, FPR: {fpr[opt_idx]:.3f}\")\n",
        "print(\"[RESULT] Confusion Matrix:\")\n",
        "print(confusion_matrix(ys, (errs > opt_thr).astype(int)))\n",
        "print(\"[RESULT] Classification Report:\")\n",
        "print(classification_report(ys, (errs > opt_thr).astype(int), target_names=['Normal','Attack']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "1kxqHHVugLS7",
        "outputId": "d2cb0d33-6052-46da-d4d8-67313cb828c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DATA] TFRecords missing, preprocessing...\n",
            "[WARN] DoS_dataset.csv not found\n",
            "[WARN] Fuzzy_dataset.csv not found\n",
            "[WARN] RPM_dataset.csv not found\n",
            "[WARN] gear_dataset.csv not found\n",
            "[WARN] parsed_dataset.csv not found\n",
            "[PIPE] Total records: 0, steps/epoch: 0\n",
            "[TRAIN] Epoch 1/30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "division by zero",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-3367899622.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;31m# average losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mtrain_re_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_re\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0mtrain_dz_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_dz\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0mtrain_dy_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_dy\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0) GPU setup (optional)\n",
        "# ------------------------------------------------------------\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Hyperparameters\n",
        "# ------------------------------------------------------------\n",
        "FEATURE_DIM = 29 * 29 * 2\n",
        "N_LABELS   = 2\n",
        "BATCH      = 128\n",
        "EPOCHS     = 30\n",
        "\n",
        "# AAE-specific\n",
        "N_L1       = 1024\n",
        "N_L2       = 768\n",
        "LATENT_DIM = 64\n",
        "λ_gp       = 10.0\n",
        "\n",
        "# Learning rates\n",
        "LR_AE = 0.0005\n",
        "LR_DZ = 0.0001\n",
        "LR_DY = 0.0001\n",
        "LR_G  = 5e-5\n",
        "\n",
        "# Architecture options\n",
        "ACTIVATION = 'elu'\n",
        "DROPOUT    = 0.2\n",
        "NORM_TYPE  = 'layer'  # 'layer' or 'batch'\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Helper functions: preprocessing & TFRecord creation\n",
        "# ------------------------------------------------------------\n",
        "datasets = ['DoS', 'Fuzzy', 'RPM', 'gear', 'parsed_dataset']\n",
        "csv_map = {\n",
        "    'DoS': 'DoS_dataset.csv',\n",
        "    'Fuzzy': 'Fuzzy_dataset.csv',\n",
        "    'RPM': 'RPM_dataset.csv',\n",
        "    'gear': 'gear_dataset.csv',\n",
        "    'parsed_dataset': 'parsed_dataset.csv'\n",
        "}\n",
        "\n",
        "def fill_flag(row):\n",
        "    if not isinstance(row['Flag'], str):\n",
        "        col = 'Data' + str(int(row['DLC']))\n",
        "        row['Flag'] = row.get(col, row['Flag'])\n",
        "    return row\n",
        "\n",
        "def convert_canid_bits(cid):\n",
        "    try:\n",
        "        b = bin(int(str(cid), 16))[2:].zfill(29)\n",
        "        return np.array(list(map(int, b)), dtype=np.uint8)\n",
        "    except:\n",
        "        return np.zeros(29, dtype=np.uint8)\n",
        "\n",
        "def hex_to_int(x):\n",
        "    try:\n",
        "        return int(str(x).strip(), 16)\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def preprocess_windows(csv_file):\n",
        "    print(f\"[DATA] Processing {csv_file}\")\n",
        "    attrs = ['Timestamp', 'canID', 'DLC'] + [f'Data{i}' for i in range(8)] + ['Flag']\n",
        "    df = pd.read_csv(csv_file, header=None, names=attrs, low_memory=False)\n",
        "    df['Timestamp'] = pd.to_numeric(df['Timestamp'], errors='coerce')\n",
        "    df['DLC']       = pd.to_numeric(df['DLC'], errors='coerce').fillna(0).astype(int)\n",
        "    df = df.dropna(subset=['Timestamp', 'canID']).apply(fill_flag, axis=1)\n",
        "    for i in range(8):\n",
        "        df[f'Data{i}'] = df[f'Data{i}'].apply(hex_to_int).astype(np.uint8)\n",
        "    df['Flag']    = df['Flag'].astype(str).str.upper().eq('T').astype(np.uint8)\n",
        "    df['canBits'] = df['canID'].apply(convert_canid_bits)\n",
        "    df = df.sort_values('Timestamp')\n",
        "\n",
        "    bits_all   = np.stack(df['canBits'].values)\n",
        "    data_bytes = df[[f'Data{i}' for i in range(8)]].values\n",
        "    flags_all  = df['Flag'].values\n",
        "\n",
        "    win = 29\n",
        "    N   = len(bits_all) // win\n",
        "    bits   = bits_all[:N * win].reshape(N, win, 29)\n",
        "    data   = data_bytes[:N * win].reshape(N, win, 8)\n",
        "    flags  = flags_all[:N * win].reshape(N, win)\n",
        "\n",
        "    rows = []\n",
        "    for i in range(N):\n",
        "        id_img   = bits[i].astype(np.uint8)\n",
        "        last_b   = data[i, -1, :]\n",
        "        b8       = np.unpackbits(last_b, axis=0).reshape(8,8)\n",
        "        data_img = cv2.resize(b8.astype(np.float32), (29,29), interpolation=cv2.INTER_NEAREST) > 0.5\n",
        "        two_ch   = np.stack([id_img, data_img.astype(np.uint8)], axis=-1)\n",
        "        feat_int = two_ch.flatten().tolist()\n",
        "        lbl      = int(flags[i].any())\n",
        "        rows.append((feat_int, lbl))\n",
        "    return rows\n",
        "\n",
        "def write_tfrecord(rows, base):\n",
        "    np.random.shuffle(rows)\n",
        "    ntr = int(0.7 * len(rows))\n",
        "    nvl = int(0.15 * len(rows))\n",
        "    splits = {'train': rows[:ntr], 'val': rows[ntr:ntr+nvl], 'test': rows[ntr+ntr+nvl:]} if False else {'train': rows[:ntr], 'val': rows[ntr:ntr+nvl], 'test': rows[ntr+nvl:]}\n",
        "    for ph, ch in splits.items():\n",
        "        fn = f\"{base}_{ph}.tfrecord\"\n",
        "        with tf.io.TFRecordWriter(fn) as writer:\n",
        "            for feat, lbl in ch:\n",
        "                ex = tf.train.Example(features=tf.train.Features(feature={\n",
        "                    'features': tf.train.Feature(int64_list=tf.train.Int64List(value=feat)),\n",
        "                    'label':    tf.train.Feature(int64_list=tf.train.Int64List(value=[lbl]))\n",
        "                }))\n",
        "                writer.write(ex.SerializeToString())\n",
        "\n",
        "# Create/check TFRecords\n",
        "expected = []\n",
        "for a in datasets:\n",
        "    for ph in ('train', 'val', 'test'):\n",
        "        expected.append(f\"{a}_{ph}.tfrecord\")\n",
        "        if a != 'parsed_dataset':\n",
        "            expected.append(f\"Normal_{a}_{ph}.tfrecord\")\n",
        "if not all(os.path.exists(f) for f in expected):\n",
        "    print(\"[DATA] TFRecords missing, preprocessing...\")\n",
        "    for a in datasets:\n",
        "        src = csv_map[a]\n",
        "        if not os.path.exists(src):\n",
        "            print(f\"[WARN] {src} not found\")\n",
        "        else:\n",
        "            rows    = preprocess_windows(src)\n",
        "            normals = [r for r in rows if r[1] == 0]\n",
        "            attacks = [r for r in rows if r[1] == 1]\n",
        "            write_tfrecord(normals, f\"Normal_{a}\")\n",
        "            if attacks:\n",
        "                write_tfrecord(attacks, a)\n",
        "else:\n",
        "    print(\"[DATA] All TFRecords found.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) tf.data pipeline\n",
        "# ------------------------------------------------------------\n",
        "def parse_feat(proto):\n",
        "    feat = tf.io.parse_single_example(proto, {\n",
        "        'features': tf.io.FixedLenFeature([FEATURE_DIM], tf.int64),\n",
        "        'label':    tf.io.FixedLenFeature([1], tf.int64)\n",
        "    })\n",
        "    x = tf.cast(feat['features'], tf.float32)\n",
        "    y = tf.one_hot(tf.cast(feat['label'][0], tf.int32), N_LABELS)\n",
        "    return x, y\n",
        "\n",
        "train_files = glob.glob('Normal_*_train.tfrecord')\n",
        "train_ds = (\n",
        "    tf.data.TFRecordDataset(train_files, num_parallel_reads=tf.data.AUTOTUNE)\n",
        "    .map(parse_feat, tf.data.AUTOTUNE)\n",
        "    .map(lambda x, y: (x + tf.random.normal(tf.shape(x), 0, 0.01), x, y), tf.data.AUTOTUNE)\n",
        "    .shuffle(10000).repeat()\n",
        "    .batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "total = sum(1 for _ in tf.data.TFRecordDataset(train_files))\n",
        "steps_per_epoch = total // BATCH\n",
        "print(f\"[PIPE] Total records: {total}, steps/epoch: {steps_per_epoch}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) AAE Model definition\n",
        "# ------------------------------------------------------------\n",
        "class AAE(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def dense_block(units):\n",
        "            layers = [tf.keras.layers.Dense(units)]\n",
        "            if NORM_TYPE == 'layer': layers.append(tf.keras.layers.LayerNormalization())\n",
        "            elif NORM_TYPE == 'batch': layers.append(tf.keras.layers.BatchNormalization())\n",
        "            layers.append(tf.keras.layers.Activation(ACTIVATION))\n",
        "            if DROPOUT > 0: layers.append(tf.keras.layers.Dropout(DROPOUT))\n",
        "            return tf.keras.Sequential(layers)\n",
        "\n",
        "        self.e1   = dense_block(N_L1)\n",
        "        self.e2   = dense_block(N_L2)\n",
        "        self.ez   = tf.keras.layers.Dense(LATENT_DIM)\n",
        "        self.ey   = tf.keras.layers.Dense(N_LABELS)\n",
        "\n",
        "        self.d1   = dense_block(N_L2)\n",
        "        self.d2   = dense_block(N_L1)\n",
        "        self.dout = tf.keras.layers.Dense(FEATURE_DIM, activation='sigmoid')\n",
        "\n",
        "        self.dz1  = dense_block(N_L1)\n",
        "        self.dz2  = dense_block(N_L2)\n",
        "        self.dzout= tf.keras.layers.Dense(1)\n",
        "\n",
        "        self.dy1  = dense_block(N_L1)\n",
        "        self.dy2  = dense_block(N_L2)\n",
        "        self.dyout= tf.keras.layers.Dense(1)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h      = self.e2(self.e1(x))\n",
        "        z      = self.ez(h)\n",
        "        logits = self.ey(h)\n",
        "        return z, tf.nn.softmax(logits), logits\n",
        "\n",
        "    def decode(self, z, y):\n",
        "        h = tf.concat([z, y], axis=1)\n",
        "        h = self.d1(h)\n",
        "        h = self.d2(h)\n",
        "        return self.dout(h)\n",
        "\n",
        "    def discriminate_z(self, z):\n",
        "        h = self.dz1(z)\n",
        "        h = self.dz2(h)\n",
        "        return self.dzout(h)\n",
        "\n",
        "    def discriminate_y(self, y):\n",
        "        h = self.dy1(y)\n",
        "        h = self.dy2(h)\n",
        "        return self.dyout(h)\n",
        "\n",
        "    def gradient_penalty(self, f, real, fake):\n",
        "        alpha = tf.random.uniform([real.shape[0], 1], 0, 1)\n",
        "        interm = real + alpha * (fake - real)\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(interm)\n",
        "            pred = f(interm)\n",
        "        grads = tape.gradient(pred, interm)\n",
        "        slopes= tf.sqrt(tf.reduce_sum(tf.square(grads), axis=1) + 1e-8)\n",
        "        return tf.reduce_mean((slopes - 1)**2)\n",
        "\n",
        "aae = AAE()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4) Losses & Optimizers\n",
        "# ------------------------------------------------------------\n",
        "mse    = tf.keras.losses.MeanSquaredError()\n",
        "ce     = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "opt_ae = tf.keras.optimizers.Adam(LR_AE)\n",
        "opt_dz = tf.keras.optimizers.Adam(LR_DZ)\n",
        "opt_dy = tf.keras.optimizers.Adam(LR_DY)\n",
        "opt_g  = tf.keras.optimizers.Adam(LR_G)\n",
        "\n",
        "# Lists to track losses\n",
        "train_re_losses = []\n",
        "val_re_losses   = []\n",
        "train_dz_losses = []\n",
        "train_dy_losses = []\n",
        "train_g_losses  = []\n",
        "\n",
        "@tf.function\n",
        "def train_step(xn, xc, y):\n",
        "    with tf.GradientTape() as t_ae:\n",
        "        z, yp, logits = aae.encode(xn)\n",
        "        xr = aae.decode(z, yp)\n",
        "        loss_re = mse(xc, xr)\n",
        "    vars_ae = aae.e1.trainable_variables + aae.e2.trainable_variables + aae.ez.trainable_variables + aae.ey.trainable_variables + aae.d1.trainable_variables + aae.d2.trainable_variables + aae.dout.trainable_variables\n",
        "    grads_ae = t_ae.gradient(loss_re, vars_ae)\n",
        "    opt_ae.apply_gradients(zip(grads_ae, vars_ae))\n",
        "\n",
        "    with tf.GradientTape() as t_dz:\n",
        "        z_real = tf.random.normal([xn.shape[0], LATENT_DIM])\n",
        "        dz_r = aae.discriminate_z(z_real)\n",
        "        dz_f = aae.discriminate_z(z)\n",
        "        gp   = aae.gradient_penalty(aae.discriminate_z, z_real, z)\n",
        "        loss_dz = tf.reduce_mean(dz_f) - tf.reduce_mean(dz_r) + λ_gp * gp\n",
        "    vars_dz = aae.dz1.trainable_variables + aae.dz2.trainable_variables + aae.dzout.trainable_variables\n",
        "    grads_dz = t_dz.gradient(loss_dz, vars_dz)\n",
        "    opt_dz.apply_gradients(zip(grads_dz, vars_dz))\n",
        "\n",
        "    with tf.GradientTape() as t_dy:\n",
        "        dy_r = aae.discriminate_y(y)\n",
        "        _, yp_enc, _ = aae.encode(xc)\n",
        "        dy_f = aae.discriminate_y(yp_enc)\n",
        "        gp_y = aae.gradient_penalty(aae.discriminate_y, y, yp_enc)\n",
        "        loss_dy = tf.reduce_mean(dy_f) - tf.reduce_mean(dy_r) + λ_gp * gp_y\n",
        "    vars_dy = aae.dy1.trainable_variables + aae.dy2.trainable_variables + aae.dyout.trainable_variables\n",
        "    grads_dy = t_dy.gradient(loss_dy, vars_dy)\n",
        "    opt_dy.apply_gradients(zip(grads_dy, vars_dy))\n",
        "\n",
        "    with tf.GradientTape() as t_g:\n",
        "        z_enc, y_enc, logits_enc = aae.encode(xc)\n",
        "        loss_g = -tf.reduce_mean(aae.discriminate_z(z_enc))\n",
        "        loss_g += -tf.reduce_mean(aae.discriminate_y(y_enc))\n",
        "        loss_g += ce(y, logits_enc)\n",
        "    vars_g = aae.e1.trainable_variables + aae.e2.trainable_variables + aae.ez.trainable_variables + aae.ey.trainable_variables\n",
        "    grads_g = t_g.gradient(loss_g, vars_g)\n",
        "    opt_g.apply_gradients(zip(grads_g, vars_g))\n",
        "\n",
        "    return loss_re, loss_dz, loss_dy, loss_g\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5) Training loop\n",
        "# ------------------------------------------------------------\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    print(f\"[TRAIN] Epoch {epoch}/{EPOCHS}\")\n",
        "    epoch_re, epoch_dz, epoch_dy, epoch_g = 0, 0, 0, 0\n",
        "    it = iter(train_ds)\n",
        "    for step in range(steps_per_epoch):\n",
        "        xn, xc, y = next(it)\n",
        "        lr, ldz, ldy, lg = train_step(xn, xc, y)\n",
        "        epoch_re  += lr.numpy()\n",
        "        epoch_dz += ldz.numpy()\n",
        "        epoch_dy += ldy.numpy()\n",
        "        epoch_g  += lg.numpy()\n",
        "        if step % 100 == 0:\n",
        "            print(f\" step {step}/{steps_per_epoch} | recon={lr:.4f} dz={ldz:.4f} dy={ldy:.4f} gen={lg:.4f}\")\n",
        "\n",
        "    # average losses\n",
        "    train_re_losses.append(epoch_re/steps_per_epoch)\n",
        "    train_dz_losses.append(epoch_dz/steps_per_epoch)\n",
        "    train_dy_losses.append(epoch_dy/steps_per_epoch)\n",
        "    train_g_losses.append(epoch_g/steps_per_epoch)\n",
        "\n",
        "    # validation recon loss\n",
        "    val_loss, val_steps = 0, 0\n",
        "    val_files = glob.glob('Normal_*_val.tfrecord')\n",
        "    for fn in val_files:\n",
        "        ds_val = tf.data.TFRecordDataset(fn).map(parse_feat).batch(BATCH)\n",
        "        for x_val, _ in ds_val:\n",
        "            _, yp, _ = aae.encode(x_val + tf.random.normal(tf.shape(x_val),0,0.01))\n",
        "            x_rec = aae.decode(*aae.encode(x_val)[0:2])\n",
        "            val_loss += tf.reduce_mean(mse(x_val, x_rec)).numpy()\n",
        "            val_steps += 1\n",
        "    val_re_losses.append(val_loss/val_steps)\n",
        "    print(f\"[VALID] recon={val_re_losses[-1]:.4f}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6) Save encoder & decoder\n",
        "# ------------------------------------------------------------\n",
        "from tensorflow.keras.layers import Input, Activation, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "enc_in = Input(shape=(FEATURE_DIM,))\n",
        "h = aae.e2(aae.e1(enc_in))\n",
        "z_enc = aae.ez(h)\n",
        "y_logits = aae.ey(h)\n",
        "y_enc = Activation('softmax')(y_logits)\n",
        "encoder = Model(enc_in, [z_enc, y_enc], name='aae_encoder')\n",
        "\n",
        "z_in = Input(shape=(LATENT_DIM,))\n",
        "y_in = Input(shape=(N_LABELS,))\n",
        "h2 = aae.d2(aae.d1(Concatenate()([z_in, y_in])))\n",
        "dec_out = aae.dout(h2)\n",
        "decoder = Model([z_in, y_in], dec_out, name='aae_decoder')\n",
        "\n",
        "encoder.save('aae_encoder.keras')\n",
        "decoder.save('aae_decoder.keras')\n",
        "print(\"[SAVE] Encoder & decoder saved\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7) Evaluation\n",
        "# ------------------------------------------------------------\n",
        "errs, ys = [], []\n",
        "for fn in glob.glob('*_test.tfrecord'):\n",
        "    label = 0 if fn.startswith('Normal_') else 1\n",
        "    ds_eval = tf.data.TFRecordDataset(fn).map(parse_feat).batch(256)\n",
        "    for x_batch, _ in ds_eval:\n",
        "        z_p, y_p = encoder(x_batch)\n",
        "        x_r = decoder([z_p, y_p])\n",
        "        e = tf.reduce_mean((x_batch - x_r)**2, axis=1).numpy()\n",
        "        errs.append(e)\n",
        "        ys.append(np.full(e.shape, label))\n",
        "errs = np.concatenate(errs)\n",
        "ys   = np.concatenate(ys)\n",
        "\n",
        "fpr, tpr, ths = roc_curve(ys, errs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "opt_idx = np.argmax(tpr - fpr)\n",
        "opt_thr = ths[opt_idx]\n",
        "\n",
        "print(f\"[RESULT] ROC AUC: {roc_auc:.4f}, Thr: {opt_thr:.6f}, TPR: {tpr[opt_idx]:.3f}, FPR: {fpr[opt_idx]:.3f}\")\n",
        "print(\"[RESULT] Confusion Matrix:\")\n",
        "cm = confusion_matrix(ys, (errs > opt_thr).astype(int))\n",
        "print(cm)\n",
        "print(\"[RESULT] Classification Report:\")\n",
        "print(classification_report(ys, (errs > opt_thr).astype(int), target_names=['Normal','Attack']))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 8) Plotting\n",
        "# ------------------------------------------------------------\n",
        "# Reconstruction loss curves\n",
        "plt.figure()\n",
        "plt.plot(range(1, EPOCHS+1), train_re_losses, label='Train recon')\n",
        "plt.plot(range(1, EPOCHS+1), val_re_losses,   label='Val recon')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.title('Reconstruction Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Adversarial losses\n",
        "plt.figure()\n",
        "plt.plot(range(1, EPOCHS+1), train_dz_losses, label='Disc_z')\n",
        "plt.plot(range(1, EPOCHS+1), train_dy_losses, label='Disc_y')\n",
        "plt.plot(range(1, EPOCHS+1), train_g_losses,  label='Generator')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Wasserstein Loss')\n",
        "plt.title('Adversarial Losses')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.3f}')\n",
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Test Set)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Confusion matrix heatmap\n",
        "plt.figure()\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "classes = ['Normal','Attack']\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation=45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "thresh = cm.max() / 2\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, cm[i, j], horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Error distribution histogram\n",
        "plt.figure()\n",
        "plt.hist(errs[ys==0], bins=50, alpha=0.5, label='Normal')\n",
        "plt.hist(errs[ys==1], bins=50, alpha=0.5, label='Attack')\n",
        "plt.xlabel('Reconstruction error')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Error Distribution')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fmUVaAef98Kt",
        "outputId": "308df02e-7bdd-4723-bcac-f2114a0a62f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DATA] TFRecords missing, preprocessing...\n",
            "[DATA] Processing DoS_dataset.csv\n",
            "[DATA] Processing Fuzzy_dataset.csv\n",
            "[DATA] Processing RPM_dataset.csv\n",
            "[DATA] Processing gear_dataset.csv\n",
            "[DATA] Processing parsed_dataset.csv\n",
            "[PIPE] Total records: 196541, steps/epoch: 1535\n",
            "[TRAIN] Epoch 1/30\n",
            " step 0/1535 | recon=0.2770 dz=3.2457 dy=3.9107 gen=0.5375\n",
            " step 100/1535 | recon=0.0522 dz=-5.5579 dy=-0.0046 gen=6.2004\n",
            " step 200/1535 | recon=0.0360 dz=-3.2766 dy=-0.0045 gen=3.1140\n",
            " step 300/1535 | recon=0.0288 dz=-2.0449 dy=-0.0013 gen=0.5553\n",
            " step 400/1535 | recon=0.0248 dz=-1.3391 dy=-0.0010 gen=-0.6564\n",
            " step 500/1535 | recon=0.0231 dz=-0.7353 dy=-0.0007 gen=-1.0535\n",
            " step 600/1535 | recon=0.0220 dz=-0.7756 dy=-0.0008 gen=-0.8366\n",
            " step 700/1535 | recon=0.0215 dz=-0.7282 dy=-0.0011 gen=-0.7689\n",
            " step 800/1535 | recon=0.0211 dz=-0.8356 dy=-0.0011 gen=-0.7457\n",
            " step 900/1535 | recon=0.0204 dz=-0.6255 dy=-0.0011 gen=-0.8284\n",
            " step 1000/1535 | recon=0.0279 dz=-0.9571 dy=-0.0023 gen=-0.7609\n",
            " step 1100/1535 | recon=0.0265 dz=-1.5228 dy=-0.0018 gen=-1.9347\n",
            " step 1200/1535 | recon=0.0236 dz=-0.7703 dy=-0.0015 gen=-2.8042\n",
            " step 1300/1535 | recon=0.0227 dz=-0.7865 dy=-0.0012 gen=-2.8188\n",
            " step 1400/1535 | recon=0.0219 dz=-0.7229 dy=-0.0013 gen=-3.0854\n",
            " step 1500/1535 | recon=0.0205 dz=-0.8206 dy=-0.0013 gen=-2.6659\n",
            "[VALID] recon=0.0202\n",
            "[TRAIN] Epoch 2/30\n",
            " step 0/1535 | recon=0.0194 dz=-0.6794 dy=-0.0014 gen=-2.7341\n",
            " step 100/1535 | recon=0.0173 dz=-0.5581 dy=-0.0013 gen=-2.7572\n",
            " step 200/1535 | recon=0.0184 dz=-0.5179 dy=-0.0013 gen=-3.1047\n",
            " step 300/1535 | recon=0.0174 dz=-0.4895 dy=-0.0016 gen=-3.1926\n",
            " step 400/1535 | recon=0.0168 dz=-0.6302 dy=-0.0018 gen=-3.3203\n",
            " step 500/1535 | recon=0.0169 dz=-0.4306 dy=-0.0019 gen=-3.6097\n",
            " step 600/1535 | recon=0.0172 dz=-0.8929 dy=-0.0022 gen=-3.6629\n",
            " step 700/1535 | recon=0.0162 dz=-0.7137 dy=-0.0025 gen=-3.4544\n",
            " step 800/1535 | recon=0.0159 dz=-0.7764 dy=-0.0029 gen=-3.7064\n",
            " step 900/1535 | recon=0.0155 dz=-1.1295 dy=-0.0035 gen=-3.5779\n",
            " step 1000/1535 | recon=0.0234 dz=-1.4714 dy=-0.0089 gen=-3.5821\n",
            " step 1100/1535 | recon=0.0194 dz=-1.3182 dy=-0.0156 gen=-4.0138\n",
            " step 1200/1535 | recon=0.0184 dz=-1.3271 dy=-0.0110 gen=-4.1502\n",
            " step 1300/1535 | recon=0.0181 dz=-1.2329 dy=-0.0813 gen=-4.3067\n",
            " step 1400/1535 | recon=0.0175 dz=-1.3624 dy=-0.0184 gen=-4.9930\n",
            " step 1500/1535 | recon=0.0172 dz=-1.4731 dy=-0.0161 gen=-5.1431\n",
            "[VALID] recon=0.0166\n",
            "[TRAIN] Epoch 3/30\n",
            " step 0/1535 | recon=0.0162 dz=-1.4413 dy=-0.0584 gen=-4.8459\n",
            " step 100/1535 | recon=0.0151 dz=-1.7909 dy=-0.0274 gen=-4.0796\n",
            " step 200/1535 | recon=0.0147 dz=-1.5847 dy=-0.0350 gen=-3.5129\n",
            " step 300/1535 | recon=0.0147 dz=-1.6691 dy=-0.0361 gen=-2.8922\n",
            " step 400/1535 | recon=0.0152 dz=-1.6353 dy=-0.0282 gen=-2.4557\n",
            " step 500/1535 | recon=0.0143 dz=-1.6249 dy=-0.0330 gen=-2.1177\n",
            " step 600/1535 | recon=0.0136 dz=-1.7750 dy=-0.0399 gen=-1.4518\n",
            " step 700/1535 | recon=0.0143 dz=-1.7253 dy=-0.0358 gen=-1.5104\n",
            " step 800/1535 | recon=0.0143 dz=-1.8989 dy=-0.0090 gen=-1.1108\n",
            " step 900/1535 | recon=0.0135 dz=-1.7981 dy=-0.0277 gen=-1.3628\n",
            " step 1000/1535 | recon=0.0168 dz=-1.7298 dy=-0.1149 gen=-0.7822\n",
            " step 1100/1535 | recon=0.0167 dz=-1.9213 dy=-0.1370 gen=-2.8764\n",
            " step 1200/1535 | recon=0.0161 dz=-1.9662 dy=-0.1065 gen=-3.6232\n",
            " step 1300/1535 | recon=0.0163 dz=-1.7503 dy=-0.1459 gen=-3.8987\n",
            " step 1400/1535 | recon=0.0146 dz=-2.1605 dy=-0.1215 gen=-3.8025\n",
            " step 1500/1535 | recon=0.0146 dz=-2.0917 dy=-0.1519 gen=-3.3906\n",
            "[VALID] recon=0.0148\n",
            "[TRAIN] Epoch 4/30\n",
            " step 0/1535 | recon=0.0143 dz=-2.3587 dy=-0.1054 gen=-3.0998\n",
            " step 100/1535 | recon=0.0132 dz=-2.2165 dy=-0.0904 gen=-2.4423\n",
            " step 200/1535 | recon=0.0137 dz=-2.0070 dy=-0.0962 gen=-1.8558\n",
            " step 300/1535 | recon=0.0129 dz=-2.1300 dy=-0.1238 gen=-1.5476\n",
            " step 400/1535 | recon=0.0132 dz=-2.1437 dy=-0.1222 gen=-1.3111\n",
            " step 500/1535 | recon=0.0128 dz=-2.2445 dy=-0.1202 gen=-1.1985\n",
            " step 600/1535 | recon=0.0133 dz=-2.1486 dy=-0.2055 gen=-0.9107\n",
            " step 700/1535 | recon=0.0128 dz=-2.0964 dy=-0.1925 gen=-1.1996\n",
            " step 800/1535 | recon=0.0127 dz=-2.1751 dy=-0.1631 gen=-1.6186\n",
            " step 900/1535 | recon=0.0127 dz=-2.3619 dy=-0.1590 gen=-1.3603\n",
            " step 1000/1535 | recon=0.0159 dz=-2.1977 dy=-0.2946 gen=-1.6146\n",
            " step 1100/1535 | recon=0.0161 dz=-2.0369 dy=-0.3069 gen=-2.9411\n",
            " step 1200/1535 | recon=0.0155 dz=-1.9380 dy=-0.2141 gen=-3.4825\n",
            " step 1300/1535 | recon=0.0137 dz=-1.9547 dy=-0.2467 gen=-3.5798\n",
            " step 1400/1535 | recon=0.0147 dz=-2.1988 dy=-0.1952 gen=-3.4624\n",
            " step 1500/1535 | recon=0.0128 dz=-2.4266 dy=-0.1762 gen=-2.8636\n",
            "[VALID] recon=0.0140\n",
            "[TRAIN] Epoch 5/30\n",
            " step 0/1535 | recon=0.0131 dz=-2.3199 dy=-0.1946 gen=-2.5480\n",
            " step 100/1535 | recon=0.0118 dz=-2.4061 dy=-0.1400 gen=-2.1068\n",
            " step 200/1535 | recon=0.0127 dz=-2.3849 dy=-0.1771 gen=-1.4237\n",
            " step 300/1535 | recon=0.0122 dz=-2.4402 dy=-0.1781 gen=-0.9820\n",
            " step 400/1535 | recon=0.0122 dz=-2.0638 dy=-0.1793 gen=-0.9773\n",
            " step 500/1535 | recon=0.0125 dz=-2.3057 dy=-0.2402 gen=-0.4966\n",
            " step 600/1535 | recon=0.0118 dz=-2.1922 dy=-0.2699 gen=-0.0306\n",
            " step 700/1535 | recon=0.0120 dz=-2.4520 dy=-0.2716 gen=0.2243\n",
            " step 800/1535 | recon=0.0114 dz=-2.5385 dy=-0.2201 gen=-0.1146\n",
            " step 900/1535 | recon=0.0114 dz=-2.2596 dy=-0.2873 gen=-0.1946\n",
            " step 1000/1535 | recon=0.0170 dz=-2.2229 dy=-0.3329 gen=-0.1757\n",
            " step 1100/1535 | recon=0.0133 dz=-2.2428 dy=-0.3382 gen=-1.3157\n",
            " step 1200/1535 | recon=0.0145 dz=-2.2639 dy=-0.3204 gen=-1.6764\n",
            " step 1300/1535 | recon=0.0143 dz=-2.3154 dy=-0.3139 gen=-1.8220\n",
            " step 1400/1535 | recon=0.0130 dz=-2.4928 dy=-0.2745 gen=-1.8474\n",
            " step 1500/1535 | recon=0.0141 dz=-2.3145 dy=-0.2740 gen=-1.3646\n",
            "[VALID] recon=0.0128\n",
            "[TRAIN] Epoch 6/30\n",
            " step 0/1535 | recon=0.0123 dz=-2.7103 dy=-0.3138 gen=-1.0259\n",
            " step 100/1535 | recon=0.0116 dz=-2.4937 dy=-0.2638 gen=-0.5577\n",
            " step 200/1535 | recon=0.0115 dz=-2.6122 dy=-0.2981 gen=-0.3369\n",
            " step 300/1535 | recon=0.0106 dz=-2.4942 dy=-0.3300 gen=-0.1167\n",
            " step 400/1535 | recon=0.0108 dz=-2.1956 dy=-0.3077 gen=-0.1482\n",
            " step 500/1535 | recon=0.0113 dz=-2.4800 dy=-0.3056 gen=-0.1196\n",
            " step 600/1535 | recon=0.0109 dz=-2.2302 dy=-0.3168 gen=-0.1944\n",
            " step 700/1535 | recon=0.0111 dz=-2.4347 dy=-0.3390 gen=0.0679\n",
            " step 800/1535 | recon=0.0113 dz=-2.4002 dy=-0.2914 gen=-0.3022\n",
            " step 900/1535 | recon=0.0106 dz=-2.1940 dy=-0.3407 gen=-0.2378\n",
            " step 1000/1535 | recon=0.0145 dz=-2.2889 dy=-0.3528 gen=-0.3613\n",
            " step 1100/1535 | recon=0.0141 dz=-2.3251 dy=-0.3215 gen=-1.5240\n",
            " step 1200/1535 | recon=0.0134 dz=-2.3711 dy=-0.3569 gen=-1.6813\n",
            " step 1300/1535 | recon=0.0128 dz=-2.5718 dy=-0.4266 gen=-1.2385\n",
            " step 1400/1535 | recon=0.0116 dz=-2.5866 dy=-0.3501 gen=-1.4375\n",
            " step 1500/1535 | recon=0.0116 dz=-2.2967 dy=-0.3862 gen=-1.1714\n",
            "[VALID] recon=0.0119\n",
            "[TRAIN] Epoch 7/30\n",
            " step 0/1535 | recon=0.0111 dz=-2.7042 dy=-0.3514 gen=-0.8172\n",
            " step 100/1535 | recon=0.0113 dz=-2.4400 dy=-0.3078 gen=-0.8316\n",
            " step 200/1535 | recon=0.0111 dz=-2.6850 dy=-0.3265 gen=-0.7014\n",
            " step 300/1535 | recon=0.0103 dz=-2.6988 dy=-0.3299 gen=-0.4435\n",
            " step 400/1535 | recon=0.0106 dz=-2.4784 dy=-0.3307 gen=-0.6115\n",
            " step 500/1535 | recon=0.0107 dz=-2.5027 dy=-0.3412 gen=-0.5074\n",
            " step 600/1535 | recon=0.0110 dz=-2.4425 dy=-0.3322 gen=-0.6435\n",
            " step 700/1535 | recon=0.0113 dz=-2.3095 dy=-0.3680 gen=-0.5648\n",
            " step 800/1535 | recon=0.0102 dz=-2.2184 dy=-0.3518 gen=-0.7354\n",
            " step 900/1535 | recon=0.0094 dz=-2.3957 dy=-0.3293 gen=-0.6035\n",
            " step 1000/1535 | recon=0.0125 dz=-2.4406 dy=-0.3928 gen=-0.7538\n",
            " step 1100/1535 | recon=0.0127 dz=-2.3638 dy=-0.3997 gen=-1.2787\n",
            " step 1200/1535 | recon=0.0120 dz=-2.4818 dy=-0.3714 gen=-1.3765\n",
            " step 1300/1535 | recon=0.0135 dz=-2.4463 dy=-0.3756 gen=-1.6965\n",
            " step 1400/1535 | recon=0.0117 dz=-2.4332 dy=-0.3415 gen=-1.8730\n",
            " step 1500/1535 | recon=0.0109 dz=-2.5740 dy=-0.3633 gen=-1.5370\n",
            "[VALID] recon=0.0113\n",
            "[TRAIN] Epoch 8/30\n",
            " step 0/1535 | recon=0.0106 dz=-2.7240 dy=-0.3660 gen=-1.2816\n",
            " step 100/1535 | recon=0.0099 dz=-2.6728 dy=-0.3386 gen=-1.0697\n",
            " step 200/1535 | recon=0.0103 dz=-2.5577 dy=-0.3648 gen=-0.9802\n",
            " step 300/1535 | recon=0.0103 dz=-2.5042 dy=-0.3475 gen=-1.0663\n",
            " step 400/1535 | recon=0.0099 dz=-2.5468 dy=-0.3170 gen=-1.0362\n",
            " step 500/1535 | recon=0.0093 dz=-2.6150 dy=-0.3336 gen=-0.8733\n",
            " step 600/1535 | recon=0.0095 dz=-2.3790 dy=-0.3404 gen=-1.1223\n",
            " step 700/1535 | recon=0.0101 dz=-2.3346 dy=-0.3359 gen=-1.0884\n",
            " step 800/1535 | recon=0.0100 dz=-2.3944 dy=-0.3757 gen=-1.0800\n",
            " step 900/1535 | recon=0.0096 dz=-2.3360 dy=-0.3461 gen=-0.9981\n",
            " step 1000/1535 | recon=0.0124 dz=-2.4356 dy=-0.3532 gen=-1.1962\n",
            " step 1100/1535 | recon=0.0125 dz=-2.3717 dy=-0.3494 gen=-1.9104\n",
            " step 1200/1535 | recon=0.0129 dz=-2.2253 dy=-0.3887 gen=-1.9989\n",
            " step 1300/1535 | recon=0.0119 dz=-2.3351 dy=-0.4075 gen=-1.8983\n",
            " step 1400/1535 | recon=0.0113 dz=-2.6010 dy=-0.3566 gen=-2.1160\n",
            " step 1500/1535 | recon=0.0104 dz=-2.5550 dy=-0.3270 gen=-1.7930\n",
            "[VALID] recon=0.0108\n",
            "[TRAIN] Epoch 9/30\n",
            " step 0/1535 | recon=0.0106 dz=-2.7005 dy=-0.3582 gen=-1.6844\n",
            " step 100/1535 | recon=0.0100 dz=-2.6070 dy=-0.3221 gen=-1.5691\n",
            " step 200/1535 | recon=0.0103 dz=-2.6297 dy=-0.3076 gen=-1.4183\n",
            " step 300/1535 | recon=0.0098 dz=-2.7310 dy=-0.2927 gen=-1.4062\n",
            " step 400/1535 | recon=0.0097 dz=-2.5445 dy=-0.3353 gen=-1.4431\n",
            " step 500/1535 | recon=0.0096 dz=-2.4721 dy=-0.3312 gen=-1.4510\n",
            " step 600/1535 | recon=0.0095 dz=-2.4568 dy=-0.2921 gen=-1.5138\n",
            " step 700/1535 | recon=0.0091 dz=-2.2652 dy=-0.3463 gen=-1.5345\n",
            " step 800/1535 | recon=0.0089 dz=-2.3248 dy=-0.3513 gen=-1.3092\n",
            " step 900/1535 | recon=0.0089 dz=-2.4232 dy=-0.3058 gen=-1.6345\n",
            " step 1000/1535 | recon=0.0121 dz=-2.3409 dy=-0.3325 gen=-1.7107\n",
            " step 1100/1535 | recon=0.0129 dz=-2.2272 dy=-0.3673 gen=-2.2381\n",
            " step 1200/1535 | recon=0.0109 dz=-2.3907 dy=-0.3629 gen=-2.1701\n",
            " step 1300/1535 | recon=0.0105 dz=-2.4618 dy=-0.3217 gen=-2.2349\n",
            " step 1400/1535 | recon=0.0103 dz=-2.4713 dy=-0.3231 gen=-2.2479\n",
            " step 1500/1535 | recon=0.0106 dz=-2.6202 dy=-0.2975 gen=-2.2579\n",
            "[VALID] recon=0.0104\n",
            "[TRAIN] Epoch 10/30\n",
            " step 0/1535 | recon=0.0091 dz=-2.6203 dy=-0.3111 gen=-2.1329\n",
            " step 100/1535 | recon=0.0099 dz=-2.5243 dy=-0.2611 gen=-1.9694\n",
            " step 200/1535 | recon=0.0098 dz=-2.4309 dy=-0.3244 gen=-2.1292\n",
            " step 300/1535 | recon=0.0087 dz=-2.6905 dy=-0.2914 gen=-1.6753\n",
            " step 400/1535 | recon=0.0091 dz=-2.4513 dy=-0.2668 gen=-1.8710\n",
            " step 500/1535 | recon=0.0095 dz=-2.2998 dy=-0.2902 gen=-1.9828\n",
            " step 600/1535 | recon=0.0096 dz=-2.4958 dy=-0.3056 gen=-1.9657\n",
            " step 700/1535 | recon=0.0085 dz=-2.5577 dy=-0.3176 gen=-1.9443\n",
            " step 800/1535 | recon=0.0095 dz=-2.2852 dy=-0.3314 gen=-2.0218\n",
            " step 900/1535 | recon=0.0087 dz=-2.4803 dy=-0.2895 gen=-1.8092\n",
            " step 1000/1535 | recon=0.0116 dz=-2.2919 dy=-0.3623 gen=-1.9034\n",
            " step 1100/1535 | recon=0.0117 dz=-2.5336 dy=-0.3465 gen=-2.3206\n",
            " step 1200/1535 | recon=0.0106 dz=-2.3932 dy=-0.3873 gen=-2.1736\n",
            " step 1300/1535 | recon=0.0099 dz=-2.3978 dy=-0.3279 gen=-2.6402\n",
            " step 1400/1535 | recon=0.0100 dz=-2.5811 dy=-0.3043 gen=-2.6937\n",
            " step 1500/1535 | recon=0.0098 dz=-2.5839 dy=-0.2976 gen=-2.5676\n",
            "[VALID] recon=0.0101\n",
            "[TRAIN] Epoch 11/30\n",
            " step 0/1535 | recon=0.0093 dz=-2.5884 dy=-0.3196 gen=-2.3206\n",
            " step 100/1535 | recon=0.0091 dz=-2.5687 dy=-0.3100 gen=-2.0773\n",
            " step 200/1535 | recon=0.0085 dz=-2.5484 dy=-0.3008 gen=-2.1917\n",
            " step 300/1535 | recon=0.0088 dz=-2.6456 dy=-0.3061 gen=-2.1831\n",
            " step 400/1535 | recon=0.0092 dz=-2.3710 dy=-0.3005 gen=-2.2984\n",
            " step 500/1535 | recon=0.0098 dz=-2.4313 dy=-0.2843 gen=-2.3089\n",
            " step 600/1535 | recon=0.0093 dz=-2.3499 dy=-0.2904 gen=-2.2142\n",
            " step 700/1535 | recon=0.0087 dz=-2.3114 dy=-0.3257 gen=-2.2903\n",
            " step 800/1535 | recon=0.0088 dz=-2.3599 dy=-0.3207 gen=-2.1613\n",
            " step 900/1535 | recon=0.0090 dz=-2.4209 dy=-0.3241 gen=-2.2886\n",
            " step 1000/1535 | recon=0.0094 dz=-2.5232 dy=-0.2937 gen=-2.1931\n",
            " step 1100/1535 | recon=0.0103 dz=-2.3358 dy=-0.3437 gen=-2.6149\n",
            " step 1200/1535 | recon=0.0108 dz=-2.4837 dy=-0.3390 gen=-2.7071\n",
            " step 1300/1535 | recon=0.0108 dz=-2.4304 dy=-0.3515 gen=-2.9089\n",
            " step 1400/1535 | recon=0.0105 dz=-2.6189 dy=-0.3140 gen=-2.8732\n",
            " step 1500/1535 | recon=0.0093 dz=-2.7456 dy=-0.3164 gen=-2.7402\n",
            "[VALID] recon=0.0099\n",
            "[TRAIN] Epoch 12/30\n",
            " step 0/1535 | recon=0.0094 dz=-2.8279 dy=-0.2892 gen=-2.7610\n",
            " step 100/1535 | recon=0.0090 dz=-2.5761 dy=-0.3104 gen=-2.5257\n",
            " step 200/1535 | recon=0.0090 dz=-2.7025 dy=-0.2952 gen=-2.5143\n",
            " step 300/1535 | recon=0.0083 dz=-2.5519 dy=-0.2826 gen=-2.4657\n",
            " step 400/1535 | recon=0.0084 dz=-2.3860 dy=-0.3128 gen=-2.5025\n",
            " step 500/1535 | recon=0.0086 dz=-2.5657 dy=-0.2748 gen=-2.4733\n",
            " step 600/1535 | recon=0.0095 dz=-2.2997 dy=-0.2809 gen=-2.5495\n",
            " step 700/1535 | recon=0.0086 dz=-2.3958 dy=-0.2724 gen=-2.6532\n",
            " step 800/1535 | recon=0.0086 dz=-2.4386 dy=-0.2908 gen=-2.5938\n",
            " step 900/1535 | recon=0.0080 dz=-2.4725 dy=-0.3082 gen=-2.3796\n",
            " step 1000/1535 | recon=0.0123 dz=-2.2881 dy=-0.3153 gen=-2.4496\n",
            " step 1100/1535 | recon=0.0104 dz=-2.4516 dy=-0.3045 gen=-2.8175\n",
            " step 1200/1535 | recon=0.0104 dz=-2.5288 dy=-0.2959 gen=-2.9462\n",
            " step 1300/1535 | recon=0.0103 dz=-2.3751 dy=-0.3179 gen=-3.1253\n",
            " step 1400/1535 | recon=0.0091 dz=-2.7206 dy=-0.2979 gen=-2.9689\n",
            " step 1500/1535 | recon=0.0088 dz=-2.5175 dy=-0.2657 gen=-2.8340\n",
            "[VALID] recon=0.0095\n",
            "[TRAIN] Epoch 13/30\n",
            " step 0/1535 | recon=0.0091 dz=-2.6575 dy=-0.2757 gen=-2.7240\n",
            " step 100/1535 | recon=0.0092 dz=-2.4587 dy=-0.2638 gen=-2.6080\n",
            " step 200/1535 | recon=0.0081 dz=-2.7743 dy=-0.2684 gen=-2.3930\n",
            " step 300/1535 | recon=0.0091 dz=-2.5264 dy=-0.2878 gen=-2.5511\n",
            " step 400/1535 | recon=0.0084 dz=-2.3876 dy=-0.3036 gen=-2.5931\n",
            " step 500/1535 | recon=0.0086 dz=-2.4611 dy=-0.2870 gen=-2.6074\n",
            " step 600/1535 | recon=0.0082 dz=-2.3256 dy=-0.2787 gen=-2.6874\n",
            " step 700/1535 | recon=0.0082 dz=-2.3967 dy=-0.2598 gen=-2.8498\n",
            " step 800/1535 | recon=0.0084 dz=-2.4183 dy=-0.2881 gen=-2.7399\n",
            " step 900/1535 | recon=0.0082 dz=-2.6000 dy=-0.2882 gen=-2.6893\n",
            " step 1000/1535 | recon=0.0102 dz=-2.3056 dy=-0.3296 gen=-2.5976\n",
            " step 1100/1535 | recon=0.0109 dz=-2.3543 dy=-0.2996 gen=-3.1159\n",
            " step 1200/1535 | recon=0.0112 dz=-2.5356 dy=-0.2765 gen=-3.1559\n",
            " step 1300/1535 | recon=0.0091 dz=-2.4955 dy=-0.3033 gen=-3.1459\n",
            " step 1400/1535 | recon=0.0091 dz=-2.5439 dy=-0.2959 gen=-3.2394\n",
            " step 1500/1535 | recon=0.0091 dz=-2.5794 dy=-0.2654 gen=-3.2068\n",
            "[VALID] recon=0.0093\n",
            "[TRAIN] Epoch 14/30\n",
            " step 0/1535 | recon=0.0082 dz=-2.6846 dy=-0.2615 gen=-3.1747\n",
            " step 100/1535 | recon=0.0086 dz=-2.4061 dy=-0.2812 gen=-3.0541\n",
            " step 200/1535 | recon=0.0086 dz=-2.5395 dy=-0.2369 gen=-2.9724\n",
            " step 300/1535 | recon=0.0089 dz=-2.3116 dy=-0.2682 gen=-2.9433\n",
            " step 400/1535 | recon=0.0081 dz=-2.3947 dy=-0.2820 gen=-2.8117\n",
            " step 500/1535 | recon=0.0079 dz=-2.3964 dy=-0.2447 gen=-2.9358\n",
            " step 600/1535 | recon=0.0080 dz=-2.5099 dy=-0.2768 gen=-2.9882\n",
            " step 700/1535 | recon=0.0082 dz=-2.2511 dy=-0.2763 gen=-3.0193\n",
            " step 800/1535 | recon=0.0082 dz=-2.3561 dy=-0.2759 gen=-2.8955\n",
            " step 900/1535 | recon=0.0078 dz=-2.3498 dy=-0.2535 gen=-3.0146\n",
            " step 1000/1535 | recon=0.0102 dz=-2.5261 dy=-0.2928 gen=-2.8620\n",
            " step 1100/1535 | recon=0.0108 dz=-2.5306 dy=-0.3245 gen=-3.0520\n",
            " step 1200/1535 | recon=0.0103 dz=-2.5337 dy=-0.2666 gen=-3.2198\n",
            " step 1300/1535 | recon=0.0111 dz=-2.2794 dy=-0.2884 gen=-3.4149\n",
            " step 1400/1535 | recon=0.0094 dz=-2.5785 dy=-0.2737 gen=-3.5276\n",
            " step 1500/1535 | recon=0.0088 dz=-2.7699 dy=-0.2474 gen=-3.3114\n",
            "[VALID] recon=0.0091\n",
            "[TRAIN] Epoch 15/30\n",
            " step 0/1535 | recon=0.0082 dz=-2.5297 dy=-0.2474 gen=-3.4025\n",
            " step 100/1535 | recon=0.0081 dz=-2.4517 dy=-0.2408 gen=-3.2344\n",
            " step 200/1535 | recon=0.0083 dz=-2.3980 dy=-0.2511 gen=-3.0300\n",
            " step 300/1535 | recon=0.0078 dz=-2.5504 dy=-0.2540 gen=-2.9252\n",
            " step 400/1535 | recon=0.0084 dz=-2.3084 dy=-0.2456 gen=-3.0893\n",
            " step 500/1535 | recon=0.0080 dz=-2.4081 dy=-0.2664 gen=-2.6969\n",
            " step 600/1535 | recon=0.0080 dz=-2.4357 dy=-0.2485 gen=-2.9414\n",
            " step 700/1535 | recon=0.0078 dz=-2.4278 dy=-0.2530 gen=-3.0297\n",
            " step 800/1535 | recon=0.0071 dz=-2.6426 dy=-0.2464 gen=-2.8120\n",
            " step 900/1535 | recon=0.0073 dz=-2.5577 dy=-0.2809 gen=-2.8203\n",
            " step 1000/1535 | recon=0.0091 dz=-2.4875 dy=-0.2859 gen=-2.9513\n",
            " step 1100/1535 | recon=0.0099 dz=-2.6421 dy=-0.2575 gen=-3.1322\n",
            " step 1200/1535 | recon=0.0085 dz=-2.4178 dy=-0.2932 gen=-3.2892\n",
            " step 1300/1535 | recon=0.0089 dz=-2.5222 dy=-0.2847 gen=-3.3041\n",
            " step 1400/1535 | recon=0.0095 dz=-2.4552 dy=-0.2597 gen=-3.3101\n",
            " step 1500/1535 | recon=0.0084 dz=-2.3050 dy=-0.2406 gen=-3.3887\n",
            "[VALID] recon=0.0090\n",
            "[TRAIN] Epoch 16/30\n",
            " step 0/1535 | recon=0.0089 dz=-2.4650 dy=-0.2472 gen=-3.4162\n",
            " step 100/1535 | recon=0.0077 dz=-2.7187 dy=-0.2345 gen=-3.0052\n",
            " step 200/1535 | recon=0.0076 dz=-2.3967 dy=-0.2344 gen=-3.2049\n",
            " step 300/1535 | recon=0.0083 dz=-2.5237 dy=-0.1996 gen=-3.1223\n",
            " step 400/1535 | recon=0.0077 dz=-2.3943 dy=-0.2185 gen=-3.0114\n",
            " step 500/1535 | recon=0.0085 dz=-2.5539 dy=-0.2252 gen=-3.0227\n",
            " step 600/1535 | recon=0.0071 dz=-2.3529 dy=-0.2615 gen=-2.7571\n",
            " step 700/1535 | recon=0.0076 dz=-2.6142 dy=-0.2208 gen=-2.8381\n",
            " step 800/1535 | recon=0.0076 dz=-2.5742 dy=-0.2296 gen=-2.8835\n",
            " step 900/1535 | recon=0.0079 dz=-2.5797 dy=-0.2630 gen=-2.7561\n",
            " step 1000/1535 | recon=0.0096 dz=-2.4775 dy=-0.2476 gen=-2.8163\n",
            " step 1100/1535 | recon=0.0094 dz=-2.4713 dy=-0.2942 gen=-3.1767\n",
            " step 1200/1535 | recon=0.0092 dz=-2.6179 dy=-0.2459 gen=-3.1212\n",
            " step 1300/1535 | recon=0.0086 dz=-2.4766 dy=-0.2583 gen=-3.1345\n",
            " step 1400/1535 | recon=0.0081 dz=-2.3829 dy=-0.2535 gen=-3.4239\n",
            " step 1500/1535 | recon=0.0085 dz=-2.4522 dy=-0.2213 gen=-3.4127\n",
            "[VALID] recon=0.0087\n",
            "[TRAIN] Epoch 17/30\n",
            " step 0/1535 | recon=0.0073 dz=-2.7106 dy=-0.2281 gen=-3.0422\n",
            " step 100/1535 | recon=0.0076 dz=-2.5639 dy=-0.2422 gen=-2.9268\n",
            " step 200/1535 | recon=0.0075 dz=-2.7927 dy=-0.2324 gen=-2.8546\n",
            " step 300/1535 | recon=0.0077 dz=-2.3945 dy=-0.1992 gen=-3.0697\n",
            " step 400/1535 | recon=0.0076 dz=-2.3208 dy=-0.2394 gen=-2.9530\n",
            " step 500/1535 | recon=0.0073 dz=-2.3382 dy=-0.2180 gen=-2.9747\n",
            " step 600/1535 | recon=0.0074 dz=-2.4461 dy=-0.2335 gen=-2.9726\n",
            " step 700/1535 | recon=0.0080 dz=-2.3386 dy=-0.2137 gen=-3.0189\n",
            " step 800/1535 | recon=0.0072 dz=-2.4590 dy=-0.2276 gen=-2.9110\n",
            " step 900/1535 | recon=0.0076 dz=-2.4061 dy=-0.2169 gen=-2.9926\n",
            " step 1000/1535 | recon=0.0094 dz=-2.5470 dy=-0.2200 gen=-2.9441\n",
            " step 1100/1535 | recon=0.0090 dz=-2.4815 dy=-0.2610 gen=-3.0332\n",
            " step 1200/1535 | recon=0.0089 dz=-2.8420 dy=-0.2616 gen=-2.9165\n",
            " step 1300/1535 | recon=0.0094 dz=-2.5434 dy=-0.2430 gen=-3.2061\n",
            " step 1400/1535 | recon=0.0079 dz=-2.5686 dy=-0.2422 gen=-3.3082\n",
            " step 1500/1535 | recon=0.0075 dz=-2.4091 dy=-0.2485 gen=-3.0273\n",
            "[VALID] recon=0.0086\n",
            "[TRAIN] Epoch 18/30\n",
            " step 0/1535 | recon=0.0079 dz=-2.7687 dy=-0.2536 gen=-3.0703\n",
            " step 100/1535 | recon=0.0069 dz=-2.8547 dy=-0.2126 gen=-2.8701\n",
            " step 200/1535 | recon=0.0075 dz=-2.5583 dy=-0.2498 gen=-2.6313\n",
            " step 300/1535 | recon=0.0073 dz=-2.5650 dy=-0.2153 gen=-2.7031\n",
            " step 400/1535 | recon=0.0079 dz=-2.4144 dy=-0.2418 gen=-2.9665\n",
            " step 500/1535 | recon=0.0075 dz=-2.6937 dy=-0.2385 gen=-2.7630\n",
            " step 600/1535 | recon=0.0074 dz=-2.6185 dy=-0.2193 gen=-2.6147\n",
            " step 700/1535 | recon=0.0075 dz=-2.4643 dy=-0.2532 gen=-2.7245\n",
            " step 800/1535 | recon=0.0073 dz=-2.5969 dy=-0.2349 gen=-2.6521\n",
            " step 900/1535 | recon=0.0076 dz=-2.4308 dy=-0.2165 gen=-2.5664\n",
            " step 1000/1535 | recon=0.0094 dz=-2.5646 dy=-0.2532 gen=-2.5943\n",
            " step 1100/1535 | recon=0.0082 dz=-2.8269 dy=-0.2518 gen=-2.3724\n",
            " step 1200/1535 | recon=0.0092 dz=-2.6374 dy=-0.2325 gen=-2.8077\n",
            " step 1300/1535 | recon=0.0093 dz=-2.6388 dy=-0.2581 gen=-2.9475\n",
            " step 1400/1535 | recon=0.0081 dz=-2.5510 dy=-0.2498 gen=-3.1245\n",
            " step 1500/1535 | recon=0.0081 dz=-2.5305 dy=-0.2319 gen=-2.9086\n",
            "[VALID] recon=0.0083\n",
            "[TRAIN] Epoch 19/30\n",
            " step 0/1535 | recon=0.0076 dz=-2.7528 dy=-0.2008 gen=-2.9462\n",
            " step 100/1535 | recon=0.0071 dz=-2.4828 dy=-0.2282 gen=-2.8621\n",
            " step 200/1535 | recon=0.0066 dz=-2.5547 dy=-0.2171 gen=-2.6275\n",
            " step 300/1535 | recon=0.0075 dz=-2.3136 dy=-0.2017 gen=-2.7446\n",
            " step 400/1535 | recon=0.0075 dz=-2.5391 dy=-0.1981 gen=-2.4819\n",
            " step 500/1535 | recon=0.0071 dz=-2.6156 dy=-0.2306 gen=-2.5972\n",
            " step 600/1535 | recon=0.0076 dz=-2.2198 dy=-0.2025 gen=-2.6606\n",
            " step 700/1535 | recon=0.0068 dz=-2.4543 dy=-0.2006 gen=-2.5829\n",
            " step 800/1535 | recon=0.0073 dz=-2.4537 dy=-0.2096 gen=-2.5414\n",
            " step 900/1535 | recon=0.0068 dz=-2.7440 dy=-0.1921 gen=-2.3969\n",
            " step 1000/1535 | recon=0.0089 dz=-2.3944 dy=-0.2407 gen=-2.6132\n",
            " step 1100/1535 | recon=0.0091 dz=-2.6357 dy=-0.2631 gen=-2.6843\n",
            " step 1200/1535 | recon=0.0089 dz=-2.7032 dy=-0.2393 gen=-2.8582\n",
            " step 1300/1535 | recon=0.0082 dz=-2.6476 dy=-0.2265 gen=-2.8511\n",
            " step 1400/1535 | recon=0.0080 dz=-2.4788 dy=-0.2510 gen=-3.3559\n",
            " step 1500/1535 | recon=0.0075 dz=-2.7231 dy=-0.2276 gen=-2.9675\n",
            "[VALID] recon=0.0083\n",
            "[TRAIN] Epoch 20/30\n",
            " step 0/1535 | recon=0.0079 dz=-2.3436 dy=-0.2002 gen=-3.2224\n",
            " step 100/1535 | recon=0.0075 dz=-2.7279 dy=-0.1990 gen=-2.6584\n",
            " step 200/1535 | recon=0.0071 dz=-2.7590 dy=-0.2160 gen=-2.6779\n",
            " step 300/1535 | recon=0.0077 dz=-2.4460 dy=-0.2131 gen=-2.9286\n",
            " step 400/1535 | recon=0.0070 dz=-2.4354 dy=-0.1979 gen=-2.8383\n",
            " step 500/1535 | recon=0.0070 dz=-2.4334 dy=-0.2066 gen=-2.6946\n",
            " step 600/1535 | recon=0.0075 dz=-2.3564 dy=-0.2148 gen=-2.7137\n",
            " step 700/1535 | recon=0.0067 dz=-2.4914 dy=-0.2090 gen=-2.8146\n",
            " step 800/1535 | recon=0.0062 dz=-2.5547 dy=-0.2333 gen=-2.5830\n",
            " step 900/1535 | recon=0.0068 dz=-2.3919 dy=-0.1916 gen=-2.7411\n",
            " step 1000/1535 | recon=0.0087 dz=-2.5306 dy=-0.2233 gen=-2.8500\n",
            " step 1100/1535 | recon=0.0090 dz=-2.6092 dy=-0.2331 gen=-2.9202\n",
            " step 1200/1535 | recon=0.0099 dz=-2.6833 dy=-0.2263 gen=-2.9344\n",
            " step 1300/1535 | recon=0.0095 dz=-2.5356 dy=-0.2427 gen=-3.1256\n",
            " step 1400/1535 | recon=0.0075 dz=-2.4770 dy=-0.2084 gen=-3.1947\n",
            " step 1500/1535 | recon=0.0078 dz=-2.6885 dy=-0.1954 gen=-2.9278\n",
            "[VALID] recon=0.0081\n",
            "[TRAIN] Epoch 21/30\n",
            " step 0/1535 | recon=0.0071 dz=-2.6740 dy=-0.1993 gen=-3.0434\n",
            " step 100/1535 | recon=0.0064 dz=-2.6616 dy=-0.2268 gen=-2.7409\n",
            " step 200/1535 | recon=0.0068 dz=-2.7461 dy=-0.2022 gen=-2.7906\n",
            " step 300/1535 | recon=0.0071 dz=-2.6373 dy=-0.1880 gen=-2.9710\n",
            " step 400/1535 | recon=0.0072 dz=-2.7871 dy=-0.2016 gen=-2.7110\n",
            " step 500/1535 | recon=0.0068 dz=-2.5713 dy=-0.2159 gen=-2.7939\n",
            " step 600/1535 | recon=0.0070 dz=-2.4714 dy=-0.1844 gen=-3.0865\n",
            " step 700/1535 | recon=0.0076 dz=-2.2932 dy=-0.2256 gen=-3.0249\n",
            " step 800/1535 | recon=0.0073 dz=-2.4719 dy=-0.1896 gen=-2.8938\n",
            " step 900/1535 | recon=0.0068 dz=-2.4955 dy=-0.1930 gen=-2.8995\n",
            " step 1000/1535 | recon=0.0080 dz=-2.2475 dy=-0.2043 gen=-3.3158\n",
            " step 1100/1535 | recon=0.0091 dz=-2.4269 dy=-0.2298 gen=-3.2667\n",
            " step 1200/1535 | recon=0.0089 dz=-2.4587 dy=-0.2149 gen=-3.4684\n",
            " step 1300/1535 | recon=0.0078 dz=-2.6545 dy=-0.1919 gen=-3.6336\n",
            " step 1400/1535 | recon=0.0083 dz=-2.4867 dy=-0.1978 gen=-3.9023\n",
            " step 1500/1535 | recon=0.0075 dz=-2.5900 dy=-0.2158 gen=-3.9614\n",
            "[VALID] recon=0.0079\n",
            "[TRAIN] Epoch 22/30\n",
            " step 0/1535 | recon=0.0072 dz=-2.3785 dy=-0.1986 gen=-4.0012\n",
            " step 100/1535 | recon=0.0077 dz=-2.4961 dy=-0.2058 gen=-3.8872\n",
            " step 200/1535 | recon=0.0069 dz=-2.4976 dy=-0.1835 gen=-3.6579\n",
            " step 300/1535 | recon=0.0076 dz=-2.2573 dy=-0.1857 gen=-4.2361\n",
            " step 400/1535 | recon=0.0068 dz=-2.4098 dy=-0.1860 gen=-3.8326\n",
            " step 500/1535 | recon=0.0068 dz=-2.2272 dy=-0.1765 gen=-3.5181\n",
            " step 600/1535 | recon=0.0069 dz=-2.2898 dy=-0.1916 gen=-3.5028\n",
            " step 700/1535 | recon=0.0068 dz=-2.1253 dy=-0.1816 gen=-3.7839\n",
            " step 800/1535 | recon=0.0070 dz=-1.8222 dy=-0.1851 gen=-3.3658\n",
            " step 900/1535 | recon=0.0069 dz=-1.8618 dy=-0.1883 gen=-3.2855\n",
            " step 1000/1535 | recon=0.0084 dz=-1.7407 dy=-0.2176 gen=-3.4353\n",
            " step 1100/1535 | recon=0.0090 dz=-2.0555 dy=-0.2075 gen=-3.2248\n",
            " step 1200/1535 | recon=0.0082 dz=-1.8864 dy=-0.2276 gen=-2.9676\n",
            " step 1300/1535 | recon=0.0086 dz=-1.9749 dy=-0.2196 gen=-2.7968\n",
            " step 1400/1535 | recon=0.0067 dz=-1.8852 dy=-0.1803 gen=-3.1543\n",
            " step 1500/1535 | recon=0.0069 dz=-1.6225 dy=-0.1787 gen=-2.6305\n",
            "[VALID] recon=0.0078\n",
            "[TRAIN] Epoch 23/30\n",
            " step 0/1535 | recon=0.0072 dz=-1.5936 dy=-0.1817 gen=-3.1949\n",
            " step 100/1535 | recon=0.0062 dz=-1.4261 dy=-0.2076 gen=-2.6469\n",
            " step 200/1535 | recon=0.0070 dz=-1.3338 dy=-0.1909 gen=-2.9661\n",
            " step 300/1535 | recon=0.0066 dz=-1.2338 dy=-0.2072 gen=-2.4206\n",
            " step 400/1535 | recon=0.0061 dz=-0.9969 dy=-0.2157 gen=-3.0232\n",
            " step 500/1535 | recon=0.0063 dz=-0.9501 dy=-0.1963 gen=-2.8261\n",
            " step 600/1535 | recon=0.0065 dz=-1.1125 dy=-0.1930 gen=-2.6010\n",
            " step 700/1535 | recon=0.0062 dz=-0.8173 dy=-0.1889 gen=-2.9953\n",
            " step 800/1535 | recon=0.0063 dz=-0.9129 dy=-0.1856 gen=-2.6799\n",
            " step 900/1535 | recon=0.0065 dz=-0.6750 dy=-0.1671 gen=-2.6353\n",
            " step 1000/1535 | recon=0.0078 dz=-0.8242 dy=-0.2267 gen=-2.3732\n",
            " step 1100/1535 | recon=0.0081 dz=-0.8660 dy=-0.1996 gen=-2.0394\n",
            " step 1200/1535 | recon=0.0088 dz=-0.8385 dy=-0.2318 gen=-2.4969\n",
            " step 1300/1535 | recon=0.0087 dz=-0.6560 dy=-0.2134 gen=-2.3487\n",
            " step 1400/1535 | recon=0.0072 dz=-0.7006 dy=-0.2077 gen=-1.9680\n",
            " step 1500/1535 | recon=0.0069 dz=-0.5411 dy=-0.1834 gen=-1.9770\n",
            "[VALID] recon=0.0077\n",
            "[TRAIN] Epoch 24/30\n",
            " step 0/1535 | recon=0.0070 dz=-0.7113 dy=-0.1995 gen=-1.6319\n",
            " step 100/1535 | recon=0.0062 dz=-0.4427 dy=-0.1788 gen=-1.2213\n",
            " step 200/1535 | recon=0.0070 dz=-0.5350 dy=-0.1773 gen=-0.9309\n",
            " step 300/1535 | recon=0.0065 dz=-0.4251 dy=-0.2043 gen=-0.4897\n",
            " step 400/1535 | recon=0.0069 dz=-0.4745 dy=-0.1823 gen=-1.0701\n",
            " step 500/1535 | recon=0.0063 dz=-0.3155 dy=-0.1901 gen=-0.8258\n",
            " step 600/1535 | recon=0.0064 dz=-0.5009 dy=-0.1993 gen=-1.2494\n",
            " step 700/1535 | recon=0.0067 dz=-0.1475 dy=-0.1889 gen=-1.3691\n",
            " step 800/1535 | recon=0.0071 dz=-0.1842 dy=-0.1955 gen=-1.2598\n",
            " step 900/1535 | recon=0.0069 dz=-0.3219 dy=-0.1885 gen=-1.3713\n",
            " step 1000/1535 | recon=0.0086 dz=-0.1756 dy=-0.2241 gen=-1.5093\n",
            " step 1100/1535 | recon=0.0079 dz=-0.3482 dy=-0.2257 gen=-1.3755\n",
            " step 1200/1535 | recon=0.0085 dz=-0.4970 dy=-0.2827 gen=-1.2965\n",
            " step 1300/1535 | recon=0.0084 dz=-0.2339 dy=-0.2297 gen=-1.8400\n",
            " step 1400/1535 | recon=0.0067 dz=-0.3470 dy=-0.2332 gen=-1.7195\n",
            " step 1500/1535 | recon=0.0066 dz=-0.2246 dy=-0.2063 gen=-1.5757\n",
            "[VALID] recon=0.0075\n",
            "[TRAIN] Epoch 25/30\n",
            " step 0/1535 | recon=0.0067 dz=-0.3614 dy=-0.2131 gen=-1.2433\n",
            " step 100/1535 | recon=0.0062 dz=-0.3736 dy=-0.1641 gen=-1.1056\n",
            " step 200/1535 | recon=0.0066 dz=-0.2742 dy=-0.1988 gen=-0.9785\n",
            " step 300/1535 | recon=0.0070 dz=-0.3121 dy=-0.1506 gen=-0.6959\n",
            " step 400/1535 | recon=0.0064 dz=-0.4397 dy=-0.1744 gen=-0.7219\n",
            " step 500/1535 | recon=0.0062 dz=-0.1440 dy=-0.1819 gen=-0.7858\n",
            " step 600/1535 | recon=0.0065 dz=-0.0720 dy=-0.2118 gen=-0.6919\n",
            " step 700/1535 | recon=0.0068 dz=-0.0803 dy=-0.1827 gen=-0.9044\n",
            " step 800/1535 | recon=0.0067 dz=-0.0620 dy=-0.1844 gen=-0.8309\n",
            " step 900/1535 | recon=0.0064 dz=0.0888 dy=-0.1841 gen=-1.0483\n",
            " step 1000/1535 | recon=0.0075 dz=0.0775 dy=-0.2110 gen=-1.1570\n",
            " step 1100/1535 | recon=0.0080 dz=-0.3618 dy=-0.2468 gen=-0.9638\n",
            " step 1200/1535 | recon=0.0088 dz=-0.3258 dy=-0.2170 gen=-1.0266\n",
            " step 1300/1535 | recon=0.0080 dz=-0.1815 dy=-0.2478 gen=-1.1794\n",
            " step 1400/1535 | recon=0.0064 dz=0.0375 dy=-0.1952 gen=-1.4934\n",
            " step 1500/1535 | recon=0.0075 dz=-0.2115 dy=-0.2052 gen=-1.3058\n",
            "[VALID] recon=0.0075\n",
            "[TRAIN] Epoch 26/30\n",
            " step 0/1535 | recon=0.0068 dz=-0.1980 dy=-0.1896 gen=-1.2068\n",
            " step 100/1535 | recon=0.0067 dz=-0.3391 dy=-0.1965 gen=-1.0311\n",
            " step 200/1535 | recon=0.0071 dz=-0.1340 dy=-0.1947 gen=-0.8261\n",
            " step 300/1535 | recon=0.0068 dz=-0.2240 dy=-0.1939 gen=-0.5704\n",
            " step 400/1535 | recon=0.0061 dz=-0.3163 dy=-0.2164 gen=-0.5174\n",
            " step 500/1535 | recon=0.0061 dz=-0.1202 dy=-0.1812 gen=-0.4109\n",
            " step 600/1535 | recon=0.0066 dz=-0.1274 dy=-0.1519 gen=-0.4950\n",
            " step 700/1535 | recon=0.0059 dz=-0.1114 dy=-0.1763 gen=-0.4713\n",
            " step 800/1535 | recon=0.0066 dz=-0.3040 dy=-0.2040 gen=-0.3367\n",
            " step 900/1535 | recon=0.0063 dz=-0.0108 dy=-0.1600 gen=-0.6753\n",
            " step 1000/1535 | recon=0.0074 dz=0.0676 dy=-0.1999 gen=-0.8043\n",
            " step 1100/1535 | recon=0.0088 dz=-0.2993 dy=-0.2207 gen=-0.7750\n",
            " step 1200/1535 | recon=0.0077 dz=-0.2983 dy=-0.2199 gen=-0.6618\n",
            " step 1300/1535 | recon=0.0072 dz=-0.3763 dy=-0.2266 gen=-0.9655\n",
            " step 1400/1535 | recon=0.0072 dz=0.0605 dy=-0.2072 gen=-1.1305\n",
            " step 1500/1535 | recon=0.0064 dz=-0.2352 dy=-0.1974 gen=-1.0470\n",
            "[VALID] recon=0.0075\n",
            "[TRAIN] Epoch 27/30\n",
            " step 0/1535 | recon=0.0065 dz=-0.1676 dy=-0.2072 gen=-1.0293\n",
            " step 100/1535 | recon=0.0063 dz=-0.1180 dy=-0.1653 gen=-0.7245\n",
            " step 200/1535 | recon=0.0064 dz=-0.2173 dy=-0.2066 gen=-0.5123\n",
            " step 300/1535 | recon=0.0069 dz=-0.0764 dy=-0.1890 gen=-0.1828\n",
            " step 400/1535 | recon=0.0061 dz=0.2008 dy=-0.1898 gen=-0.4134\n",
            " step 500/1535 | recon=0.0063 dz=-0.3860 dy=-0.1910 gen=-0.1783\n",
            " step 600/1535 | recon=0.0062 dz=-0.0852 dy=-0.1800 gen=-0.0483\n",
            " step 700/1535 | recon=0.0060 dz=0.0349 dy=-0.1598 gen=-0.0768\n",
            " step 800/1535 | recon=0.0068 dz=-0.2711 dy=-0.1806 gen=-0.1040\n",
            " step 900/1535 | recon=0.0060 dz=-0.1517 dy=-0.1724 gen=-0.2337\n",
            " step 1000/1535 | recon=0.0084 dz=0.1744 dy=-0.1658 gen=-0.6603\n",
            " step 1100/1535 | recon=0.0087 dz=-0.0745 dy=-0.2311 gen=-0.8541\n",
            " step 1200/1535 | recon=0.0078 dz=-0.3775 dy=-0.2040 gen=-0.7925\n",
            " step 1300/1535 | recon=0.0073 dz=-0.4174 dy=-0.2227 gen=-0.5613\n",
            " step 1400/1535 | recon=0.0068 dz=-0.0570 dy=-0.2240 gen=-0.7677\n",
            " step 1500/1535 | recon=0.0068 dz=0.0083 dy=-0.1849 gen=-0.9179\n",
            "[VALID] recon=0.0074\n",
            "[TRAIN] Epoch 28/30\n",
            " step 0/1535 | recon=0.0066 dz=0.2674 dy=-0.1990 gen=-0.5512\n",
            " step 100/1535 | recon=0.0065 dz=-0.1288 dy=-0.2061 gen=-0.3772\n",
            " step 200/1535 | recon=0.0060 dz=0.0615 dy=-0.1961 gen=-0.5607\n",
            " step 300/1535 | recon=0.0056 dz=-0.0946 dy=-0.1950 gen=-0.3510\n",
            " step 400/1535 | recon=0.0068 dz=-0.1016 dy=-0.1726 gen=-0.1054\n",
            " step 500/1535 | recon=0.0061 dz=-0.3662 dy=-0.1903 gen=0.0197\n",
            " step 600/1535 | recon=0.0060 dz=-0.2332 dy=-0.1675 gen=0.0861\n",
            " step 700/1535 | recon=0.0063 dz=-0.0502 dy=-0.1784 gen=0.1845\n",
            " step 800/1535 | recon=0.0061 dz=-0.1316 dy=-0.1660 gen=0.0653\n",
            " step 900/1535 | recon=0.0062 dz=-0.0867 dy=-0.1803 gen=0.2026\n",
            " step 1000/1535 | recon=0.0074 dz=0.0752 dy=-0.1919 gen=-0.3917\n",
            " step 1100/1535 | recon=0.0079 dz=0.0845 dy=-0.2012 gen=-0.5844\n",
            " step 1200/1535 | recon=0.0075 dz=-0.1151 dy=-0.2343 gen=-0.4863\n",
            " step 1300/1535 | recon=0.0081 dz=-0.3595 dy=-0.1979 gen=-0.3253\n",
            " step 1400/1535 | recon=0.0067 dz=0.0982 dy=-0.2126 gen=-0.6816\n",
            " step 1500/1535 | recon=0.0076 dz=-0.1155 dy=-0.2167 gen=-0.2762\n",
            "[VALID] recon=0.0073\n",
            "[TRAIN] Epoch 29/30\n",
            " step 0/1535 | recon=0.0070 dz=0.1413 dy=-0.1776 gen=-0.4433\n",
            " step 100/1535 | recon=0.0060 dz=0.1146 dy=-0.1929 gen=-0.3955\n",
            " step 200/1535 | recon=0.0062 dz=0.0859 dy=-0.1827 gen=-0.0217\n",
            " step 300/1535 | recon=0.0063 dz=-0.1166 dy=-0.1843 gen=-0.0875\n",
            " step 400/1535 | recon=0.0059 dz=-0.0943 dy=-0.1563 gen=0.0657\n",
            " step 500/1535 | recon=0.0064 dz=-0.1778 dy=-0.1857 gen=0.2212\n",
            " step 600/1535 | recon=0.0062 dz=-0.3023 dy=-0.1704 gen=0.2555\n",
            " step 700/1535 | recon=0.0064 dz=-0.0793 dy=-0.1867 gen=0.1668\n",
            " step 800/1535 | recon=0.0068 dz=-0.0133 dy=-0.1774 gen=0.3732\n",
            " step 900/1535 | recon=0.0059 dz=0.0860 dy=-0.1469 gen=0.3089\n",
            " step 1000/1535 | recon=0.0068 dz=0.0941 dy=-0.2017 gen=0.0248\n",
            " step 1100/1535 | recon=0.0085 dz=0.2725 dy=-0.2100 gen=-0.4359\n",
            " step 1200/1535 | recon=0.0070 dz=0.1886 dy=-0.2139 gen=-0.4377\n",
            " step 1300/1535 | recon=0.0073 dz=-0.3741 dy=-0.2221 gen=-0.1643\n",
            " step 1400/1535 | recon=0.0062 dz=-0.1226 dy=-0.2101 gen=-0.3938\n",
            " step 1500/1535 | recon=0.0064 dz=0.0265 dy=-0.1804 gen=-0.3501\n",
            "[VALID] recon=0.0072\n",
            "[TRAIN] Epoch 30/30\n",
            " step 0/1535 | recon=0.0065 dz=0.2979 dy=-0.1670 gen=-0.3294\n",
            " step 100/1535 | recon=0.0061 dz=-0.0147 dy=-0.1721 gen=-0.2211\n",
            " step 200/1535 | recon=0.0065 dz=0.0668 dy=-0.1868 gen=0.2011\n",
            " step 300/1535 | recon=0.0063 dz=-0.0046 dy=-0.2068 gen=0.3891\n",
            " step 400/1535 | recon=0.0068 dz=0.0066 dy=-0.1579 gen=0.4623\n",
            " step 500/1535 | recon=0.0064 dz=-0.0844 dy=-0.1918 gen=0.5734\n",
            " step 600/1535 | recon=0.0066 dz=-0.0319 dy=-0.1720 gen=0.7792\n",
            " step 700/1535 | recon=0.0061 dz=-0.2352 dy=-0.1848 gen=0.7618\n",
            " step 800/1535 | recon=0.0066 dz=0.0290 dy=-0.1692 gen=0.4009\n",
            " step 900/1535 | recon=0.0061 dz=0.0664 dy=-0.1537 gen=0.4188\n",
            " step 1000/1535 | recon=0.0073 dz=0.2219 dy=-0.1801 gen=0.2441\n",
            " step 1100/1535 | recon=0.0082 dz=0.3615 dy=-0.1971 gen=-0.0061\n",
            " step 1200/1535 | recon=0.0077 dz=0.5257 dy=-0.2054 gen=-0.1582\n",
            " step 1300/1535 | recon=0.0078 dz=-0.1468 dy=-0.2102 gen=-0.0647\n",
            " step 1400/1535 | recon=0.0080 dz=0.1349 dy=-0.2067 gen=-0.1733\n",
            " step 1500/1535 | recon=0.0061 dz=0.1865 dy=-0.1612 gen=-0.3709\n",
            "[VALID] recon=0.0072\n",
            "[SAVE] Encoder & decoder saved\n",
            "[RESULT] ROC AUC: 0.9870, Thr: 0.015235, TPR: 0.962, FPR: 0.054\n",
            "[RESULT] Confusion Matrix:\n",
            "[[39842  2280]\n",
            " [  867 22124]]\n",
            "[RESULT] Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.98      0.95      0.96     42122\n",
            "      Attack       0.91      0.96      0.93     22991\n",
            "\n",
            "    accuracy                           0.95     65113\n",
            "   macro avg       0.94      0.95      0.95     65113\n",
            "weighted avg       0.95      0.95      0.95     65113\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0) GPU setup (optional)\n",
        "# ------------------------------------------------------------\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Hyperparameters\n",
        "# ------------------------------------------------------------\n",
        "FEATURE_DIM = 29 * 29 * 2\n",
        "N_LABELS   = 2\n",
        "BATCH      = 128\n",
        "EPOCHS     = 30\n",
        "\n",
        "# AAE-specific\n",
        "N_L1       = 1024\n",
        "N_L2       = 768\n",
        "LATENT_DIM = 64\n",
        "λ_gp       = 10.0\n",
        "\n",
        "# Learning rates\n",
        "LR_AE = 0.0005\n",
        "LR_DZ = 0.0001\n",
        "LR_DY = 0.0001\n",
        "LR_G  = 5e-5\n",
        "\n",
        "# Architecture options\n",
        "ACTIVATION = 'elu'\n",
        "DROPOUT    = 0.2\n",
        "NORM_TYPE  = 'layer'  # 'layer' or 'batch'\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Helper functions: preprocessing & TFRecord creation\n",
        "# ------------------------------------------------------------\n",
        "datasets = ['DoS', 'Fuzzy', 'RPM', 'gear', 'parsed_dataset']\n",
        "csv_map = {\n",
        "    'DoS': 'DoS_dataset.csv',\n",
        "    'Fuzzy': 'Fuzzy_dataset.csv',\n",
        "    'RPM': 'RPM_dataset.csv',\n",
        "    'gear': 'gear_dataset.csv',\n",
        "    'parsed_dataset': 'parsed_dataset.csv'\n",
        "}\n",
        "\n",
        "def fill_flag(row):\n",
        "    if not isinstance(row['Flag'], str):\n",
        "        col = 'Data' + str(int(row['DLC']))\n",
        "        row['Flag'] = row.get(col, row['Flag'])\n",
        "    return row\n",
        "\n",
        "def convert_canid_bits(cid):\n",
        "    try:\n",
        "        b = bin(int(str(cid), 16))[2:].zfill(29)\n",
        "        return np.array(list(map(int, b)), dtype=np.uint8)\n",
        "    except:\n",
        "        return np.zeros(29, dtype=np.uint8)\n",
        "\n",
        "def hex_to_int(x):\n",
        "    try:\n",
        "        return int(str(x).strip(), 16)\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def preprocess_windows(csv_file):\n",
        "    print(f\"[DATA] Processing {csv_file}\")\n",
        "    attrs = ['Timestamp', 'canID', 'DLC'] + [f'Data{i}' for i in range(8)] + ['Flag']\n",
        "    df = pd.read_csv(csv_file, header=None, names=attrs, low_memory=False)\n",
        "    df['Timestamp'] = pd.to_numeric(df['Timestamp'], errors='coerce')\n",
        "    df['DLC']       = pd.to_numeric(df['DLC'], errors='coerce').fillna(0).astype(int)\n",
        "    df = df.dropna(subset=['Timestamp', 'canID']).apply(fill_flag, axis=1)\n",
        "    for i in range(8):\n",
        "        df[f'Data{i}'] = df[f'Data{i}'].apply(hex_to_int).astype(np.uint8)\n",
        "    df['Flag']    = df['Flag'].astype(str).str.upper().eq('T').astype(np.uint8)\n",
        "    df['canBits'] = df['canID'].apply(convert_canid_bits)\n",
        "    df = df.sort_values('Timestamp')\n",
        "\n",
        "    bits_all   = np.stack(df['canBits'].values)\n",
        "    data_bytes = df[[f'Data{i}' for i in range(8)]].values\n",
        "    flags_all  = df['Flag'].values\n",
        "\n",
        "    win = 29\n",
        "    N   = len(bits_all) // win\n",
        "    bits   = bits_all[:N * win].reshape(N, win, 29)\n",
        "    data   = data_bytes[:N * win].reshape(N, win, 8)\n",
        "    flags  = flags_all[:N * win].reshape(N, win)\n",
        "\n",
        "    rows = []\n",
        "    for i in range(N):\n",
        "        id_img   = bits[i].astype(np.uint8)\n",
        "        last_b   = data[i, -1, :]\n",
        "        b8       = np.unpackbits(last_b, axis=0).reshape(8,8)\n",
        "        data_img = cv2.resize(b8.astype(np.float32), (29,29), interpolation=cv2.INTER_NEAREST) > 0.5\n",
        "        two_ch   = np.stack([id_img, data_img.astype(np.uint8)], axis=-1)\n",
        "        feat_int = two_ch.flatten().tolist()\n",
        "        lbl      = int(flags[i].any())\n",
        "        rows.append((feat_int, lbl))\n",
        "    return rows\n",
        "\n",
        "def write_tfrecord(rows, base):\n",
        "    np.random.shuffle(rows)\n",
        "    ntr = int(0.7 * len(rows))\n",
        "    nvl = int(0.15 * len(rows))\n",
        "    splits = {'train': rows[:ntr], 'val': rows[ntr:ntr+nvl], 'test': rows[ntr+ntr+nvl:]} if False else {'train': rows[:ntr], 'val': rows[ntr:ntr+nvl], 'test': rows[ntr+nvl:]}\n",
        "    for ph, ch in splits.items():\n",
        "        fn = f\"{base}_{ph}.tfrecord\"\n",
        "        with tf.io.TFRecordWriter(fn) as writer:\n",
        "            for feat, lbl in ch:\n",
        "                ex = tf.train.Example(features=tf.train.Features(feature={\n",
        "                    'features': tf.train.Feature(int64_list=tf.train.Int64List(value=feat)),\n",
        "                    'label':    tf.train.Feature(int64_list=tf.train.Int64List(value=[lbl]))\n",
        "                }))\n",
        "                writer.write(ex.SerializeToString())\n",
        "\n",
        "# Create/check TFRecords\n",
        "expected = []\n",
        "for a in datasets:\n",
        "    for ph in ('train', 'val', 'test'):\n",
        "        expected.append(f\"{a}_{ph}.tfrecord\")\n",
        "        if a != 'parsed_dataset':\n",
        "            expected.append(f\"Normal_{a}_{ph}.tfrecord\")\n",
        "if not all(os.path.exists(f) for f in expected):\n",
        "    print(\"[DATA] TFRecords missing, preprocessing...\")\n",
        "    for a in datasets:\n",
        "        src = csv_map[a]\n",
        "        if not os.path.exists(src):\n",
        "            print(f\"[WARN] {src} not found\")\n",
        "        else:\n",
        "            rows    = preprocess_windows(src)\n",
        "            normals = [r for r in rows if r[1] == 0]\n",
        "            attacks = [r for r in rows if r[1] == 1]\n",
        "            write_tfrecord(normals, f\"Normal_{a}\")\n",
        "            if attacks:\n",
        "                write_tfrecord(attacks, a)\n",
        "else:\n",
        "    print(\"[DATA] All TFRecords found.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) tf.data pipeline\n",
        "# ------------------------------------------------------------\n",
        "def parse_feat(proto):\n",
        "    feat = tf.io.parse_single_example(proto, {\n",
        "        'features': tf.io.FixedLenFeature([FEATURE_DIM], tf.int64),\n",
        "        'label':    tf.io.FixedLenFeature([1], tf.int64)\n",
        "    })\n",
        "    x = tf.cast(feat['features'], tf.float32)\n",
        "    y = tf.one_hot(tf.cast(feat['label'][0], tf.int32), N_LABELS)\n",
        "    return x, y\n",
        "\n",
        "train_files = glob.glob('Normal_*_train.tfrecord')\n",
        "train_ds = (\n",
        "    tf.data.TFRecordDataset(train_files, num_parallel_reads=tf.data.AUTOTUNE)\n",
        "    .map(parse_feat, tf.data.AUTOTUNE)\n",
        "    .map(lambda x, y: (x + tf.random.normal(tf.shape(x), 0, 0.01), x, y), tf.data.AUTOTUNE)\n",
        "    .shuffle(10000).repeat()\n",
        "    .batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "total = sum(1 for _ in tf.data.TFRecordDataset(train_files))\n",
        "steps_per_epoch = total // BATCH\n",
        "print(f\"[PIPE] Total records: {total}, steps/epoch: {steps_per_epoch}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) AAE Model definition\n",
        "# ------------------------------------------------------------\n",
        "class AAE(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def dense_block(units):\n",
        "            layers = [tf.keras.layers.Dense(units)]\n",
        "            if NORM_TYPE == 'layer': layers.append(tf.keras.layers.LayerNormalization())\n",
        "            elif NORM_TYPE == 'batch': layers.append(tf.keras.layers.BatchNormalization())\n",
        "            layers.append(tf.keras.layers.Activation(ACTIVATION))\n",
        "            if DROPOUT > 0: layers.append(tf.keras.layers.Dropout(DROPOUT))\n",
        "            return tf.keras.Sequential(layers)\n",
        "\n",
        "        self.e1   = dense_block(N_L1)\n",
        "        self.e2   = dense_block(N_L2)\n",
        "        self.ez   = tf.keras.layers.Dense(LATENT_DIM)\n",
        "        self.ey   = tf.keras.layers.Dense(N_LABELS)\n",
        "\n",
        "        self.d1   = dense_block(N_L2)\n",
        "        self.d2   = dense_block(N_L1)\n",
        "        self.dout = tf.keras.layers.Dense(FEATURE_DIM, activation='sigmoid')\n",
        "\n",
        "        self.dz1  = dense_block(N_L1)\n",
        "        self.dz2  = dense_block(N_L2)\n",
        "        self.dzout= tf.keras.layers.Dense(1)\n",
        "\n",
        "        self.dy1  = dense_block(N_L1)\n",
        "        self.dy2  = dense_block(N_L2)\n",
        "        self.dyout= tf.keras.layers.Dense(1)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h      = self.e2(self.e1(x))\n",
        "        z      = self.ez(h)\n",
        "        logits = self.ey(h)\n",
        "        return z, tf.nn.softmax(logits), logits\n",
        "\n",
        "    def decode(self, z, y):\n",
        "        h = tf.concat([z, y], axis=1)\n",
        "        h = self.d1(h)\n",
        "        h = self.d2(h)\n",
        "        return self.dout(h)\n",
        "\n",
        "    def discriminate_z(self, z):\n",
        "        h = self.dz1(z)\n",
        "        h = self.dz2(h)\n",
        "        return self.dzout(h)\n",
        "\n",
        "    def discriminate_y(self, y):\n",
        "        h = self.dy1(y)\n",
        "        h = self.dy2(h)\n",
        "        return self.dyout(h)\n",
        "\n",
        "    def gradient_penalty(self, f, real, fake):\n",
        "        alpha = tf.random.uniform([real.shape[0], 1], 0, 1)\n",
        "        interm = real + alpha * (fake - real)\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(interm)\n",
        "            pred = f(interm)\n",
        "        grads = tape.gradient(pred, interm)\n",
        "        slopes= tf.sqrt(tf.reduce_sum(tf.square(grads), axis=1) + 1e-8)\n",
        "        return tf.reduce_mean((slopes - 1)**2)\n",
        "\n",
        "aae = AAE()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4) Losses & Optimizers\n",
        "# ------------------------------------------------------------\n",
        "mse    = tf.keras.losses.MeanSquaredError()\n",
        "ce     = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "opt_ae = tf.keras.optimizers.Adam(LR_AE)\n",
        "opt_dz = tf.keras.optimizers.Adam(LR_DZ)\n",
        "opt_dy = tf.keras.optimizers.Adam(LR_DY)\n",
        "opt_g  = tf.keras.optimizers.Adam(LR_G)\n",
        "\n",
        "# Lists to track losses\n",
        "train_re_losses = []\n",
        "val_re_losses   = []\n",
        "train_dz_losses = []\n",
        "train_dy_losses = []\n",
        "train_g_losses  = []\n",
        "\n",
        "@tf.function\n",
        "def train_step(xn, xc, y):\n",
        "    with tf.GradientTape() as t_ae:\n",
        "        z, yp, logits = aae.encode(xn)\n",
        "        xr = aae.decode(z, yp)\n",
        "        loss_re = mse(xc, xr)\n",
        "    vars_ae = aae.e1.trainable_variables + aae.e2.trainable_variables + aae.ez.trainable_variables + aae.ey.trainable_variables + aae.d1.trainable_variables + aae.d2.trainable_variables + aae.dout.trainable_variables\n",
        "    grads_ae = t_ae.gradient(loss_re, vars_ae)\n",
        "    opt_ae.apply_gradients(zip(grads_ae, vars_ae))\n",
        "\n",
        "    with tf.GradientTape() as t_dz:\n",
        "        z_real = tf.random.normal([xn.shape[0], LATENT_DIM])\n",
        "        dz_r = aae.discriminate_z(z_real)\n",
        "        dz_f = aae.discriminate_z(z)\n",
        "        gp   = aae.gradient_penalty(aae.discriminate_z, z_real, z)\n",
        "        loss_dz = tf.reduce_mean(dz_f) - tf.reduce_mean(dz_r) + λ_gp * gp\n",
        "    vars_dz = aae.dz1.trainable_variables + aae.dz2.trainable_variables + aae.dzout.trainable_variables\n",
        "    grads_dz = t_dz.gradient(loss_dz, vars_dz)\n",
        "    opt_dz.apply_gradients(zip(grads_dz, vars_dz))\n",
        "\n",
        "    with tf.GradientTape() as t_dy:\n",
        "        dy_r = aae.discriminate_y(y)\n",
        "        _, yp_enc, _ = aae.encode(xc)\n",
        "        dy_f = aae.discriminate_y(yp_enc)\n",
        "        gp_y = aae.gradient_penalty(aae.discriminate_y, y, yp_enc)\n",
        "        loss_dy = tf.reduce_mean(dy_f) - tf.reduce_mean(dy_r) + λ_gp * gp_y\n",
        "    vars_dy = aae.dy1.trainable_variables + aae.dy2.trainable_variables + aae.dyout.trainable_variables\n",
        "    grads_dy = t_dy.gradient(loss_dy, vars_dy)\n",
        "    opt_dy.apply_gradients(zip(grads_dy, vars_dy))\n",
        "\n",
        "    with tf.GradientTape() as t_g:\n",
        "        z_enc, y_enc, logits_enc = aae.encode(xc)\n",
        "        loss_g = -tf.reduce_mean(aae.discriminate_z(z_enc))\n",
        "        loss_g += -tf.reduce_mean(aae.discriminate_y(y_enc))\n",
        "        loss_g += ce(y, logits_enc)\n",
        "    vars_g = aae.e1.trainable_variables + aae.e2.trainable_variables + aae.ez.trainable_variables + aae.ey.trainable_variables\n",
        "    grads_g = t_g.gradient(loss_g, vars_g)\n",
        "    opt_g.apply_gradients(zip(grads_g, vars_g))\n",
        "\n",
        "    return loss_re, loss_dz, loss_dy, loss_g\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5) Training loop\n",
        "# ------------------------------------------------------------\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    print(f\"[TRAIN] Epoch {epoch}/{EPOCHS}\")\n",
        "    epoch_re, epoch_dz, epoch_dy, epoch_g = 0, 0, 0, 0\n",
        "    it = iter(train_ds)\n",
        "    for step in range(steps_per_epoch):\n",
        "        xn, xc, y = next(it)\n",
        "        lr, ldz, ldy, lg = train_step(xn, xc, y)\n",
        "        epoch_re  += lr.numpy()\n",
        "        epoch_dz += ldz.numpy()\n",
        "        epoch_dy += ldy.numpy()\n",
        "        epoch_g  += lg.numpy()\n",
        "        if step % 100 == 0:\n",
        "            print(f\" step {step}/{steps_per_epoch} | recon={lr:.4f} dz={ldz:.4f} dy={ldy:.4f} gen={lg:.4f}\")\n",
        "\n",
        "    # average losses\n",
        "    train_re_losses.append(epoch_re/steps_per_epoch)\n",
        "    train_dz_losses.append(epoch_dz/steps_per_epoch)\n",
        "    train_dy_losses.append(epoch_dy/steps_per_epoch)\n",
        "    train_g_losses.append(epoch_g/steps_per_epoch)\n",
        "\n",
        "    # validation recon loss\n",
        "    val_loss, val_steps = 0, 0\n",
        "    val_files = glob.glob('Normal_*_val.tfrecord')\n",
        "    for fn in val_files:\n",
        "        ds_val = tf.data.TFRecordDataset(fn).map(parse_feat).batch(BATCH)\n",
        "        for x_val, _ in ds_val:\n",
        "            _, yp, _ = aae.encode(x_val + tf.random.normal(tf.shape(x_val),0,0.01))\n",
        "            x_rec = aae.decode(*aae.encode(x_val)[0:2])\n",
        "            val_loss += tf.reduce_mean(mse(x_val, x_rec)).numpy()\n",
        "            val_steps += 1\n",
        "    val_re_losses.append(val_loss/val_steps)\n",
        "    print(f\"[VALID] recon={val_re_losses[-1]:.4f}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6) Save encoder & decoder\n",
        "# ------------------------------------------------------------\n",
        "from tensorflow.keras.layers import Input, Activation, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "enc_in = Input(shape=(FEATURE_DIM,))\n",
        "h = aae.e2(aae.e1(enc_in))\n",
        "z_enc = aae.ez(h)\n",
        "y_logits = aae.ey(h)\n",
        "y_enc = Activation('softmax')(y_logits)\n",
        "encoder = Model(enc_in, [z_enc, y_enc], name='aae_encoder')\n",
        "\n",
        "z_in = Input(shape=(LATENT_DIM,))\n",
        "y_in = Input(shape=(N_LABELS,))\n",
        "h2 = aae.d2(aae.d1(Concatenate()([z_in, y_in])))\n",
        "dec_out = aae.dout(h2)\n",
        "decoder = Model([z_in, y_in], dec_out, name='aae_decoder')\n",
        "\n",
        "encoder.save('aae_encoder.keras')\n",
        "decoder.save('aae_decoder.keras')\n",
        "print(\"[SAVE] Encoder & decoder saved\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7) Evaluation\n",
        "# ------------------------------------------------------------\n",
        "errs, ys = [], []\n",
        "for fn in glob.glob('*_test.tfrecord'):\n",
        "    label = 0 if fn.startswith('Normal_') else 1\n",
        "    ds_eval = tf.data.TFRecordDataset(fn).map(parse_feat).batch(256)\n",
        "    for x_batch, _ in ds_eval:\n",
        "        z_p, y_p = encoder(x_batch)\n",
        "        x_r = decoder([z_p, y_p])\n",
        "        e = tf.reduce_mean((x_batch - x_r)**2, axis=1).numpy()\n",
        "        errs.append(e)\n",
        "        ys.append(np.full(e.shape, label))\n",
        "errs = np.concatenate(errs)\n",
        "ys   = np.concatenate(ys)\n",
        "\n",
        "fpr, tpr, ths = roc_curve(ys, errs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "opt_idx = np.argmax(tpr - fpr)\n",
        "opt_thr = ths[opt_idx]\n",
        "\n",
        "print(f\"[RESULT] ROC AUC: {roc_auc:.4f}, Thr: {opt_thr:.6f}, TPR: {tpr[opt_idx]:.3f}, FPR: {fpr[opt_idx]:.3f}\")\n",
        "print(\"[RESULT] Confusion Matrix:\")\n",
        "cm = confusion_matrix(ys, (errs > opt_thr).astype(int))\n",
        "print(cm)\n",
        "print(\"[RESULT] Classification Report:\")\n",
        "print(classification_report(ys, (errs > opt_thr).astype(int), target_names=['Normal','Attack']))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 8) Plotting\n",
        "# ------------------------------------------------------------\n",
        "# Reconstruction loss curves\n",
        "plt.figure()\n",
        "plt.plot(range(1, EPOCHS+1), train_re_losses, label='Train recon')\n",
        "plt.plot(range(1, EPOCHS+1), val_re_losses,   label='Val recon')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.title('Reconstruction Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Adversarial losses\n",
        "plt.figure()\n",
        "plt.plot(range(1, EPOCHS+1), train_dz_losses, label='Disc_z')\n",
        "plt.plot(range(1, EPOCHS+1), train_dy_losses, label='Disc_y')\n",
        "plt.plot(range(1, EPOCHS+1), train_g_losses,  label='Generator')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Wasserstein Loss')\n",
        "plt.title('Adversarial Losses')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.3f}')\n",
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Test Set)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Confusion matrix heatmap\n",
        "plt.figure()\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "classes = ['Normal','Attack']\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation=45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "thresh = cm.max() / 2\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, cm[i, j], horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Error distribution histogram\n",
        "plt.figure()\n",
        "plt.hist(errs[ys==0], bins=50, alpha=0.5, label='Normal')\n",
        "plt.hist(errs[ys==1], bins=50, alpha=0.5, label='Attack')\n",
        "plt.xlabel('Reconstruction error')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Error Distribution')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2BucJtt_Qi3m",
        "outputId": "4637723f-fae0-43b0-9066-db4c03b108ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DATA] Creating TFRecords…\n",
            "[DATA] Processing Attack_free_CHEVROLET_Spark_train.cleaned.csv\n",
            "[DATA] Processing parsed_dataset.csv\n",
            "[DATA] Processing Attack_free_HYUNDAI_Sonata_train.cleaned.csv\n",
            "[DATA] Processing Flooding_CHEVROLET_Spark_train.cleaned.csv\n",
            "[DATA] Processing Flooding_HYUNDAI_Sonata_train.cleaned.csv\n",
            "[DATA] Processing Flooding_KIA_Soul_train.cleaned.csv\n",
            "[DATA] Processing Fuzzy_CHEVROLET_Spark_train.cleaned.csv\n",
            "[DATA] Processing Fuzzy_HYUNDAI_Sonata_train.cleaned.csv\n",
            "[DATA] Processing Fuzzy_KIA_Soul_train.cleaned.csv\n",
            "[DATA] Processing Malfunction_CHEVROLET_Spark_train.cleaned.csv\n",
            "[DATA] Processing Malfunction_HYUNDAI_Sonata_train.cleaned.csv\n",
            "[DATA] Processing Malfunction_KIA_Soul_train.cleaned.csv\n",
            "[DATA] Processing gear_dataset.csv\n",
            "[DATA] Processing DoS_dataset.csv\n",
            "[DATA] Processing RPM_dataset.csv\n",
            "[DATA] Processing Fuzzy_dataset.csv\n",
            "[PIPE] records=215424, steps/epoch=1683\n",
            "[BUILD] all layer variables created: 42\n",
            "\n",
            "[TRAIN] Epoch 1/30\n",
            "  step 0/1683 | re=0.2517 dz=3.9785 dy=4.6106 g=-0.5415\n",
            "  step 100/1683 | re=0.0467 dz=-1.6557 dy=-0.0528 g=1.5390\n",
            "  step 200/1683 | re=0.0374 dz=-1.3676 dy=-0.0093 g=0.9923\n",
            "  step 300/1683 | re=0.0335 dz=-1.1355 dy=-0.0085 g=0.6411\n",
            "  step 400/1683 | re=0.0306 dz=-1.2696 dy=-0.0089 g=0.7377\n",
            "  step 500/1683 | re=0.0273 dz=-1.3246 dy=-0.0064 g=0.6247\n",
            "  step 600/1683 | re=0.0256 dz=-1.4004 dy=-0.0075 g=0.6943\n",
            "  step 700/1683 | re=0.0236 dz=-1.4780 dy=-0.0080 g=0.6582\n",
            "  step 800/1683 | re=0.0217 dz=-1.1219 dy=-0.0133 g=0.5337\n",
            "  step 900/1683 | re=0.0208 dz=-1.3260 dy=-0.0363 g=0.5917\n",
            "  step 1000/1683 | re=0.0258 dz=-1.1013 dy=-0.0833 g=0.9384\n",
            "  step 1100/1683 | re=0.0274 dz=-1.2085 dy=-0.0899 g=1.0199\n",
            "  step 1200/1683 | re=0.0259 dz=-1.1313 dy=-0.3285 g=0.9001\n",
            "  step 1300/1683 | re=0.0221 dz=-1.0927 dy=-0.3179 g=0.7385\n",
            "  step 1400/1683 | re=0.0200 dz=-0.8688 dy=-0.3820 g=0.8994\n",
            "  step 1500/1683 | re=0.0190 dz=-1.1416 dy=-0.4339 g=1.3690\n",
            "  step 1600/1683 | re=0.0184 dz=-1.0982 dy=-0.4264 g=1.5511\n",
            "[VAL] recon=0.0201\n",
            "\n",
            "[TRAIN] Epoch 2/30\n",
            "  step 0/1683 | re=0.0301 dz=-1.0354 dy=-0.3573 g=1.3313\n",
            "  step 100/1683 | re=0.0187 dz=-1.4006 dy=-0.3707 g=1.8699\n",
            "  step 200/1683 | re=0.0168 dz=-1.5662 dy=-0.4047 g=2.3486\n",
            "  step 300/1683 | re=0.0152 dz=-1.6174 dy=-0.4225 g=2.6989\n",
            "  step 400/1683 | re=0.0153 dz=-1.7173 dy=-0.4264 g=3.1096\n",
            "  step 500/1683 | re=0.0140 dz=-1.6461 dy=-0.3815 g=3.4262\n",
            "  step 600/1683 | re=0.0142 dz=-1.6656 dy=-0.4258 g=3.8597\n",
            "  step 700/1683 | re=0.0136 dz=-1.8120 dy=-0.4462 g=4.2232\n",
            "  step 800/1683 | re=0.0140 dz=-1.8250 dy=-0.4531 g=4.4877\n",
            "  step 900/1683 | re=0.0131 dz=-2.0023 dy=-0.4703 g=4.9835\n",
            "  step 1000/1683 | re=0.0175 dz=-1.9501 dy=-0.3883 g=5.0257\n",
            "  step 1100/1683 | re=0.0212 dz=-1.6732 dy=-0.4834 g=5.2490\n",
            "  step 1200/1683 | re=0.0177 dz=-1.6366 dy=-0.4989 g=5.4858\n",
            "  step 1300/1683 | re=0.0160 dz=-1.9102 dy=-0.4504 g=5.6699\n",
            "  step 1400/1683 | re=0.0158 dz=-1.8482 dy=-0.5130 g=5.9321\n",
            "  step 1500/1683 | re=0.0144 dz=-2.3168 dy=-0.5242 g=6.5147\n",
            "  step 1600/1683 | re=0.0128 dz=-2.2881 dy=-0.4919 g=6.3249\n",
            "[VAL] recon=0.0150\n",
            "\n",
            "[TRAIN] Epoch 3/30\n",
            "  step 0/1683 | re=0.0275 dz=-1.6520 dy=-0.4788 g=5.6566\n",
            "  step 100/1683 | re=0.0151 dz=-2.3762 dy=-0.5043 g=6.3303\n",
            "  step 200/1683 | re=0.0135 dz=-2.5266 dy=-0.4890 g=6.4814\n",
            "  step 300/1683 | re=0.0115 dz=-2.3825 dy=-0.5200 g=6.6667\n",
            "  step 400/1683 | re=0.0114 dz=-2.6794 dy=-0.4921 g=6.7885\n",
            "  step 500/1683 | re=0.0113 dz=-2.7534 dy=-0.4516 g=6.9989\n",
            "  step 600/1683 | re=0.0107 dz=-2.4049 dy=-0.4954 g=7.0622\n",
            "  step 700/1683 | re=0.0108 dz=-2.7586 dy=-0.5178 g=7.2933\n",
            "  step 800/1683 | re=0.0099 dz=-2.6886 dy=-0.4824 g=7.2995\n",
            "  step 900/1683 | re=0.0103 dz=-2.6389 dy=-0.4506 g=7.2021\n",
            "  step 1000/1683 | re=0.0135 dz=-2.2123 dy=-0.4879 g=7.0956\n",
            "  step 1100/1683 | re=0.0169 dz=-1.9310 dy=-0.4841 g=6.8953\n",
            "  step 1200/1683 | re=0.0158 dz=-2.0215 dy=-0.4768 g=6.6427\n",
            "  step 1300/1683 | re=0.0137 dz=-1.9137 dy=-0.5004 g=6.5342\n",
            "  step 1400/1683 | re=0.0118 dz=-2.1537 dy=-0.5408 g=7.0159\n",
            "  step 1500/1683 | re=0.0109 dz=-2.2940 dy=-0.4982 g=6.9798\n",
            "  step 1600/1683 | re=0.0112 dz=-2.7686 dy=-0.4625 g=7.2178\n",
            "[VAL] recon=0.0122\n",
            "\n",
            "[TRAIN] Epoch 4/30\n",
            "  step 0/1683 | re=0.0213 dz=-2.0101 dy=-0.5179 g=6.7240\n",
            "  step 100/1683 | re=0.0121 dz=-2.5455 dy=-0.4237 g=7.0661\n",
            "  step 200/1683 | re=0.0101 dz=-2.5042 dy=-0.4614 g=7.3946\n",
            "  step 300/1683 | re=0.0091 dz=-2.8234 dy=-0.4577 g=7.6787\n",
            "  step 400/1683 | re=0.0091 dz=-2.8622 dy=-0.4311 g=7.9998\n",
            "  step 500/1683 | re=0.0087 dz=-2.9308 dy=-0.4874 g=8.1570\n",
            "  step 600/1683 | re=0.0081 dz=-2.9360 dy=-0.4666 g=8.2883\n",
            "  step 700/1683 | re=0.0088 dz=-2.8303 dy=-0.4507 g=8.2966\n",
            "  step 800/1683 | re=0.0078 dz=-2.6517 dy=-0.4606 g=8.4166\n",
            "  step 900/1683 | re=0.0082 dz=-2.7626 dy=-0.4622 g=8.4578\n",
            "  step 1000/1683 | re=0.0129 dz=-2.5253 dy=-0.4469 g=8.1595\n",
            "  step 1100/1683 | re=0.0156 dz=-1.7829 dy=-0.5341 g=7.9252\n",
            "  step 1200/1683 | re=0.0135 dz=-1.9259 dy=-0.5298 g=7.7558\n",
            "  step 1300/1683 | re=0.0105 dz=-2.0071 dy=-0.4898 g=7.5590\n",
            "  step 1400/1683 | re=0.0094 dz=-1.9268 dy=-0.5721 g=7.8663\n",
            "  step 1500/1683 | re=0.0086 dz=-2.1979 dy=-0.4648 g=7.9177\n",
            "  step 1600/1683 | re=0.0079 dz=-2.6344 dy=-0.4696 g=8.4321\n",
            "[VAL] recon=0.0105\n",
            "\n",
            "[TRAIN] Epoch 5/30\n",
            "  step 0/1683 | re=0.0221 dz=-1.7188 dy=-0.4970 g=7.5142\n",
            "  step 100/1683 | re=0.0099 dz=-2.2661 dy=-0.4469 g=8.2323\n",
            "  step 200/1683 | re=0.0091 dz=-2.0301 dy=-0.4715 g=8.4341\n",
            "  step 300/1683 | re=0.0081 dz=-2.2085 dy=-0.4446 g=8.6273\n",
            "  step 400/1683 | re=0.0072 dz=-2.2262 dy=-0.4574 g=9.2650\n",
            "  step 500/1683 | re=0.0065 dz=-1.8128 dy=-0.4673 g=9.3065\n",
            "  step 600/1683 | re=0.0071 dz=-1.7341 dy=-0.5330 g=9.8265\n",
            "  step 700/1683 | re=0.0073 dz=-1.6605 dy=-0.4985 g=10.0021\n",
            "  step 800/1683 | re=0.0066 dz=-1.6992 dy=-0.4835 g=10.5094\n",
            "  step 900/1683 | re=0.0067 dz=-1.5441 dy=-0.4937 g=9.6673\n",
            "  step 1000/1683 | re=0.0105 dz=-1.2943 dy=-0.4896 g=10.1037\n",
            "  step 1100/1683 | re=0.0131 dz=-0.9022 dy=-0.4685 g=9.6347\n",
            "  step 1200/1683 | re=0.0131 dz=-0.7048 dy=-0.5160 g=9.5326\n",
            "  step 1300/1683 | re=0.0102 dz=-0.8013 dy=-0.5189 g=9.8029\n",
            "  step 1400/1683 | re=0.0081 dz=-0.8360 dy=-0.4785 g=10.3540\n",
            "  step 1500/1683 | re=0.0084 dz=-0.7158 dy=-0.4098 g=9.6719\n",
            "  step 1600/1683 | re=0.0073 dz=-0.9122 dy=-0.4395 g=9.3029\n",
            "[VAL] recon=0.0093\n",
            "\n",
            "[TRAIN] Epoch 6/30\n",
            "  step 0/1683 | re=0.0183 dz=-0.5285 dy=-0.4949 g=8.9881\n",
            "  step 100/1683 | re=0.0090 dz=-0.8373 dy=-0.4602 g=8.9966\n",
            "  step 200/1683 | re=0.0071 dz=-0.8012 dy=-0.4528 g=9.4580\n",
            "  step 300/1683 | re=0.0074 dz=-0.6346 dy=-0.4559 g=9.5480\n",
            "  step 400/1683 | re=0.0070 dz=-0.5920 dy=-0.4441 g=9.3221\n",
            "  step 500/1683 | re=0.0066 dz=-0.6615 dy=-0.4649 g=9.9297\n",
            "  step 600/1683 | re=0.0062 dz=-0.6062 dy=-0.4733 g=9.3537\n",
            "  step 700/1683 | re=0.0061 dz=-0.4501 dy=-0.4365 g=8.5042\n",
            "  step 800/1683 | re=0.0060 dz=-0.3840 dy=-0.4642 g=7.8283\n",
            "  step 900/1683 | re=0.0059 dz=-0.2205 dy=-0.4984 g=7.3710\n",
            "  step 1000/1683 | re=0.0100 dz=-0.0074 dy=-0.4642 g=6.5956\n",
            "  step 1100/1683 | re=0.0113 dz=-0.5083 dy=-0.5016 g=6.6511\n",
            "  step 1200/1683 | re=0.0130 dz=-0.2656 dy=-0.5476 g=6.3654\n",
            "  step 1300/1683 | re=0.0092 dz=-0.1547 dy=-0.5413 g=6.5426\n",
            "  step 1400/1683 | re=0.0078 dz=-0.0069 dy=-0.5102 g=6.6721\n",
            "  step 1500/1683 | re=0.0071 dz=0.0740 dy=-0.4100 g=6.1020\n",
            "  step 1600/1683 | re=0.0060 dz=0.3609 dy=-0.4357 g=5.0342\n",
            "[VAL] recon=0.0084\n",
            "\n",
            "[TRAIN] Epoch 7/30\n",
            "  step 0/1683 | re=0.0157 dz=0.0143 dy=-0.4757 g=4.7655\n",
            "  step 100/1683 | re=0.0082 dz=0.1735 dy=-0.4070 g=3.9143\n",
            "  step 200/1683 | re=0.0070 dz=0.2303 dy=-0.4512 g=3.8248\n",
            "  step 300/1683 | re=0.0062 dz=0.3673 dy=-0.4464 g=2.9786\n",
            "  step 400/1683 | re=0.0062 dz=0.3411 dy=-0.4513 g=2.1256\n",
            "  step 500/1683 | re=0.0058 dz=0.4969 dy=-0.4386 g=1.6755\n",
            "  step 600/1683 | re=0.0054 dz=0.3707 dy=-0.5066 g=1.6079\n",
            "  step 700/1683 | re=0.0056 dz=0.2977 dy=-0.4276 g=1.1552\n",
            "  step 800/1683 | re=0.0057 dz=0.1230 dy=-0.3908 g=1.4460\n",
            "  step 900/1683 | re=0.0051 dz=0.1667 dy=-0.4144 g=1.1498\n",
            "  step 1000/1683 | re=0.0093 dz=0.1760 dy=-0.4371 g=1.5987\n",
            "  step 1100/1683 | re=0.0112 dz=0.3358 dy=-0.4452 g=1.2179\n",
            "  step 1200/1683 | re=0.0088 dz=0.3499 dy=-0.5184 g=1.0035\n",
            "  step 1300/1683 | re=0.0085 dz=0.2591 dy=-0.5197 g=1.4861\n",
            "  step 1400/1683 | re=0.0073 dz=0.1916 dy=-0.4704 g=2.0488\n",
            "  step 1500/1683 | re=0.0066 dz=0.3237 dy=-0.4375 g=2.3297\n",
            "  step 1600/1683 | re=0.0057 dz=0.1589 dy=-0.4214 g=1.3513\n",
            "[VAL] recon=0.0076\n",
            "\n",
            "[TRAIN] Epoch 8/30\n",
            "  step 0/1683 | re=0.0139 dz=0.2886 dy=-0.4130 g=1.6619\n",
            "  step 100/1683 | re=0.0080 dz=0.5387 dy=-0.4430 g=2.1443\n",
            "  step 200/1683 | re=0.0058 dz=0.3578 dy=-0.4383 g=2.8418\n",
            "  step 300/1683 | re=0.0055 dz=0.1986 dy=-0.4505 g=3.0917\n",
            "  step 400/1683 | re=0.0056 dz=0.3936 dy=-0.4385 g=3.4042\n",
            "  step 500/1683 | re=0.0059 dz=0.4364 dy=-0.3920 g=3.1119\n",
            "  step 600/1683 | re=0.0045 dz=0.4257 dy=-0.4204 g=3.5639\n",
            "  step 700/1683 | re=0.0052 dz=0.4887 dy=-0.4391 g=3.3986\n",
            "  step 800/1683 | re=0.0053 dz=0.7605 dy=-0.4339 g=3.0943\n",
            "  step 900/1683 | re=0.0048 dz=0.5022 dy=-0.4448 g=4.3393\n",
            "  step 1000/1683 | re=0.0077 dz=0.6434 dy=-0.4247 g=4.4557\n",
            "  step 1100/1683 | re=0.0113 dz=0.6966 dy=-0.5201 g=3.9228\n",
            "  step 1200/1683 | re=0.0097 dz=0.7298 dy=-0.5320 g=4.0858\n",
            "  step 1300/1683 | re=0.0069 dz=0.7256 dy=-0.5248 g=4.9892\n",
            "  step 1400/1683 | re=0.0070 dz=0.7608 dy=-0.4992 g=5.2922\n",
            "  step 1500/1683 | re=0.0058 dz=0.7208 dy=-0.4681 g=5.5767\n",
            "  step 1600/1683 | re=0.0049 dz=0.8759 dy=-0.4691 g=4.7396\n",
            "[VAL] recon=0.0071\n",
            "\n",
            "[TRAIN] Epoch 9/30\n",
            "  step 0/1683 | re=0.0176 dz=0.5540 dy=-0.4491 g=4.7788\n",
            "  step 100/1683 | re=0.0078 dz=0.6331 dy=-0.4663 g=4.9725\n",
            "  step 200/1683 | re=0.0057 dz=0.8201 dy=-0.4368 g=5.4300\n",
            "  step 300/1683 | re=0.0051 dz=1.0442 dy=-0.4608 g=5.4636\n",
            "  step 400/1683 | re=0.0051 dz=1.4340 dy=-0.4138 g=4.7627\n",
            "  step 500/1683 | re=0.0046 dz=1.1882 dy=-0.4280 g=4.9309\n",
            "  step 600/1683 | re=0.0046 dz=1.0566 dy=-0.4212 g=5.0280\n",
            "  step 700/1683 | re=0.0042 dz=0.8567 dy=-0.4293 g=5.8336\n",
            "  step 800/1683 | re=0.0048 dz=0.9230 dy=-0.4318 g=5.8423\n",
            "  step 900/1683 | re=0.0052 dz=0.7869 dy=-0.4230 g=5.3644\n",
            "  step 1000/1683 | re=0.0075 dz=1.2857 dy=-0.4043 g=4.8352\n",
            "  step 1100/1683 | re=0.0089 dz=1.1511 dy=-0.4672 g=5.0617\n",
            "  step 1200/1683 | re=0.0083 dz=1.2635 dy=-0.4685 g=4.8374\n",
            "  step 1300/1683 | re=0.0071 dz=1.0343 dy=-0.4994 g=4.6382\n",
            "  step 1400/1683 | re=0.0052 dz=0.9817 dy=-0.4578 g=4.3515\n",
            "  step 1500/1683 | re=0.0050 dz=1.4807 dy=-0.4838 g=3.9671\n",
            "  step 1600/1683 | re=0.0050 dz=1.2844 dy=-0.4536 g=3.5416\n",
            "[VAL] recon=0.0065\n",
            "\n",
            "[TRAIN] Epoch 10/30\n",
            "  step 0/1683 | re=0.0111 dz=1.2670 dy=-0.4383 g=3.4533\n",
            "  step 100/1683 | re=0.0056 dz=1.4118 dy=-0.3694 g=2.9381\n",
            "  step 200/1683 | re=0.0059 dz=1.5298 dy=-0.3847 g=2.8859\n",
            "  step 300/1683 | re=0.0043 dz=1.4036 dy=-0.4167 g=2.8572\n",
            "  step 400/1683 | re=0.0046 dz=1.0481 dy=-0.3851 g=2.9366\n",
            "  step 500/1683 | re=0.0045 dz=0.9050 dy=-0.3649 g=3.1410\n",
            "  step 600/1683 | re=0.0041 dz=1.3161 dy=-0.3813 g=3.3940\n",
            "  step 700/1683 | re=0.0044 dz=1.2955 dy=-0.4013 g=3.8275\n",
            "  step 800/1683 | re=0.0040 dz=1.2586 dy=-0.4398 g=3.6652\n",
            "  step 900/1683 | re=0.0038 dz=1.6097 dy=-0.4218 g=3.2051\n",
            "  step 1000/1683 | re=0.0077 dz=1.4383 dy=-0.4169 g=2.7597\n",
            "  step 1100/1683 | re=0.0088 dz=1.5647 dy=-0.4939 g=2.8136\n",
            "  step 1200/1683 | re=0.0076 dz=1.2886 dy=-0.5002 g=2.7510\n",
            "  step 1300/1683 | re=0.0065 dz=1.3274 dy=-0.4695 g=2.7181\n",
            "  step 1400/1683 | re=0.0058 dz=1.3454 dy=-0.4899 g=2.7453\n",
            "  step 1500/1683 | re=0.0042 dz=1.6118 dy=-0.4424 g=2.3802\n",
            "  step 1600/1683 | re=0.0044 dz=1.8627 dy=-0.4234 g=1.9182\n",
            "[VAL] recon=0.0061\n",
            "\n",
            "[TRAIN] Epoch 11/30\n",
            "  step 0/1683 | re=0.0116 dz=1.2331 dy=-0.4700 g=2.3641\n",
            "  step 100/1683 | re=0.0062 dz=1.6483 dy=-0.4421 g=1.9650\n",
            "  step 200/1683 | re=0.0045 dz=1.3005 dy=-0.3697 g=1.9144\n",
            "  step 300/1683 | re=0.0038 dz=1.6021 dy=-0.4343 g=1.9284\n",
            "  step 400/1683 | re=0.0040 dz=1.3235 dy=-0.3699 g=1.8596\n",
            "  step 500/1683 | re=0.0040 dz=1.6440 dy=-0.3856 g=2.0168\n",
            "  step 600/1683 | re=0.0040 dz=1.6251 dy=-0.3919 g=1.9573\n",
            "  step 700/1683 | re=0.0038 dz=1.3760 dy=-0.3894 g=2.0421\n",
            "  step 800/1683 | re=0.0035 dz=1.1102 dy=-0.3336 g=2.2422\n",
            "  step 900/1683 | re=0.0038 dz=1.2208 dy=-0.3451 g=2.3471\n",
            "  step 1000/1683 | re=0.0072 dz=1.3550 dy=-0.3827 g=1.8635\n",
            "  step 1100/1683 | re=0.0083 dz=1.4507 dy=-0.4628 g=1.7740\n",
            "  step 1200/1683 | re=0.0083 dz=1.3107 dy=-0.5059 g=1.9741\n",
            "  step 1300/1683 | re=0.0058 dz=1.1196 dy=-0.4738 g=1.9492\n",
            "  step 1400/1683 | re=0.0048 dz=1.4104 dy=-0.5335 g=2.0975\n",
            "  step 1500/1683 | re=0.0044 dz=1.3141 dy=-0.4408 g=2.1200\n",
            "  step 1600/1683 | re=0.0036 dz=1.9033 dy=-0.4430 g=2.0907\n",
            "[VAL] recon=0.0058\n",
            "\n",
            "[TRAIN] Epoch 12/30\n",
            "  step 0/1683 | re=0.0150 dz=1.4102 dy=-0.5070 g=2.6104\n",
            "  step 100/1683 | re=0.0063 dz=1.8806 dy=-0.4403 g=2.6700\n",
            "  step 200/1683 | re=0.0043 dz=1.7245 dy=-0.4050 g=3.3476\n",
            "  step 300/1683 | re=0.0036 dz=1.6144 dy=-0.4552 g=4.0219\n",
            "  step 400/1683 | re=0.0041 dz=2.0206 dy=-0.4449 g=3.6873\n",
            "  step 500/1683 | re=0.0036 dz=1.3956 dy=-0.4124 g=3.4017\n",
            "  step 600/1683 | re=0.0032 dz=1.6357 dy=-0.4310 g=2.7691\n",
            "  step 700/1683 | re=0.0038 dz=2.2693 dy=-0.3960 g=2.1076\n",
            "  step 800/1683 | re=0.0034 dz=1.5508 dy=-0.4488 g=2.1173\n",
            "  step 900/1683 | re=0.0030 dz=1.4256 dy=-0.4255 g=1.7700\n",
            "  step 1000/1683 | re=0.0083 dz=1.5008 dy=-0.4690 g=1.4417\n",
            "  step 1100/1683 | re=0.0086 dz=1.5662 dy=-0.4550 g=1.1010\n",
            "  step 1200/1683 | re=0.0079 dz=1.3918 dy=-0.5255 g=1.0629\n",
            "  step 1300/1683 | re=0.0066 dz=1.4766 dy=-0.5003 g=0.9412\n",
            "  step 1400/1683 | re=0.0052 dz=1.2980 dy=-0.5041 g=0.8476\n",
            "  step 1500/1683 | re=0.0036 dz=1.3069 dy=-0.4171 g=0.2312\n",
            "  step 1600/1683 | re=0.0032 dz=0.9885 dy=-0.4296 g=0.2549\n",
            "[VAL] recon=0.0054\n",
            "\n",
            "[TRAIN] Epoch 13/30\n",
            "  step 0/1683 | re=0.0135 dz=1.3027 dy=-0.4607 g=0.0407\n",
            "  step 100/1683 | re=0.0058 dz=1.4674 dy=-0.4078 g=-0.3385\n",
            "  step 200/1683 | re=0.0041 dz=1.0991 dy=-0.4824 g=-0.0973\n",
            "  step 300/1683 | re=0.0036 dz=1.1732 dy=-0.4396 g=-0.4219\n",
            "  step 400/1683 | re=0.0030 dz=0.9027 dy=-0.4139 g=-0.2726\n",
            "  step 500/1683 | re=0.0031 dz=1.2043 dy=-0.4153 g=-0.2421\n",
            "  step 600/1683 | re=0.0030 dz=1.2981 dy=-0.3466 g=-0.1094\n",
            "  step 700/1683 | re=0.0030 dz=1.5019 dy=-0.3438 g=-0.0867\n",
            "  step 800/1683 | re=0.0033 dz=1.4439 dy=-0.3654 g=0.2950\n",
            "  step 900/1683 | re=0.0029 dz=1.2978 dy=-0.3725 g=0.6323\n",
            "  step 1000/1683 | re=0.0053 dz=1.3421 dy=-0.4000 g=1.3529\n",
            "  step 1100/1683 | re=0.0070 dz=0.7090 dy=-0.4730 g=1.9604\n",
            "  step 1200/1683 | re=0.0067 dz=0.6177 dy=-0.4605 g=1.6453\n",
            "  step 1300/1683 | re=0.0054 dz=0.9720 dy=-0.4731 g=1.3907\n",
            "  step 1400/1683 | re=0.0039 dz=1.0424 dy=-0.4923 g=1.5127\n",
            "  step 1500/1683 | re=0.0039 dz=1.0304 dy=-0.4076 g=1.5302\n",
            "  step 1600/1683 | re=0.0035 dz=0.5389 dy=-0.4339 g=1.9684\n",
            "[VAL] recon=0.0050\n",
            "\n",
            "[TRAIN] Epoch 14/30\n",
            "  step 0/1683 | re=0.0115 dz=0.3497 dy=-0.4618 g=2.2612\n",
            "  step 100/1683 | re=0.0051 dz=0.3576 dy=-0.4427 g=2.2566\n",
            "  step 200/1683 | re=0.0036 dz=0.4581 dy=-0.4492 g=2.2190\n",
            "  step 300/1683 | re=0.0030 dz=0.5720 dy=-0.4029 g=2.4078\n",
            "  step 400/1683 | re=0.0030 dz=0.8747 dy=-0.4308 g=2.4167\n",
            "  step 500/1683 | re=0.0031 dz=0.8025 dy=-0.4218 g=2.9924\n",
            "  step 600/1683 | re=0.0026 dz=0.6411 dy=-0.4025 g=3.5187\n",
            "  step 700/1683 | re=0.0029 dz=0.8677 dy=-0.3918 g=3.4253\n",
            "  step 800/1683 | re=0.0028 dz=0.8592 dy=-0.4757 g=3.3311\n",
            "  step 900/1683 | re=0.0028 dz=1.1308 dy=-0.4500 g=2.6501\n",
            "  step 1000/1683 | re=0.0064 dz=1.1385 dy=-0.4033 g=1.8882\n",
            "  step 1100/1683 | re=0.0072 dz=0.7757 dy=-0.4481 g=2.0546\n",
            "  step 1200/1683 | re=0.0065 dz=0.5795 dy=-0.4206 g=2.1330\n",
            "  step 1300/1683 | re=0.0055 dz=0.3584 dy=-0.5244 g=3.1630\n",
            "  step 1400/1683 | re=0.0040 dz=0.4090 dy=-0.4532 g=3.8694\n",
            "  step 1500/1683 | re=0.0042 dz=0.5915 dy=-0.4525 g=3.9508\n",
            "  step 1600/1683 | re=0.0030 dz=0.6920 dy=-0.4152 g=3.7452\n",
            "[VAL] recon=0.0048\n",
            "\n",
            "[TRAIN] Epoch 15/30\n",
            "  step 0/1683 | re=0.0132 dz=0.4945 dy=-0.4371 g=3.9517\n",
            "  step 100/1683 | re=0.0046 dz=0.7108 dy=-0.4071 g=3.6481\n",
            "  step 200/1683 | re=0.0032 dz=1.2153 dy=-0.4213 g=2.5225\n",
            "  step 300/1683 | re=0.0028 dz=1.2918 dy=-0.3984 g=1.7408\n",
            "  step 400/1683 | re=0.0029 dz=1.0838 dy=-0.3679 g=1.2931\n",
            "  step 500/1683 | re=0.0027 dz=0.9085 dy=-0.3947 g=1.2521\n",
            "  step 600/1683 | re=0.0025 dz=1.1306 dy=-0.3508 g=1.0484\n",
            "  step 700/1683 | re=0.0025 dz=0.6683 dy=-0.3966 g=0.7879\n",
            "  step 800/1683 | re=0.0028 dz=0.2634 dy=-0.3926 g=0.6747\n",
            "  step 900/1683 | re=0.0024 dz=0.3041 dy=-0.3720 g=0.7218\n",
            "  step 1000/1683 | re=0.0053 dz=0.6336 dy=-0.3643 g=1.0265\n",
            "  step 1100/1683 | re=0.0085 dz=0.3316 dy=-0.4680 g=2.2916\n",
            "  step 1200/1683 | re=0.0070 dz=0.3866 dy=-0.4665 g=2.9935\n",
            "  step 1300/1683 | re=0.0050 dz=0.4390 dy=-0.4932 g=3.6794\n",
            "  step 1400/1683 | re=0.0036 dz=0.4676 dy=-0.5089 g=4.3828\n",
            "  step 1500/1683 | re=0.0032 dz=0.5705 dy=-0.4222 g=5.1006\n",
            "  step 1600/1683 | re=0.0031 dz=1.1163 dy=-0.4468 g=5.8354\n",
            "[VAL] recon=0.0045\n",
            "\n",
            "[TRAIN] Epoch 16/30\n",
            "  step 0/1683 | re=0.0115 dz=1.0311 dy=-0.4924 g=6.4000\n",
            "  step 100/1683 | re=0.0044 dz=1.0346 dy=-0.3766 g=6.6214\n",
            "  step 200/1683 | re=0.0028 dz=1.1543 dy=-0.4088 g=6.4906\n",
            "  step 300/1683 | re=0.0032 dz=1.1344 dy=-0.3897 g=5.9868\n",
            "  step 400/1683 | re=0.0031 dz=0.9071 dy=-0.3864 g=5.6330\n",
            "  step 500/1683 | re=0.0026 dz=0.4985 dy=-0.3891 g=5.4829\n",
            "  step 600/1683 | re=0.0026 dz=0.5242 dy=-0.3626 g=5.5909\n",
            "  step 700/1683 | re=0.0025 dz=1.2127 dy=-0.3481 g=5.8726\n",
            "  step 800/1683 | re=0.0026 dz=2.0118 dy=-0.3477 g=5.2060\n",
            "  step 900/1683 | re=0.0026 dz=1.9727 dy=-0.3488 g=4.8709\n",
            "  step 1000/1683 | re=0.0045 dz=0.1376 dy=-0.3775 g=5.1667\n",
            "  step 1100/1683 | re=0.0079 dz=0.2146 dy=-0.4875 g=4.8550\n",
            "  step 1200/1683 | re=0.0061 dz=0.3128 dy=-0.4115 g=4.4258\n",
            "  step 1300/1683 | re=0.0038 dz=0.6421 dy=-0.4322 g=4.1920\n",
            "  step 1400/1683 | re=0.0034 dz=0.8277 dy=-0.4235 g=4.1622\n",
            "  step 1500/1683 | re=0.0031 dz=1.0777 dy=-0.4201 g=4.1822\n",
            "  step 1600/1683 | re=0.0025 dz=1.0876 dy=-0.3843 g=3.8643\n",
            "[VAL] recon=0.0043\n",
            "\n",
            "[TRAIN] Epoch 17/30\n",
            "  step 0/1683 | re=0.0099 dz=1.0094 dy=-0.4271 g=3.7363\n",
            "  step 100/1683 | re=0.0048 dz=1.5581 dy=-0.3837 g=3.7348\n",
            "  step 200/1683 | re=0.0033 dz=1.5718 dy=-0.3815 g=3.4412\n",
            "  step 300/1683 | re=0.0025 dz=1.3083 dy=-0.3601 g=3.1449\n",
            "  step 400/1683 | re=0.0024 dz=1.4089 dy=-0.3629 g=2.9376\n",
            "  step 500/1683 | re=0.0024 dz=2.3605 dy=-0.3642 g=2.9525\n",
            "  step 600/1683 | re=0.0025 dz=0.9119 dy=-0.3598 g=3.8634\n",
            "  step 700/1683 | re=0.0024 dz=0.6862 dy=-0.3804 g=4.4839\n",
            "  step 800/1683 | re=0.0020 dz=0.2108 dy=-0.3511 g=5.0774\n",
            "  step 900/1683 | re=0.0021 dz=0.5814 dy=-0.3299 g=4.7168\n",
            "  step 1000/1683 | re=0.0047 dz=0.8040 dy=-0.3563 g=4.3757\n",
            "  step 1100/1683 | re=0.0073 dz=0.7949 dy=-0.4409 g=4.6780\n",
            "  step 1200/1683 | re=0.0057 dz=0.9760 dy=-0.4933 g=4.8203\n",
            "  step 1300/1683 | re=0.0038 dz=0.7998 dy=-0.4459 g=4.8023\n",
            "  step 1400/1683 | re=0.0030 dz=0.6289 dy=-0.3866 g=4.7920\n",
            "  step 1500/1683 | re=0.0029 dz=0.8045 dy=-0.3430 g=4.6303\n",
            "  step 1600/1683 | re=0.0027 dz=0.9046 dy=-0.3884 g=4.3334\n",
            "[VAL] recon=0.0042\n",
            "\n",
            "[TRAIN] Epoch 18/30\n",
            "  step 0/1683 | re=0.0114 dz=1.0403 dy=-0.4357 g=4.1425\n",
            "  step 100/1683 | re=0.0047 dz=1.3758 dy=-0.4002 g=3.8265\n",
            "  step 200/1683 | re=0.0026 dz=1.4134 dy=-0.3693 g=3.7410\n",
            "  step 300/1683 | re=0.0025 dz=1.1796 dy=-0.3779 g=4.0164\n",
            "  step 400/1683 | re=0.0024 dz=0.9920 dy=-0.3507 g=4.1314\n",
            "  step 500/1683 | re=0.0022 dz=1.3218 dy=-0.3463 g=3.8422\n",
            "  step 600/1683 | re=0.0023 dz=1.3867 dy=-0.3424 g=3.5323\n",
            "  step 700/1683 | re=0.0023 dz=1.5950 dy=-0.3071 g=3.2514\n",
            "  step 800/1683 | re=0.0021 dz=1.7440 dy=-0.3350 g=3.7645\n",
            "  step 900/1683 | re=0.0023 dz=0.8337 dy=-0.3603 g=4.0310\n",
            "  step 1000/1683 | re=0.0047 dz=0.9823 dy=-0.3277 g=3.4032\n",
            "  step 1100/1683 | re=0.0074 dz=0.9273 dy=-0.4278 g=3.6453\n",
            "  step 1200/1683 | re=0.0049 dz=0.9229 dy=-0.4544 g=3.5443\n",
            "  step 1300/1683 | re=0.0037 dz=1.1025 dy=-0.4336 g=3.3771\n",
            "  step 1400/1683 | re=0.0033 dz=0.9033 dy=-0.4579 g=3.3644\n",
            "  step 1500/1683 | re=0.0023 dz=1.0462 dy=-0.4186 g=3.1006\n",
            "  step 1600/1683 | re=0.0026 dz=1.1651 dy=-0.3859 g=2.6673\n",
            "[VAL] recon=0.0039\n",
            "\n",
            "[TRAIN] Epoch 19/30\n",
            "  step 0/1683 | re=0.0102 dz=1.2680 dy=-0.4430 g=2.6543\n",
            "  step 100/1683 | re=0.0045 dz=1.2552 dy=-0.4061 g=2.4715\n",
            "  step 200/1683 | re=0.0022 dz=1.6212 dy=-0.3793 g=2.2059\n",
            "  step 300/1683 | re=0.0025 dz=1.7265 dy=-0.3220 g=2.1172\n",
            "  step 400/1683 | re=0.0023 dz=1.6613 dy=-0.3333 g=2.1070\n",
            "  step 500/1683 | re=0.0021 dz=1.9213 dy=-0.2782 g=2.0561\n",
            "  step 600/1683 | re=0.0022 dz=1.0969 dy=-0.3054 g=2.6701\n",
            "  step 700/1683 | re=0.0021 dz=0.2586 dy=-0.3074 g=1.6752\n",
            "  step 800/1683 | re=0.0020 dz=0.4836 dy=-0.3090 g=1.2158\n",
            "  step 900/1683 | re=0.0020 dz=0.6532 dy=-0.3417 g=1.0414\n",
            "  step 1000/1683 | re=0.0054 dz=0.6970 dy=-0.3419 g=0.8262\n",
            "  step 1100/1683 | re=0.0060 dz=0.7356 dy=-0.4618 g=1.2691\n",
            "  step 1200/1683 | re=0.0055 dz=0.8130 dy=-0.4436 g=1.2248\n",
            "  step 1300/1683 | re=0.0034 dz=1.0414 dy=-0.4403 g=1.1267\n",
            "  step 1400/1683 | re=0.0031 dz=0.9464 dy=-0.5011 g=1.4009\n",
            "  step 1500/1683 | re=0.0035 dz=1.1807 dy=-0.4396 g=1.3372\n",
            "  step 1600/1683 | re=0.0023 dz=1.0482 dy=-0.4085 g=1.6423\n",
            "[VAL] recon=0.0040\n",
            "\n",
            "[TRAIN] Epoch 20/30\n",
            "  step 0/1683 | re=0.0095 dz=1.4504 dy=-0.4896 g=1.9211\n",
            "  step 100/1683 | re=0.0048 dz=1.0874 dy=-0.4428 g=2.8049\n",
            "  step 200/1683 | re=0.0026 dz=1.1012 dy=-0.4071 g=3.5258\n",
            "  step 300/1683 | re=0.0022 dz=1.0806 dy=-0.3755 g=4.0470\n",
            "  step 400/1683 | re=0.0024 dz=1.0047 dy=-0.3670 g=4.4305\n",
            "  step 500/1683 | re=0.0020 dz=0.9979 dy=-0.3290 g=4.5239\n",
            "  step 600/1683 | re=0.0024 dz=1.6507 dy=-0.3522 g=4.1235\n",
            "  step 700/1683 | re=0.0020 dz=1.7647 dy=-0.3361 g=3.6038\n",
            "  step 800/1683 | re=0.0019 dz=1.9775 dy=-0.3129 g=2.8598\n",
            "  step 900/1683 | re=0.0023 dz=2.0786 dy=-0.3632 g=2.7323\n",
            "  step 1000/1683 | re=0.0064 dz=2.3981 dy=-0.3202 g=2.3567\n",
            "  step 1100/1683 | re=0.0067 dz=1.9222 dy=-0.4219 g=2.3596\n",
            "  step 1200/1683 | re=0.0057 dz=1.9750 dy=-0.4471 g=2.2736\n",
            "  step 1300/1683 | re=0.0032 dz=1.9357 dy=-0.3946 g=2.0499\n",
            "  step 1400/1683 | re=0.0030 dz=1.6586 dy=-0.4324 g=2.3824\n",
            "  step 1500/1683 | re=0.0026 dz=1.2788 dy=-0.4359 g=2.4950\n",
            "  step 1600/1683 | re=0.0021 dz=1.1363 dy=-0.3692 g=2.0927\n",
            "[VAL] recon=0.0038\n",
            "\n",
            "[TRAIN] Epoch 21/30\n",
            "  step 0/1683 | re=0.0097 dz=1.3729 dy=-0.4237 g=2.1110\n",
            "  step 100/1683 | re=0.0043 dz=1.4786 dy=-0.3775 g=1.6249\n",
            "  step 200/1683 | re=0.0037 dz=1.5251 dy=-0.3702 g=1.4070\n",
            "  step 300/1683 | re=0.0022 dz=1.6476 dy=-0.3894 g=1.1953\n",
            "  step 400/1683 | re=0.0020 dz=1.8146 dy=-0.4124 g=1.0817\n",
            "  step 500/1683 | re=0.0019 dz=1.9940 dy=-0.4180 g=1.0878\n",
            "  step 600/1683 | re=0.0019 dz=1.1421 dy=-0.4127 g=2.2382\n",
            "  step 700/1683 | re=0.0020 dz=1.0301 dy=-0.3982 g=2.4856\n",
            "  step 800/1683 | re=0.0019 dz=1.1744 dy=-0.3749 g=2.2066\n",
            "  step 900/1683 | re=0.0019 dz=1.1970 dy=-0.3505 g=1.9051\n",
            "  step 1000/1683 | re=0.0059 dz=1.7456 dy=-0.3883 g=1.6388\n",
            "  step 1100/1683 | re=0.0065 dz=1.6354 dy=-0.4178 g=1.4564\n",
            "  step 1200/1683 | re=0.0052 dz=1.7906 dy=-0.4388 g=1.1881\n",
            "  step 1300/1683 | re=0.0031 dz=1.7261 dy=-0.4963 g=1.1302\n",
            "  step 1400/1683 | re=0.0028 dz=1.2456 dy=-0.4245 g=0.9982\n",
            "  step 1500/1683 | re=0.0030 dz=0.9733 dy=-0.4367 g=1.0400\n",
            "  step 1600/1683 | re=0.0021 dz=1.0527 dy=-0.3947 g=0.5787\n",
            "[VAL] recon=0.0038\n",
            "\n",
            "[TRAIN] Epoch 22/30\n",
            "  step 0/1683 | re=0.0093 dz=1.3158 dy=-0.4824 g=0.6006\n",
            "  step 100/1683 | re=0.0037 dz=1.3633 dy=-0.3888 g=0.1457\n",
            "  step 200/1683 | re=0.0029 dz=1.5485 dy=-0.4027 g=0.1380\n",
            "  step 300/1683 | re=0.0023 dz=1.5022 dy=-0.3803 g=0.3154\n",
            "  step 400/1683 | re=0.0018 dz=1.7878 dy=-0.3584 g=0.9471\n",
            "  step 500/1683 | re=0.0017 dz=0.9292 dy=-0.3211 g=1.5328\n",
            "  step 600/1683 | re=0.0017 dz=0.7503 dy=-0.3014 g=1.0485\n",
            "  step 700/1683 | re=0.0018 dz=1.1460 dy=-0.3419 g=0.8376\n",
            "  step 800/1683 | re=0.0017 dz=1.4036 dy=-0.3157 g=1.0482\n",
            "  step 900/1683 | re=0.0020 dz=0.6180 dy=-0.3364 g=1.5576\n",
            "  step 1000/1683 | re=0.0035 dz=0.6433 dy=-0.3749 g=1.7641\n",
            "  step 1100/1683 | re=0.0062 dz=0.3915 dy=-0.4295 g=2.2560\n",
            "  step 1200/1683 | re=0.0044 dz=0.6123 dy=-0.3994 g=2.4151\n",
            "  step 1300/1683 | re=0.0033 dz=0.3294 dy=-0.4477 g=2.9927\n",
            "  step 1400/1683 | re=0.0030 dz=0.4379 dy=-0.4388 g=3.3678\n",
            "  step 1500/1683 | re=0.0020 dz=0.8240 dy=-0.3944 g=3.5756\n",
            "  step 1600/1683 | re=0.0025 dz=1.0782 dy=-0.3963 g=3.7798\n",
            "[VAL] recon=0.0036\n",
            "\n",
            "[TRAIN] Epoch 23/30\n",
            "  step 0/1683 | re=0.0087 dz=0.4408 dy=-0.4420 g=4.6954\n",
            "  step 100/1683 | re=0.0048 dz=0.7198 dy=-0.3902 g=4.8063\n",
            "  step 200/1683 | re=0.0024 dz=0.8228 dy=-0.4057 g=5.0519\n",
            "  step 300/1683 | re=0.0020 dz=0.7640 dy=-0.3553 g=4.8932\n",
            "  step 400/1683 | re=0.0019 dz=1.1014 dy=-0.3486 g=4.3088\n",
            "  step 500/1683 | re=0.0019 dz=1.0592 dy=-0.3063 g=3.8034\n",
            "  step 600/1683 | re=0.0018 dz=0.5252 dy=-0.3179 g=4.7081\n",
            "  step 700/1683 | re=0.0017 dz=0.1773 dy=-0.3552 g=4.4811\n",
            "  step 800/1683 | re=0.0017 dz=0.8092 dy=-0.3853 g=3.9105\n",
            "  step 900/1683 | re=0.0018 dz=1.2951 dy=-0.3816 g=3.5352\n",
            "  step 1000/1683 | re=0.0035 dz=1.5320 dy=-0.4267 g=3.6167\n",
            "  step 1100/1683 | re=0.0050 dz=0.3218 dy=-0.4003 g=4.9170\n",
            "  step 1200/1683 | re=0.0047 dz=0.4426 dy=-0.4738 g=4.6516\n",
            "  step 1300/1683 | re=0.0032 dz=0.9743 dy=-0.4538 g=4.1379\n",
            "  step 1400/1683 | re=0.0023 dz=1.1674 dy=-0.4049 g=3.8465\n",
            "  step 1500/1683 | re=0.0022 dz=1.3586 dy=-0.4280 g=3.7675\n",
            "  step 1600/1683 | re=0.0021 dz=1.1108 dy=-0.3891 g=3.5999\n",
            "[VAL] recon=0.0034\n",
            "\n",
            "[TRAIN] Epoch 24/30\n",
            "  step 0/1683 | re=0.0096 dz=1.3955 dy=-0.4955 g=3.5528\n",
            "  step 100/1683 | re=0.0034 dz=0.7956 dy=-0.4141 g=3.0160\n",
            "  step 200/1683 | re=0.0025 dz=1.1193 dy=-0.3706 g=2.3813\n",
            "  step 300/1683 | re=0.0017 dz=1.4096 dy=-0.3433 g=2.3114\n",
            "  step 400/1683 | re=0.0020 dz=1.3839 dy=-0.4104 g=2.3052\n",
            "  step 500/1683 | re=0.0017 dz=1.6615 dy=-0.3784 g=2.3133\n",
            "  step 600/1683 | re=0.0017 dz=1.8358 dy=-0.3784 g=2.4999\n",
            "  step 700/1683 | re=0.0015 dz=1.3656 dy=-0.3178 g=2.8178\n",
            "  step 800/1683 | re=0.0018 dz=1.0928 dy=-0.3591 g=3.0950\n",
            "  step 900/1683 | re=0.0016 dz=1.0267 dy=-0.3343 g=3.1080\n",
            "  step 1000/1683 | re=0.0037 dz=0.8084 dy=-0.3225 g=2.8065\n",
            "  step 1100/1683 | re=0.0053 dz=0.8943 dy=-0.4300 g=3.3616\n",
            "  step 1200/1683 | re=0.0049 dz=0.8513 dy=-0.4402 g=3.5712\n",
            "  step 1300/1683 | re=0.0032 dz=1.0683 dy=-0.4475 g=3.8055\n",
            "  step 1400/1683 | re=0.0030 dz=1.1259 dy=-0.4787 g=4.1670\n",
            "  step 1500/1683 | re=0.0027 dz=1.3206 dy=-0.3980 g=4.2073\n",
            "  step 1600/1683 | re=0.0021 dz=1.3484 dy=-0.3847 g=4.0913\n",
            "[VAL] recon=0.0036\n",
            "\n",
            "[TRAIN] Epoch 25/30\n",
            "  step 0/1683 | re=0.0095 dz=0.8647 dy=-0.3749 g=4.7796\n",
            "  step 100/1683 | re=0.0037 dz=1.0525 dy=-0.3908 g=4.7177\n",
            "  step 200/1683 | re=0.0025 dz=1.3112 dy=-0.3116 g=3.9266\n",
            "  step 300/1683 | re=0.0024 dz=1.0556 dy=-0.3261 g=3.6272\n",
            "  step 400/1683 | re=0.0019 dz=0.6938 dy=-0.3160 g=3.6870\n",
            "  step 500/1683 | re=0.0017 dz=1.0962 dy=-0.3424 g=3.0620\n",
            "  step 600/1683 | re=0.0017 dz=1.6302 dy=-0.3216 g=2.1832\n",
            "  step 700/1683 | re=0.0017 dz=1.0215 dy=-0.3138 g=2.6925\n",
            "  step 800/1683 | re=0.0018 dz=1.6967 dy=-0.3220 g=2.9606\n",
            "  step 900/1683 | re=0.0016 dz=1.8950 dy=-0.3371 g=2.8551\n",
            "  step 1000/1683 | re=0.0042 dz=2.0246 dy=-0.3534 g=3.5559\n",
            "  step 1100/1683 | re=0.0056 dz=0.9048 dy=-0.3933 g=4.9439\n",
            "  step 1200/1683 | re=0.0040 dz=0.8603 dy=-0.4203 g=4.2450\n",
            "  step 1300/1683 | re=0.0038 dz=1.4493 dy=-0.4486 g=3.7192\n",
            "  step 1400/1683 | re=0.0021 dz=1.2088 dy=-0.3750 g=3.2007\n",
            "  step 1500/1683 | re=0.0018 dz=1.1596 dy=-0.3884 g=3.0398\n",
            "  step 1600/1683 | re=0.0019 dz=1.5499 dy=-0.3454 g=2.6742\n",
            "[VAL] recon=0.0034\n",
            "\n",
            "[TRAIN] Epoch 26/30\n",
            "  step 0/1683 | re=0.0085 dz=1.6370 dy=-0.3878 g=2.5026\n",
            "  step 100/1683 | re=0.0031 dz=1.5662 dy=-0.3968 g=2.4181\n",
            "  step 200/1683 | re=0.0024 dz=0.6674 dy=-0.3806 g=4.0261\n",
            "  step 300/1683 | re=0.0018 dz=0.9884 dy=-0.3212 g=3.5030\n",
            "  step 400/1683 | re=0.0017 dz=1.3001 dy=-0.3888 g=3.4972\n",
            "  step 500/1683 | re=0.0017 dz=1.6268 dy=-0.3435 g=4.3187\n",
            "  step 600/1683 | re=0.0015 dz=1.2830 dy=-0.3113 g=3.3482\n",
            "  step 700/1683 | re=0.0018 dz=1.8100 dy=-0.3241 g=3.0238\n",
            "  step 800/1683 | re=0.0018 dz=0.9423 dy=-0.3311 g=2.9494\n",
            "  step 900/1683 | re=0.0016 dz=0.5456 dy=-0.3153 g=3.5735\n",
            "  step 1000/1683 | re=0.0038 dz=1.3569 dy=-0.3226 g=2.5508\n",
            "  step 1100/1683 | re=0.0059 dz=1.7124 dy=-0.4206 g=2.1975\n",
            "  step 1200/1683 | re=0.0046 dz=0.1765 dy=-0.4540 g=3.4344\n",
            "  step 1300/1683 | re=0.0025 dz=0.9751 dy=-0.4565 g=3.3596\n",
            "  step 1400/1683 | re=0.0031 dz=0.9834 dy=-0.4725 g=3.5668\n",
            "  step 1500/1683 | re=0.0020 dz=1.7764 dy=-0.4179 g=3.3320\n",
            "  step 1600/1683 | re=0.0019 dz=1.4372 dy=-0.3706 g=4.4616\n",
            "[VAL] recon=0.0032\n",
            "\n",
            "[TRAIN] Epoch 27/30\n",
            "  step 0/1683 | re=0.0083 dz=-0.2346 dy=-0.4012 g=5.4197\n",
            "  step 100/1683 | re=0.0031 dz=0.6196 dy=-0.3506 g=4.2043\n",
            "  step 200/1683 | re=0.0023 dz=1.5081 dy=-0.3305 g=3.3653\n",
            "  step 300/1683 | re=0.0014 dz=1.6689 dy=-0.3140 g=2.6323\n",
            "  step 400/1683 | re=0.0018 dz=0.4652 dy=-0.3243 g=3.9548\n",
            "  step 500/1683 | re=0.0015 dz=1.4520 dy=-0.3449 g=2.8291\n",
            "  step 600/1683 | re=0.0017 dz=1.0453 dy=-0.3731 g=2.6469\n",
            "  step 700/1683 | re=0.0016 dz=0.5747 dy=-0.3407 g=2.6838\n",
            "  step 800/1683 | re=0.0017 dz=1.4517 dy=-0.3545 g=2.0866\n",
            "  step 900/1683 | re=0.0017 dz=1.0825 dy=-0.3639 g=2.7334\n",
            "  step 1000/1683 | re=0.0039 dz=1.0246 dy=-0.3552 g=3.1064\n",
            "  step 1100/1683 | re=0.0062 dz=0.8374 dy=-0.4253 g=3.2627\n",
            "  step 1200/1683 | re=0.0039 dz=1.1272 dy=-0.4409 g=3.2729\n",
            "  step 1300/1683 | re=0.0028 dz=0.8892 dy=-0.3861 g=2.8098\n",
            "  step 1400/1683 | re=0.0025 dz=0.8318 dy=-0.4348 g=2.4375\n",
            "  step 1500/1683 | re=0.0019 dz=0.8617 dy=-0.3599 g=2.5359\n",
            "  step 1600/1683 | re=0.0017 dz=1.1705 dy=-0.4119 g=2.5472\n",
            "[VAL] recon=0.0032\n",
            "\n",
            "[TRAIN] Epoch 28/30\n",
            "  step 0/1683 | re=0.0092 dz=1.4463 dy=-0.5075 g=3.1145\n",
            "  step 100/1683 | re=0.0028 dz=0.9762 dy=-0.3563 g=3.5588\n",
            "  step 200/1683 | re=0.0020 dz=0.6149 dy=-0.3668 g=3.6160\n",
            "  step 300/1683 | re=0.0019 dz=0.4329 dy=-0.3462 g=3.2843\n",
            "  step 400/1683 | re=0.0015 dz=1.0298 dy=-0.3622 g=2.7374\n",
            "  step 500/1683 | re=0.0015 dz=0.6398 dy=-0.3620 g=3.0085\n",
            "  step 600/1683 | re=0.0018 dz=1.0734 dy=-0.3366 g=2.1256\n",
            "  step 700/1683 | re=0.0016 dz=0.0928 dy=-0.3248 g=3.0361\n",
            "  step 800/1683 | re=0.0014 dz=1.2348 dy=-0.3266 g=2.7298\n",
            "  step 900/1683 | re=0.0015 dz=0.9608 dy=-0.3609 g=2.6785\n",
            "  step 1000/1683 | re=0.0051 dz=0.2074 dy=-0.3562 g=3.7396\n",
            "  step 1100/1683 | re=0.0054 dz=0.9162 dy=-0.4252 g=3.8238\n",
            "  step 1200/1683 | re=0.0040 dz=0.6902 dy=-0.4280 g=4.3851\n",
            "  step 1300/1683 | re=0.0022 dz=0.3408 dy=-0.4441 g=3.2720\n",
            "  step 1400/1683 | re=0.0023 dz=0.4650 dy=-0.4258 g=2.1928\n",
            "  step 1500/1683 | re=0.0020 dz=0.4294 dy=-0.3673 g=1.7420\n",
            "  step 1600/1683 | re=0.0014 dz=0.6348 dy=-0.3338 g=2.0773\n",
            "[VAL] recon=0.0031\n",
            "\n",
            "[TRAIN] Epoch 29/30\n",
            "  step 0/1683 | re=0.0083 dz=0.6248 dy=-0.3904 g=2.9769\n",
            "  step 100/1683 | re=0.0029 dz=0.5629 dy=-0.3721 g=2.7754\n",
            "  step 200/1683 | re=0.0021 dz=1.0516 dy=-0.3945 g=2.5841\n",
            "  step 300/1683 | re=0.0015 dz=1.2816 dy=-0.2990 g=2.3289\n",
            "  step 400/1683 | re=0.0014 dz=1.2844 dy=-0.2892 g=2.6943\n",
            "  step 500/1683 | re=0.0014 dz=1.2452 dy=-0.2952 g=3.5100\n",
            "  step 600/1683 | re=0.0014 dz=1.4041 dy=-0.3278 g=3.7775\n",
            "  step 700/1683 | re=0.0013 dz=1.5623 dy=-0.2940 g=3.7428\n",
            "  step 800/1683 | re=0.0015 dz=1.4586 dy=-0.2890 g=3.8148\n",
            "  step 900/1683 | re=0.0014 dz=1.7510 dy=-0.2785 g=3.7940\n",
            "  step 1000/1683 | re=0.0040 dz=1.0811 dy=-0.3213 g=3.8437\n",
            "  step 1100/1683 | re=0.0054 dz=1.5578 dy=-0.3753 g=4.0520\n",
            "  step 1200/1683 | re=0.0046 dz=1.6179 dy=-0.3892 g=3.7814\n",
            "  step 1300/1683 | re=0.0025 dz=1.9155 dy=-0.3971 g=3.7504\n",
            "  step 1400/1683 | re=0.0019 dz=1.2151 dy=-0.4544 g=3.7368\n",
            "  step 1500/1683 | re=0.0023 dz=1.4974 dy=-0.3807 g=3.4767\n",
            "  step 1600/1683 | re=0.0016 dz=1.6091 dy=-0.3461 g=3.6063\n",
            "[VAL] recon=0.0031\n",
            "\n",
            "[TRAIN] Epoch 30/30\n",
            "  step 0/1683 | re=0.0085 dz=1.2405 dy=-0.3748 g=4.4053\n",
            "  step 100/1683 | re=0.0031 dz=1.3303 dy=-0.3491 g=4.3928\n",
            "  step 200/1683 | re=0.0021 dz=0.7735 dy=-0.3284 g=4.4789\n",
            "  step 300/1683 | re=0.0016 dz=1.3643 dy=-0.3419 g=3.5541\n",
            "  step 400/1683 | re=0.0017 dz=1.3447 dy=-0.2968 g=3.2140\n",
            "  step 500/1683 | re=0.0014 dz=0.5326 dy=-0.3072 g=3.9069\n",
            "  step 600/1683 | re=0.0016 dz=1.0415 dy=-0.2987 g=3.3458\n",
            "  step 700/1683 | re=0.0014 dz=1.7981 dy=-0.3128 g=2.9634\n",
            "  step 800/1683 | re=0.0015 dz=1.3531 dy=-0.3574 g=3.3147\n",
            "  step 900/1683 | re=0.0013 dz=0.9242 dy=-0.3105 g=4.0843\n",
            "  step 1000/1683 | re=0.0044 dz=0.8093 dy=-0.2926 g=4.0056\n",
            "  step 1100/1683 | re=0.0054 dz=1.3974 dy=-0.3906 g=3.9365\n",
            "  step 1200/1683 | re=0.0042 dz=1.2452 dy=-0.4127 g=4.2133\n",
            "  step 1300/1683 | re=0.0031 dz=1.2457 dy=-0.3920 g=4.2860\n",
            "  step 1400/1683 | re=0.0027 dz=1.3998 dy=-0.4341 g=4.0265\n",
            "  step 1500/1683 | re=0.0020 dz=0.8033 dy=-0.3408 g=3.9079\n",
            "  step 1600/1683 | re=0.0015 dz=0.6113 dy=-0.3703 g=3.8405\n",
            "[VAL] recon=0.0031\n",
            "[SAVE] models stored\n",
            "\n",
            "[RESULT] ROC-AUC=0.9316 | Thr=0.003435 | TPR=0.878 | FPR=0.155\n",
            "[CM]\n",
            " [[39026  7164]\n",
            " [ 2996 21527]]\n",
            "[Report]\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.93      0.84      0.88     46190\n",
            "      Attack       0.75      0.88      0.81     24523\n",
            "\n",
            "    accuracy                           0.86     70713\n",
            "   macro avg       0.84      0.86      0.85     70713\n",
            "weighted avg       0.87      0.86      0.86     70713\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ============================================================\n",
        "# caae_full.py –  Conv-AAE end-to-end pipeline (A→Z)\n",
        "# ============================================================\n",
        "\n",
        "import os, glob, itertools, cv2, numpy as np, pandas as pd, tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0) GPU setup (optional)\n",
        "# ------------------------------------------------------------\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Hyper-parameters\n",
        "# ------------------------------------------------------------\n",
        "IMG_SHAPE   = (32, 32, 2)              # <-- תמונת-קלט\n",
        "FEATURE_DIM = np.prod(IMG_SHAPE)       # 29*29*2\n",
        "N_LABELS    = 2\n",
        "\n",
        "BATCH       = 128\n",
        "EPOCHS      = 30\n",
        "\n",
        "LATENT_DIM  = 64\n",
        "λ_gp        = 10.0\n",
        "\n",
        "LR_AE = 5e-4\n",
        "LR_DZ = 1e-4\n",
        "LR_DY = 1e-4\n",
        "LR_G  = 5e-5\n",
        "\n",
        "ACTIVATION = 'elu'\n",
        "DROPOUT    = 0.2\n",
        "NORM_TYPE  = 'layer'           # layer / batch\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) Pre-processing & TFRecord creation  (ללא שינוי לוגי)\n",
        "# ------------------------------------------------------------\n",
        "datasets = [\n",
        "    'Attack_free_CHEVROLET_Spark_train',\n",
        "    'parsed_dataset',\n",
        "    'Attack_free_HYUNDAI_Sonata_train',\n",
        "    'Attack_free_KIA_Soul_train',\n",
        "    'Flooding_CHEVROLET_Spark_train',\n",
        "    'Flooding_HYUNDAI_Sonata_train',\n",
        "    'Flooding_KIA_Soul_train',\n",
        "    'Fuzzy_CHEVROLET_Spark_train',\n",
        "    'Fuzzy_HYUNDAI_Sonata_train',\n",
        "    'Fuzzy_KIA_Soul_train',\n",
        "    'Malfunction_CHEVROLET_Spark_train',\n",
        "    'Malfunction_HYUNDAI_Sonata_train',\n",
        "    'Malfunction_KIA_Soul_train',\n",
        "    'Attack_free_HY_Sonata_train',\n",
        "    'Attack_free_KIA_Soul_train',\n",
        "    'Fuzzy_dataset_HY_Sonata_train',\n",
        "    'Fuzzy_dataset_KIA_Soul_train',\n",
        "    'Malfunction_1st_dataset_HY_Sonata_train',\n",
        "    'Malfunction_1st_dataset_KIA_Soul_train',\n",
        "    'Malfunction_2nd_HY_Sonata_train',\n",
        "    'Malfunction_2nd_KIA_Soul_train',\n",
        "    'Replay_dataset_HY_Sonata_train',\n",
        "    'Replay_dataset_KIA_Soul_train',\n",
        "    'gear_dataset',\n",
        "    'DoS_dataset',\n",
        "    'RPM_dataset',\n",
        "    'Fuzzy_dataset',\n",
        "]\n",
        "csv_map = {\n",
        "    'Attack_free_CHEVROLET_Spark_train':   'Attack_free_CHEVROLET_Spark_train.cleaned.csv',\n",
        "    'Attack_free_HYUNDAI_Sonata_train':    'Attack_free_HYUNDAI_Sonata_train.cleaned.csv',\n",
        "    'Attack_free_KIA_Soul_train':          'Attack_free_KIA_Soul_train.cleaned.csv',\n",
        "    'Flooding_CHEVROLET_Spark_train':      'Flooding_CHEVROLET_Spark_train.cleaned.csv',\n",
        "    'Flooding_HYUNDAI_Sonata_train':       'Flooding_HYUNDAI_Sonata_train.cleaned.csv',\n",
        "    'Flooding_KIA_Soul_train':             'Flooding_KIA_Soul_train.cleaned.csv',\n",
        "    'Fuzzy_CHEVROLET_Spark_train':         'Fuzzy_CHEVROLET_Spark_train.cleaned.csv',\n",
        "    'Fuzzy_HYUNDAI_Sonata_train':          'Fuzzy_HYUNDAI_Sonata_train.cleaned.csv',\n",
        "    'Fuzzy_KIA_Soul_train':                'Fuzzy_KIA_Soul_train.cleaned.csv',\n",
        "    'Malfunction_CHEVROLET_Spark_train':   'Malfunction_CHEVROLET_Spark_train.cleaned.csv',\n",
        "    'Malfunction_HYUNDAI_Sonata_train':    'Malfunction_HYUNDAI_Sonata_train.cleaned.csv',\n",
        "    'Malfunction_KIA_Soul_train':          'Malfunction_KIA_Soul_train.cleaned.csv',\n",
        "    'Attack_free_HY_Sonata_train':              'Attack_free_HY_Sonata_train.cleaned_Final.csv',\n",
        "    'Attack_free_KIA_Soul_train':               'Attack_free_KIA_Soul_train.cleaned_Final.csv',\n",
        "    'Fuzzy_dataset_HY_Sonata_train':            'Fuzzy_dataset_HY_Sonata_train.cleaned_Final.csv',\n",
        "    'Fuzzy_dataset_KIA_Soul_train':             'Fuzzy_dataset_KIA_Soul_train.cleaned_Final.csv',\n",
        "    'Malfunction_1st_dataset_HY_Sonata_train':  'Malfunction_1st_dataset_HY_Sonata_train.cleaned_Final.csv',\n",
        "    'Malfunction_1st_dataset_KIA_Soul_train':   'Malfunction_1st_dataset_KIA_Soul_train.cleaned_Final.csv',\n",
        "    'Malfunction_2nd_HY_Sonata_train':          'Malfunction_2nd_HY_Sonata_train.cleaned_Final.csv',\n",
        "    'Malfunction_2nd_KIA_Soul_train':           'Malfunction_2nd_KIA_Soul_train.cleaned_Final.csv',\n",
        "    'Replay_dataset_HY_Sonata_train':           'Replay_dataset_HY_Sonata_train.cleaned_Final.csv',\n",
        "    'Replay_dataset_KIA_Soul_train':            'Replay_dataset_KIA_Soul_train.cleaned_Final.csv',\n",
        "    'parsed_dataset':                           'parsed_dataset.csv',\n",
        "    'gear_dataset':                             'gear_dataset.csv',\n",
        "    'DoS_dataset':                              'DoS_dataset.csv',\n",
        "    'RPM_dataset':                              'RPM_dataset.csv',\n",
        "    'Fuzzy_dataset':                            'Fuzzy_dataset.csv',\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "def fill_flag(row):\n",
        "    if not isinstance(row['Label'], str):\n",
        "        col = 'Data' + str(int(row['DLC']))\n",
        "        row['Flag'] = row.get(col, row['Label'])\n",
        "    return row\n",
        "\n",
        "def convert_canid_bits(cid):\n",
        "    try:\n",
        "        return np.array(list(map(int, bin(int(str(cid),16))[2:].zfill(29))), dtype=np.uint8)\n",
        "    except:\n",
        "        return np.zeros(29, dtype=np.uint8)\n",
        "\n",
        "def hex_to_int(x):\n",
        "    try: return int(str(x).strip(), 16)\n",
        "    except: return 0\n",
        "\n",
        "# Replace the preprocess_windows function with this fixed version:\n",
        "def preprocess_windows(csv_file):\n",
        "    print(f\"[DATA] Processing {csv_file}\")\n",
        "    cols = ['Timestamp','canID','DLC']+[f'Data{i}' for i in range(8)] + ['Label']\n",
        "    df   = pd.read_csv(csv_file, header=None, names=cols, low_memory=False)\n",
        "\n",
        "    df['Timestamp'] = pd.to_numeric(df['Timestamp'], errors='coerce')\n",
        "    df['DLC']       = pd.to_numeric(df['DLC'], errors='coerce').fillna(0).astype(int)\n",
        "    df = df.dropna(subset=['Timestamp','canID']).apply(fill_flag, axis=1)\n",
        "\n",
        "    for i in range(8):\n",
        "        df[f'Data{i}'] = df[f'Data{i}'].apply(hex_to_int).astype(np.uint8)\n",
        "\n",
        "    df['Label']    = df['Label'].astype(str).str.upper().eq('T').astype(np.uint8)\n",
        "    df['canBits'] = df['canID'].apply(convert_canid_bits)\n",
        "    df = df.sort_values('Timestamp')\n",
        "\n",
        "    bits_all   = np.stack(df['canBits'].values)\n",
        "    data_bytes = df[[f'Data{i}' for i in range(8)]].values\n",
        "    flags_all  = df['Label'].values\n",
        "\n",
        "    win = 29\n",
        "    N   = len(bits_all)//win\n",
        "    bits   = bits_all[:N*win].reshape(N, win, 29)\n",
        "    data   = data_bytes[:N*win].reshape(N, win, 8)\n",
        "    flags  = flags_all[:N*win].reshape(N, win)\n",
        "\n",
        "    rows = []\n",
        "    for i in range(N):\n",
        "        id_block = bits[i]\n",
        "        id_img   = cv2.resize(id_block.astype(np.uint8), (32, 32),\n",
        "                              interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        last_b = data[i,-1,:]\n",
        "        b8     = np.unpackbits(last_b).reshape(8,8)\n",
        "        data_img = cv2.resize(b8.astype(np.float32), (32, 32),\n",
        "                              interpolation=cv2.INTER_NEAREST) > .5\n",
        "\n",
        "        two_ch = np.stack([id_img, data_img.astype(np.uint8)], axis=-1)  # 32x32x2\n",
        "        rows.append((two_ch.flatten().tolist(), int(flags[i].any())))\n",
        "    return rows\n",
        "\n",
        "\n",
        "def write_tfrecord(rows, base):\n",
        "    np.random.shuffle(rows)\n",
        "    ntr = int(.7*len(rows)); nvl = int(.15*len(rows))\n",
        "    splits = {'train':rows[:ntr], 'val':rows[ntr:ntr+nvl], 'test':rows[ntr+nvl:]}\n",
        "    for phase, chunk in splits.items():\n",
        "        with tf.io.TFRecordWriter(f\"{base}_{phase}.tfrecord\") as w:\n",
        "            for feat,lbl in chunk:\n",
        "                ex = tf.train.Example(\n",
        "                     features=tf.train.Features(feature={\n",
        "                     'features': tf.train.Feature(int64_list=tf.train.Int64List(value=feat)),\n",
        "                     'label':    tf.train.Feature(int64_list=tf.train.Int64List(value=[lbl]))}))\n",
        "                w.write(ex.SerializeToString())\n",
        "\n",
        "# צור TFRecords אם חסרים\n",
        "\n",
        "print(\"[DATA] Creating TFRecords…\")\n",
        "for d in datasets:\n",
        "    if not os.path.exists(csv_map[d]): continue\n",
        "    rows = preprocess_windows(csv_map[d])\n",
        "    normals = [r for r in rows if r[1]==0]\n",
        "    attacks = [r for r in rows if r[1]==1]\n",
        "    write_tfrecord(normals, f\"Normal_{d}\")\n",
        "    if attacks: write_tfrecord(attacks, d)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) tf.data pipeline\n",
        "# ------------------------------------------------------------\n",
        "def parse_feat(proto):\n",
        "    fs = {'features': tf.io.FixedLenFeature([FEATURE_DIM], tf.int64),\n",
        "          'label':    tf.io.FixedLenFeature([1], tf.int64)}\n",
        "    feat = tf.io.parse_single_example(proto, fs)\n",
        "    x = tf.cast(feat['features'], tf.float32)\n",
        "    x = tf.reshape(x, IMG_SHAPE)              # <-- תמונה\n",
        "    y = tf.one_hot(tf.cast(feat['label'][0], tf.int32), N_LABELS)\n",
        "    return x, y\n",
        "\n",
        "train_files = glob.glob('Normal_*_train.tfrecord')\n",
        "train_ds = (\n",
        "    tf.data.TFRecordDataset(train_files, num_parallel_reads=tf.data.AUTOTUNE)\n",
        "    .map(parse_feat, tf.data.AUTOTUNE)\n",
        "    .map(lambda x,y: (x + tf.random.normal(tf.shape(x),0,0.01), x, y), tf.data.AUTOTUNE)\n",
        "    .shuffle(10000).repeat()\n",
        "    .batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "steps_per_epoch = sum(1 for _ in tf.data.TFRecordDataset(train_files)) // BATCH\n",
        "print(f\"[PIPE] records={steps_per_epoch*BATCH}, steps/epoch={steps_per_epoch}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4) CAAE Model\n",
        "# ------------------------------------------------------------\n",
        "def dense_block(units):\n",
        "    layers = [tf.keras.layers.Dense(units)]\n",
        "    if NORM_TYPE=='layer': layers.append(tf.keras.layers.LayerNormalization())\n",
        "    elif NORM_TYPE=='batch': layers.append(tf.keras.layers.BatchNormalization())\n",
        "    layers.append(tf.keras.layers.Activation(ACTIVATION))\n",
        "    if DROPOUT>0: layers.append(tf.keras.layers.Dropout(DROPOUT))\n",
        "    return tf.keras.Sequential(layers)\n",
        "\n",
        "class ConvAAE(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # ---- encoder\n",
        "        self.enc_c1  = tf.keras.layers.Conv2D(32,(3,3),strides=2,padding='same',activation=ACTIVATION)\n",
        "        self.enc_c2  = tf.keras.layers.Conv2D(64,(3,3),strides=2,padding='same',activation=ACTIVATION)\n",
        "        self.enc_flat= tf.keras.layers.Flatten()\n",
        "        self.enc_fc  = dense_block(256)\n",
        "        self.z_layer = tf.keras.layers.Dense(LATENT_DIM)\n",
        "        self.y_logits= tf.keras.layers.Dense(N_LABELS)\n",
        "\n",
        "        # ---- decoder\n",
        "        self.dec_fc   = dense_block(8*8*64)\n",
        "        self.dec_reshape = tf.keras.layers.Reshape((8,8,64))\n",
        "        self.dec_t1  = tf.keras.layers.Conv2DTranspose(64,(3,3),strides=2,padding='same',activation=ACTIVATION)\n",
        "        self.dec_t2  = tf.keras.layers.Conv2DTranspose(32,(3,3),strides=2,padding='same',activation=ACTIVATION)\n",
        "        self.dec_out = tf.keras.layers.Conv2DTranspose(2,(3,3),padding='same',activation='sigmoid')\n",
        "\n",
        "        # ---- discriminators (z , y)\n",
        "        self.dz = tf.keras.Sequential([dense_block(256),\n",
        "                                       dense_block(128),\n",
        "                                       tf.keras.layers.Dense(1)])\n",
        "        self.dy = tf.keras.Sequential([dense_block(256),\n",
        "                                       dense_block(128),\n",
        "                                       tf.keras.layers.Dense(1)])\n",
        "\n",
        "    # ---------- forward passes ----------\n",
        "    def encode(self, x):\n",
        "        h = self.enc_c2(self.enc_c1(x))\n",
        "        h = self.enc_fc(self.enc_flat(h))\n",
        "        z = self.z_layer(h)\n",
        "        logits = self.y_logits(h)\n",
        "        y = tf.nn.softmax(logits)\n",
        "        return z, y, logits\n",
        "\n",
        "    def decode(self, z, y):\n",
        "        h = tf.concat([z,y], axis=1)\n",
        "        h = self.dec_fc(h)\n",
        "        h = self.dec_reshape(h)\n",
        "        h = self.dec_t2(self.dec_t1(h))\n",
        "        return self.dec_out(h)\n",
        "\n",
        "    def discriminate_z(self, z): return self.dz(z)\n",
        "    def discriminate_y(self, y): return self.dy(y)\n",
        "\n",
        "    @staticmethod\n",
        "    def gp(f, real, fake):\n",
        "        α = tf.random.uniform([real.shape[0],1],0,1)\n",
        "        inter = real + α*(fake-real)\n",
        "        with tf.GradientTape() as t:\n",
        "            t.watch(inter); p=f(inter)\n",
        "        g = t.gradient(p, inter)\n",
        "        slopes = tf.sqrt(tf.reduce_sum(tf.square(g), axis=1)+1e-8)\n",
        "        return tf.reduce_mean((slopes-1.)**2)\n",
        "\n",
        "caae = ConvAAE()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4.5) Warm-up: לבנות את כל המשתנים לפני האופטימיזרים\n",
        "# ------------------------------------------------------------\n",
        "dummy_x = tf.zeros((1,) + IMG_SHAPE, dtype=tf.float32)\n",
        "z0, y0, _ = caae.encode(dummy_x)\n",
        "_ = caae.decode(z0, y0)\n",
        "_ = caae.discriminate_z(tf.random.normal((1, LATENT_DIM)))\n",
        "_ = caae.discriminate_y(tf.one_hot([0], depth=N_LABELS))\n",
        "print(\"[BUILD] all layer variables created:\", len(caae.trainable_variables))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5) Losses & optimizers  (עם רשימות קבועות)\n",
        "# ------------------------------------------------------------\n",
        "ae_vars = (\n",
        "    caae.enc_c1.trainable_variables + caae.enc_c2.trainable_variables +\n",
        "    caae.enc_fc.trainable_variables + caae.z_layer.trainable_variables +\n",
        "    caae.y_logits.trainable_variables +\n",
        "    caae.dec_fc.trainable_variables + caae.dec_reshape.trainable_variables +\n",
        "    caae.dec_t1.trainable_variables + caae.dec_t2.trainable_variables +\n",
        "    caae.dec_out.trainable_variables\n",
        ")\n",
        "dz_vars = caae.dz.trainable_variables\n",
        "dy_vars = caae.dy.trainable_variables\n",
        "enc_vars = (\n",
        "    caae.enc_c1.trainable_variables + caae.enc_c2.trainable_variables +\n",
        "    caae.enc_fc.trainable_variables + caae.z_layer.trainable_variables +\n",
        "    caae.y_logits.trainable_variables\n",
        ")\n",
        "\n",
        "mse  = tf.keras.losses.MeanSquaredError()\n",
        "ce   = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "opt_ae = tf.keras.optimizers.Adam(LR_AE)\n",
        "opt_dz = tf.keras.optimizers.Adam(LR_DZ)\n",
        "opt_dy = tf.keras.optimizers.Adam(LR_DY)\n",
        "opt_g  = tf.keras.optimizers.Adam(LR_G)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6) Training step (tf.function)\n",
        "# ------------------------------------------------------------\n",
        "@tf.function\n",
        "def train_step(x_noisy, x_clean, y_lbl):\n",
        "    # ---------- auto-encoder ----------\n",
        "    with tf.GradientTape() as t_ae:\n",
        "        z_enc, y_enc, _ = caae.encode(x_noisy)\n",
        "        x_rec = caae.decode(z_enc, y_enc)\n",
        "        loss_re = mse(x_clean, x_rec)\n",
        "    grads = t_ae.gradient(loss_re, ae_vars)\n",
        "    opt_ae.apply_gradients(zip(grads, ae_vars))\n",
        "\n",
        "    # ---------- discriminator-z ----------\n",
        "    with tf.GradientTape() as t_dz:\n",
        "        z_real = tf.random.normal([tf.shape(x_noisy)[0], LATENT_DIM])\n",
        "        dz_r   = caae.discriminate_z(z_real)\n",
        "        dz_f   = caae.discriminate_z(z_enc)\n",
        "        gp_z   = caae.gp(caae.discriminate_z, z_real, z_enc)\n",
        "        loss_dz = tf.reduce_mean(dz_f) - tf.reduce_mean(dz_r) + λ_gp * gp_z\n",
        "    opt_dz.apply_gradients(zip(t_dz.gradient(loss_dz, dz_vars), dz_vars))\n",
        "\n",
        "    # ---------- discriminator-y ----------\n",
        "    with tf.GradientTape() as t_dy:\n",
        "        dy_r = caae.discriminate_y(y_lbl)\n",
        "        _, y_enc2, _ = caae.encode(x_clean)\n",
        "        dy_f = caae.discriminate_y(y_enc2)\n",
        "        gp_y = caae.gp(caae.discriminate_y, y_lbl, y_enc2)\n",
        "        loss_dy = tf.reduce_mean(dy_f) - tf.reduce_mean(dy_r) + λ_gp * gp_y\n",
        "    opt_dy.apply_gradients(zip(t_dy.gradient(loss_dy, dy_vars), dy_vars))\n",
        "\n",
        "    # ---------- generator / encoder adversarial ----------\n",
        "    with tf.GradientTape() as t_g:\n",
        "        z_g, y_g, logits = caae.encode(x_clean)\n",
        "        loss_g = (\n",
        "            -tf.reduce_mean(caae.discriminate_z(z_g))\n",
        "            -tf.reduce_mean(caae.discriminate_y(y_g))\n",
        "            + ce(y_lbl, logits)\n",
        "        )\n",
        "    opt_g.apply_gradients(zip(t_g.gradient(loss_g, enc_vars), enc_vars))\n",
        "\n",
        "    return loss_re, loss_dz, loss_dy, loss_g\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7) Training loop\n",
        "# ------------------------------------------------------------\n",
        "re_hist, dz_hist, dy_hist, g_hist, val_hist = [],[],[],[],[]\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    print(f\"\\n[TRAIN] Epoch {epoch}/{EPOCHS}\")\n",
        "    ep_re=ep_dz=ep_dy=ep_g=0\n",
        "    for step,(xn, xc, y) in enumerate(train_ds.take(steps_per_epoch)):\n",
        "        lr,ldz,ldy,lg = train_step(xn, xc, y)\n",
        "        ep_re+=lr.numpy(); ep_dz+=ldz.numpy(); ep_dy+=ldy.numpy(); ep_g+=lg.numpy()\n",
        "        if step%100==0:\n",
        "            print(f\"  step {step}/{steps_per_epoch} | re={lr:.4f} dz={ldz:.4f} dy={ldy:.4f} g={lg:.4f}\")\n",
        "    re_hist.append(ep_re/steps_per_epoch)\n",
        "    dz_hist.append(ep_dz/steps_per_epoch)\n",
        "    dy_hist.append(ep_dy/steps_per_epoch)\n",
        "    g_hist .append(ep_g /steps_per_epoch)\n",
        "\n",
        "    # -------- validation recon ----------\n",
        "    val_loss, n_batches = 0,0\n",
        "    for fn in glob.glob('Normal_*_val.tfrecord'):\n",
        "        for x_val,_ in tf.data.TFRecordDataset(fn).map(parse_feat).batch(BATCH):\n",
        "            x_rec = caae.decode(*caae.encode(x_val)[0:2])\n",
        "            val_loss += mse(x_val, x_rec).numpy()\n",
        "            n_batches += 1\n",
        "    val_hist.append(val_loss/n_batches)\n",
        "    print(f\"[VAL] recon={val_hist[-1]:.4f}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 8) Save encoder & decoder\n",
        "# ------------------------------------------------------------\n",
        "from tensorflow.keras.layers import Input, Activation, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# --- Encoder\n",
        "enc_in = Input(shape=IMG_SHAPE)\n",
        "h = caae.enc_c2(caae.enc_c1(enc_in))\n",
        "h = caae.enc_fc(caae.enc_flat(h))\n",
        "z_out = caae.z_layer(h)\n",
        "y_log = caae.y_logits(h)\n",
        "y_out = Activation('softmax')(y_log)\n",
        "encoder = Model(enc_in, [z_out,y_out], name='caae_encoder')\n",
        "\n",
        "# --- Decoder\n",
        "z_in = Input(shape=(LATENT_DIM,))\n",
        "y_in = Input(shape=(N_LABELS,))\n",
        "h2   = caae.dec_fc(Concatenate()([z_in,y_in]))\n",
        "h2   = caae.dec_reshape(h2)\n",
        "h2   = caae.dec_t2(caae.dec_t1(h2))\n",
        "dec_out = caae.dec_out(h2)\n",
        "decoder = Model([z_in,y_in], dec_out, name='caae_decoder')\n",
        "\n",
        "encoder.save('caae_encoder.keras')\n",
        "decoder.save('caae_decoder.keras')\n",
        "print(\"[SAVE] models stored\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 9) Evaluation\n",
        "# ------------------------------------------------------------\n",
        "errs, ys = [], []\n",
        "for fn in glob.glob('*_test.tfrecord'):\n",
        "    label = 0 if fn.startswith('Normal_') else 1\n",
        "    for x_batch,_ in tf.data.TFRecordDataset(fn).map(parse_feat).batch(256):\n",
        "        z_p,y_p = encoder(x_batch)\n",
        "        x_r = decoder([z_p,y_p])\n",
        "        e = tf.reduce_mean(tf.square(x_batch - x_r), axis=[1,2,3]).numpy()\n",
        "        errs.append(e); ys.append(np.full(e.shape,label))\n",
        "errs = np.concatenate(errs)\n",
        "ys   = np.concatenate(ys)\n",
        "\n",
        "fpr,tpr,ths = roc_curve(ys, errs)\n",
        "roc_auc     = auc(fpr,tpr)\n",
        "best_idx    = np.argmax(tpr-fpr)\n",
        "thr_opt     = ths[best_idx]\n",
        "\n",
        "print(f\"\\n[RESULT] ROC-AUC={roc_auc:.4f} | Thr={thr_opt:.6f} | \"\n",
        "      f\"TPR={tpr[best_idx]:.3f} | FPR={fpr[best_idx]:.3f}\")\n",
        "cm = confusion_matrix(ys, (errs>thr_opt).astype(int))\n",
        "print(\"[CM]\\n\", cm)\n",
        "print(\"[Report]\\n\", classification_report(ys,(errs>thr_opt).astype(int),\n",
        "                                          target_names=['Normal','Attack']))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 10) Plotting\n",
        "# ------------------------------------------------------------\n",
        "# -- Reconstruction loss curves\n",
        "plt.figure(); plt.plot(re_hist,label='Train'); plt.plot(val_hist,label='Val')\n",
        "plt.xlabel('Epoch'); plt.ylabel('MSE'); plt.title('Reconstruction Loss'); plt.legend(); plt.show()\n",
        "\n",
        "# -- Adversarial losses\n",
        "plt.figure(); plt.plot(dz_hist,label='Disc-z'); plt.plot(dy_hist,label='Disc-y'); plt.plot(g_hist,label='Gen')\n",
        "plt.xlabel('Epoch'); plt.ylabel('Wasserstein'); plt.title('Adversarial Losses'); plt.legend(); plt.show()\n",
        "\n",
        "# -- ROC curve\n",
        "plt.figure(); plt.plot(fpr,tpr,label=f'AUC={roc_auc:.3f}'); plt.plot([0,1],[0,1],'k--')\n",
        "plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC Curve'); plt.legend(); plt.show()\n",
        "\n",
        "# -- Confusion-matrix heat-map\n",
        "plt.figure(); plt.imshow(cm,cmap=plt.cm.Blues); plt.title('Confusion Matrix'); plt.colorbar()\n",
        "ticks = np.arange(2); classes=['Normal','Attack']\n",
        "plt.xticks(ticks,classes,rotation=45); plt.yticks(ticks,classes)\n",
        "th = cm.max()/2\n",
        "for i,j in itertools.product(range(2),range(2)):\n",
        "    plt.text(j,i,cm[i,j],ha='center',color='white' if cm[i,j]>th else 'black')\n",
        "plt.ylabel('True'); plt.xlabel('Predicted'); plt.tight_layout(); plt.show()\n",
        "\n",
        "# -- Error distributions\n",
        "plt.figure()\n",
        "plt.hist(errs[ys==0],bins=50,alpha=.5,label='Normal')\n",
        "plt.hist(errs[ys==1],bins=50,alpha=.5,label='Attack')\n",
        "plt.xlabel('Reconstruction error'); plt.ylabel('Count')\n",
        "plt.title('Error Distribution'); plt.legend(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import pandas as pd\n",
        "\n",
        "def clean_and_save_csv(csv_file: str) -> str:\n",
        "    \"\"\"\n",
        "    מנקה קובץ CSV: מסיר עמודת אינדקס, מפצל ומרפד את עמודת ה-Data, ושומר מחדש.\n",
        "    Label תמיד תופיע אחרי DATA[7].\n",
        "\n",
        "    Args:\n",
        "        csv_file (str): הנתיב לקובץ המקורי.\n",
        "\n",
        "    Returns:\n",
        "        str: הנתיב לקובץ החדש שנשמר.\n",
        "    \"\"\"\n",
        "    # קריאה עם עמודה אחת ל־Data\n",
        "\n",
        "    cols = ['Timestamp', 'CAN ID', 'DLC', 'Data', 'Label']\n",
        "    df = pd.read_csv(csv_file, header=None, names=cols, low_memory=False)\n",
        "\n",
        "    # הסרת עמודת index\n",
        "\n",
        "    # המרות בסיסיות\n",
        "    df['Timestamp'] = pd.to_numeric(df['Timestamp'], errors='coerce')\n",
        "    df['DLC'] = pd.to_numeric(df['DLC'], errors='coerce').fillna(0).astype(int)\n",
        "    df = df.dropna(subset=['Timestamp', 'CAN ID'])\n",
        "\n",
        "    # ניקוי ערכי Data\n",
        "    def process_data_field(raw):\n",
        "        if pd.isna(raw): return ['00'] * 8\n",
        "        raw = str(raw).replace(\" \", \"\")  # הסרת רווחים\n",
        "        bytes_list = [raw[i:i+2] for i in range(0, len(raw), 2)]\n",
        "        while len(bytes_list) < 8:\n",
        "            bytes_list.append(\"00\")\n",
        "        return bytes_list[:8]\n",
        "\n",
        "    # החלת הפיצול והפירוק\n",
        "    processed_data = df['Data'].apply(process_data_field)\n",
        "    data_df = pd.DataFrame(processed_data.tolist(), columns=[f'DATA[{i}]' for i in range(8)])\n",
        "    df.drop(columns=['Data'], inplace=True)\n",
        "\n",
        "    # עדכון DLC ל-8 אם היה פחות\n",
        "    df['DLC'] = 8\n",
        "\n",
        "    # בניית הסדר הנכון מחדש\n",
        "    final_df = pd.concat([df[['Timestamp', 'CAN ID', 'DLC']].reset_index(drop=True),\n",
        "                          data_df.reset_index(drop=True),\n",
        "                          df[['Label']].reset_index(drop=True)], axis=1)\n",
        "\n",
        "    # שמירה\n",
        "    out_file = Path(csv_file).with_suffix('.cleaned.csv')\n",
        "    final_df.to_csv(out_file, index=False)\n",
        "    logging.info(f\"[CLEAN] Saved cleaned file: {out_file}\")\n",
        "    return str(out_file)\n",
        "\n",
        "# רשימת שמות הקבצים מתוך התמונה\n",
        "csv_files = [\n",
        "    \"Attack_free_CHEVROLET_Spark_train.csv\",\n",
        "    \"Attack_free_HYUNDAI_Sonata_train.csv\",\n",
        "    \"Attack_free_KIA_Soul_train.csv\",\n",
        "    \"Flooding_CHEVROLET_Spark_train.csv\",\n",
        "    \"Flooding_HYUNDAI_Sonata_train.csv\",\n",
        "    \"Flooding_KIA_Soul_train.csv\",\n",
        "    \"Fuzzy_CHEVROLET_Spark_train.csv\",\n",
        "    \"Fuzzy_HYUNDAI_Sonata_train.csv\",\n",
        "    \"Fuzzy_KIA_Soul_train.csv\",\n",
        "    \"Malfunction_CHEVROLET_Spark_train.csv\",\n",
        "    \"Malfunction_HYUNDAI_Sonata_train.csv\",\n",
        "    \"Malfunction_KIA_Soul_train.csv\",\n",
        "    'Attack_free_HY_Sonata_train.csv',\n",
        "    'Attack_free_KIA_Soul_train.csv',\n",
        "    'Fuzzy_dataset_HY_Sonata_train.csv',\n",
        "    'Fuzzy_dataset_KIA_Soul_train.csv',\n",
        "    'Malfunction_1st_dataset_HY_Sonata_train.csv',\n",
        "    'Malfunction_1st_dataset_KIA_Soul_train.csv',\n",
        "    'Malfunction_2nd_HY_Sonata_train.csv',\n",
        "    'Malfunction_2nd_KIA_Soul_train.csv',\n",
        "    'Replay_dataset_HY_Sonata_train.csv',\n",
        "    'Replay_dataset_KIA_Soul_train.csv'\n",
        "]\n",
        "\n",
        "\n",
        "# נתיב לתיקייה המכילה את הקבצים\n",
        "\n",
        "# הפעלת הפונקציה על כל קובץ\n",
        "for fname in csv_files:\n",
        "    try:\n",
        "        cleaned_path = clean_and_save_csv(str(fname))\n",
        "        print(f\"[✓] Cleaned: {cleaned_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[✗] Failed: {fname} — {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lOd27u7PrG8",
        "outputId": "226cb774-73ac-4907-e979-62663bd40463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[✓] Cleaned: Attack_free_CHEVROLET_Spark_train.cleaned.csv\n",
            "[✓] Cleaned: Attack_free_HYUNDAI_Sonata_train.cleaned.csv\n",
            "[✓] Cleaned: Attack_free_KIA_Soul_train.cleaned.csv\n",
            "[✓] Cleaned: Flooding_CHEVROLET_Spark_train.cleaned.csv\n",
            "[✓] Cleaned: Flooding_HYUNDAI_Sonata_train.cleaned.csv\n",
            "[✓] Cleaned: Flooding_KIA_Soul_train.cleaned.csv\n",
            "[✓] Cleaned: Fuzzy_CHEVROLET_Spark_train.cleaned.csv\n",
            "[✓] Cleaned: Fuzzy_HYUNDAI_Sonata_train.cleaned.csv\n",
            "[✓] Cleaned: Fuzzy_KIA_Soul_train.cleaned.csv\n",
            "[✓] Cleaned: Malfunction_CHEVROLET_Spark_train.cleaned.csv\n",
            "[✓] Cleaned: Malfunction_HYUNDAI_Sonata_train.cleaned.csv\n",
            "[✓] Cleaned: Malfunction_KIA_Soul_train.cleaned.csv\n",
            "[✓] Cleaned: Attack_free_HY_Sonata_train.cleaned.csv\n",
            "[✓] Cleaned: Attack_free_KIA_Soul_train.cleaned.csv\n",
            "[✓] Cleaned: Fuzzy_dataset_HY_Sonata_train.cleaned.csv\n",
            "[✓] Cleaned: Fuzzy_dataset_KIA_Soul_train.cleaned.csv\n",
            "[✓] Cleaned: Malfunction_1st_dataset_HY_Sonata_train.cleaned.csv\n",
            "[✓] Cleaned: Malfunction_1st_dataset_KIA_Soul_train.cleaned.csv\n",
            "[✓] Cleaned: Malfunction_2nd_HY_Sonata_train.cleaned.csv\n",
            "[✓] Cleaned: Malfunction_2nd_KIA_Soul_train.cleaned.csv\n",
            "[✓] Cleaned: Replay_dataset_HY_Sonata_train.cleaned.csv\n",
            "[✓] Cleaned: Replay_dataset_KIA_Soul_train.cleaned.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}